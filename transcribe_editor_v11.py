# transcribe_editor_v11.py
# -------------------------------------------------------------
# æ©Ÿèƒ½:
# 1) éŸ³å£°/å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ â†’ OpenAIã§æ–‡å­—èµ·ã“ã—ï¼ˆ50MBã¾ã§ç›´æ¥å¯ã€è¶…éã¯è‡ªå‹•åˆ†å‰²ï¼‰
# 2) å‡ºåŠ›é¸æŠ: é€èª(ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—) / ç›´è¨³ï¼ˆæ—¥æœ¬èªåŒ–ã®ã¿ï¼‰/ è­°äº‹éŒ² / è¦æ—¨ / è¨˜äº‹ / ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬
# 3) ç›®çš„é¸æŠ: å­¦ä¼šç™ºè¡¨ / ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬ / ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ï¼ˆLLMæ•´å½¢ã«åæ˜ ï¼‰
# 4) å‹•ç”»ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ã‚¹ãƒ©ã‚¤ãƒ‰OCR(ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º + OCR) ä½µç”¨ã®å¯å¦ï¼ˆä¾å­˜ãŒç„¡ã‘ã‚Œã°è‡ªå‹•ã§ã‚¹ã‚­ãƒƒãƒ—ï¼‰
# 5) TXT/DOCXã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½
# 6) ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§æ¯å›ã€Œå…±é€šãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã€ã¨ã€ŒOpenAI APIã‚­ãƒ¼ã€ã‚’å…¥åŠ›ï¼ˆSecretsä¸è¦ï¼‰
# -------------------------------------------------------------

import os
import io
import time
import glob
import shutil
import subprocess
import mimetypes
import json
import traceback
from datetime import timedelta
import re
from typing import List, Tuple, Dict, Any

import math
from pathlib import Path

import streamlit as st
from pydub import AudioSegment
from pydub.utils import which
from docx import Document
from docx.shared import Pt

# ï¼ˆLLMã®æ•´å½¢ã« chat.completions ã‚’ä½¿ã†ãŸã‚ã®äº’æ›ãƒãƒ³ãƒ‰ãƒ«ï¼‰
try:
    import openai as openai_mod  # pip install openai
except Exception:
    openai_mod = None

# EasyOCR ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã‚‚è½ã¡ãªã„ã‚ˆã†ã«ï¼‰
try:
    import easyocr  # pip install easyocr
except Exception:
    easyocr = None

# ç”»åƒç³»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯é…å»¶ãƒ»ä»»æ„ï¼ˆæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’è¨±å®¹ï¼‰
try:
    import numpy as np
    import cv2
    from PIL import Image
except Exception:
    np = None
    cv2 = None
    Image = None

# OpenAI v1
from openai import OpenAI

# ========== OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç”Ÿæˆï¼ˆAzureäº’æ›ï¼‰ ==========
def get_openai_client(api_key: str) -> OpenAI:
    base = os.environ.get("OPENAI_BASE_URL")  # ä¾‹: https://{resource}.openai.azure.com/openai/v1
    if base:
        return OpenAI(api_key=api_key, base_url=base)
    return OpenAI(api_key=api_key)

# ========== ãƒ©ãƒ³ã‚¿ã‚¤ãƒ å…±é€šã‚¹ãƒˆã‚¢ï¼ˆèµ·å‹•ä¸­ã®ã¿ä¿æŒï¼‰ ==========
@st.cache_resource(show_spinner=False)
def runtime_config():
    return {
        "common_password": None,   # åˆå›ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã§ç®¡ç†è€…ãŒè¨­å®š
        "default_api_key": None,   # ä»»æ„ï¼šæ—¢å®šã®APIã‚­ãƒ¼ã€‚æœªè¨­å®šãªã‚‰å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¯å›å…¥åŠ›
    }

# ========== ãƒ­ã‚°ã‚¤ãƒ³ï¼†APIã‚­ãƒ¼å–å¾—ï¼ˆæ¯å›ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§å…¥åŠ›ï¼‰ ==========
def require_login_and_api() -> str:
    cfg = runtime_config()
    with st.sidebar:
        st.header("ğŸ” ã‚¢ã‚¯ã‚»ã‚¹")

        # âš™ï¸ ç®¡ç†è€…ãƒªã‚»ãƒƒãƒˆï¼ˆä»»æ„ï¼‰
        with st.expander("âš™ï¸ ç®¡ç†è€…ãƒ¡ãƒ‹ãƒ¥ãƒ¼ï¼ˆãƒªã‚»ãƒƒãƒˆï¼‰"):
            reset_token = st.text_input("RESET ã¨å…¥åŠ›ã—ã¦æœ‰åŠ¹åŒ–", key="reset_token")
            if st.button("åˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’ã‚„ã‚Šç›´ã™", key="btn_reset_setup"):
                if reset_token.strip().upper() != "RESET":
                    st.warning("RESET ã¨å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                else:
                    cfg["common_password"] = None
                    cfg["default_api_key"] = None
                    st.session_state.clear()
                    try:
                        st.rerun()
                    except Exception:
                        try:
                            st.experimental_rerun()
                        except Exception:
                            pass

        # åˆå›ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼šå…±é€šãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã®ã¿è¨­å®š
        if not cfg["common_password"]:
            st.info("åˆå›ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼šå…±é€šãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã®ã¿è¨­å®šï¼ˆAPIã‚­ãƒ¼ã¯ä¿å­˜ã—ã¾ã›ã‚“ï¼‰")
            new_pw = st.text_input("å…±é€šãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ï¼ˆå¿…é ˆï¼‰", type="password", key="pw_setup")
            if st.button("ä¿å­˜", key="btn_save_pw"):
                if not new_pw:
                    st.error("å…±é€šãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¯å¿…é ˆã§ã™ã€‚")
                else:
                    cfg["common_password"] = new_pw
                    cfg["default_api_key"] = None
                    st.success("ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ã€‚ä»¥é™ã¯ã“ã®ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã§ãƒ­ã‚°ã‚¤ãƒ³ã§ãã¾ã™ã€‚")
                    try:
                        st.rerun()
                    except Exception:
                        try:
                            st.experimental_rerun()
                        except Exception:
                            pass
            st.stop()

        # é€šå¸¸ãƒ­ã‚°ã‚¤ãƒ³ï¼šæ¯å› ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ï¼‹APIã‚­ãƒ¼ ã‚’å…¥åŠ›
        pw = st.text_input("å…±é€šãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›", type="password", key="pw_login")
        user_key = st.text_input("OpenAI APIã‚­ãƒ¼ï¼ˆå¿…é ˆï¼‰", type="password", key="user_api")

        if st.button("ãƒ­ã‚°ã‚¤ãƒ³", key="btn_login"):
            if pw != cfg["common_password"]:
                st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™ã€‚")
                st.stop()
            if not user_key.strip():
                st.error("OpenAI APIã‚­ãƒ¼ã¯å¿…é ˆã§ã™ã€‚")
                st.stop()
            st.session_state["auth_ok"] = True
            st.session_state["user_api_key"] = user_key.strip()
            try:
                st.rerun()
            except Exception:
                try:
                    st.experimental_rerun()
                except Exception:
                    pass

        if not st.session_state.get("auth_ok"):
            st.stop()

    api_key = st.session_state.get("user_api_key", "")
    if not api_key:
        st.error("OpenAI APIã‚­ãƒ¼ãŒæœªå…¥åŠ›ã§ã™ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    return api_key

# ========== æ–‡å­—ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ==========
def split_text_by_chars(text: str, chunk_size: int = 6000, overlap: int = 300) -> list[str]:
    text = text.strip()
    if len(text) <= chunk_size:
        return [text]
    chunks = []
    start = 0
    while start < len(text):
        end = min(len(text), start + chunk_size)
        cut = end
        for p in ("ã€‚", "ï¼", "ï¼Ÿ", "\n"):
            idx = text.rfind(p, start, end)
            if idx != -1 and idx > start + 1000:
                cut = idx + 1
                break
        chunks.append(text[start:cut].strip())
        if cut >= len(text):
            break
        start = max(cut - overlap, 0)
    return [c for c in chunks if c]

def strip_timestamps(text: str) -> str:
    pattern = re.compile(
        r"^\s*\[\d{2}:\d{2}:\d{2}(?:\.\d{3})?\s*(?:â†’|->|-|ï¼|â€”)\s*\d{2}:\d{2}:\d{2}(?:\.\d{3})?\]\s*",
        re.MULTILINE,
    )
    return pattern.sub("", text).strip()

# ========== FFmpeg/ffprobe æ¤œå‡º ==========
PROJECT_DIR = Path(__file__).parent
FFBIN_CANDIDATES = [
    PROJECT_DIR / "ffmpeg-7.0.2-essentials_build" / "bin",
    Path(r"C:\\Users\\s-has\\Desktop\\å‹•ç”»éŸ³å£°åŸç¨¿ä½œæˆ082025\\ffmpeg-7.0.2-essentials_build\\bin"),
    Path(r"C:\\Users\\s-has\\Desktop\\ffmpeg-7.0.2-essentials_build\\bin"),
]
FFMPEG_EXE = None
FFPROBE_EXE = None
for _bin in FFBIN_CANDIDATES:
    ff = _bin / "ffmpeg.exe"
    fp = _bin / "ffprobe.exe"
    if ff.exists():
        FFMPEG_EXE, FFPROBE_EXE = ff, (fp if fp.exists() else None)
        os.environ["PATH"] = str(_bin) + os.pathsep + os.environ.get("PATH", "")
        os.environ["FFMPEG_BINARY"] = str(ff)
        os.environ["IMAGEIO_FFMPEG_EXE"] = str(ff)
        AudioSegment.converter = str(ff)
        AudioSegment.ffmpeg = str(ff)
        if FFPROBE_EXE:
            AudioSegment.ffprobe = str(FFPROBE_EXE)
        break
else:
    ffmpeg_found = which("ffmpeg")
    ffprobe_found = which("ffprobe")
    if ffmpeg_found:
        FFMPEG_EXE = Path(ffmpeg_found)
        AudioSegment.converter = ffmpeg_found
        AudioSegment.ffmpeg = ffmpeg_found
    if ffprobe_found:
        FFPROBE_EXE = Path(ffprobe_found)
        AudioSegment.ffprobe = ffprobe_found

# ========== I/O ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ==========
def save_uploaded_file_to_temp(uploaded_file) -> str:
    suffix = os.path.splitext(uploaded_file.name)[1]
    tmp_path = os.path.join(st.session_state["workdir"], f"upload_{int(time.time())}{suffix}")
    with open(tmp_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return tmp_path

def ensure_wav(input_path: str) -> str:
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ 16kHz/mono ã® WAV ã«å¤‰æ›ã€‚
       pydubâ†’å¤±æ•—æ™‚ã¯ ffmpeg CLI ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚"""
    wav_path = os.path.splitext(input_path)[0] + "_16k.wav"
    # 1) ã¾ãšã¯ pydub
    try:
        audio = AudioSegment.from_file(input_path)
        audio = audio.set_channels(1).set_frame_rate(16000)
        audio.export(wav_path, format="wav")
        return wav_path
    except Exception:
        pass  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¸

    # 2) ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ffmpeg CLI ã§ â€œä¿®å¾©â†’éŸ³å£°æŠ½å‡ºâ€
    ff = shutil.which("ffmpeg") or "ffmpeg"
    fixed_mp4 = os.path.splitext(input_path)[0] + "_fixed.mp4"
    try:
        p1 = subprocess.run(
            [ff, "-y", "-v", "error", "-i", input_path, "-c", "copy", "-movflags", "+faststart", fixed_mp4],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding="utf-8", errors="ignore"
        )
        src_for_audio = fixed_mp4 if os.path.exists(fixed_mp4) and p1.returncode == 0 else input_path
        p2 = subprocess.run(
            [ff, "-y", "-v", "error", "-i", src_for_audio,
             "-vn", "-ac", "1", "-ar", "16000", "-map", "0:a:0?",
             "-c:a", "pcm_s16le", wav_path],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding="utf-8", errors="ignore"
        )
        if p2.returncode == 0 and os.path.exists(wav_path):
            return wav_path
        raise RuntimeError(p2.stderr or "ffmpeg failed")
    except Exception as e2:
        st.error(
            "éŸ³å£°/å‹•ç”»ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n"
            "ï¼ˆå°ã•ã‚ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§å†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€ã‚ã‚‹ã„ã¯ mp3/m4a ã§ã®ã‚¢ãƒƒãƒ—ã‚’ãŠè©¦ã—ãã ã•ã„ï¼‰\n\n"
            f"è©³ç´°: {e2}"
        )
        st.stop()

# ---- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‰ã®è»½é‡åŒ–ï¼ˆã¾ãšã¯MP3 32kbps monoã‚’è©¦ã™ï¼‰----
def shrink_audio_for_upload(src_path: str, target_mb: float = 50.0) -> tuple[str, float, str]:
    """
    return: (ä½¿ã†ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹, ã‚µã‚¤ã‚ºMB, ãƒ¢ãƒ¼ãƒ‰)
      ãƒ¢ãƒ¼ãƒ‰: "original" / "mp3-32k" / "too_large"
    """
    try:
        size_mb = os.path.getsize(src_path) / (1024 * 1024)
    except Exception:
        return src_path, 0.0, "original"
    if size_mb <= target_mb:
        return src_path, size_mb, "original"
    # MP3 32kbps mono å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    try:
        audio = AudioSegment.from_file(src_path)
        audio = audio.set_channels(1).set_frame_rate(16000)
        mp3_path = os.path.splitext(src_path)[0] + "_uploader.mp3"
        audio.export(mp3_path, format="mp3", bitrate="32k")
        size_mb2 = os.path.getsize(mp3_path) / (1024 * 1024)
        if size_mb2 <= target_mb:
            return mp3_path, size_mb2, "mp3-32k"
    except Exception:
        pass
    return src_path, size_mb, "too_large"

# ---- WAVã‚’ä¸€å®šç§’æ•°ã§åˆ†å‰²ï¼ˆãƒ‡ãƒ•ã‚© 10åˆ†=600ç§’ï¼‰----
def chunk_wav_by_time(src_wav: str, chunk_sec: int = 600) -> list[str]:
    audio = AudioSegment.from_file(src_wav)
    chunks = []
    base = os.path.splitext(src_wav)[0]
    total_ms = len(audio)
    step = chunk_sec * 1000
    i = 0
    for start_ms in range(0, total_ms, step):
        part = audio[start_ms:start_ms + step]
        out = f"{base}_part{i:03d}.wav"
        part.export(out, format="wav")
        chunks.append(out)
        i += 1
    return chunks

def format_timestamp(seconds: float) -> str:
    td = timedelta(seconds=float(seconds))
    total_seconds = int(td.total_seconds())
    ms = int((td.total_seconds() - total_seconds) * 1000)
    return f"{total_seconds//3600:02d}:{(total_seconds%3600)//60:02d}:{total_seconds%60:02d}.{ms:03d}"

def fmt_ts(x: float) -> str:
    return format_timestamp(x) if math.isfinite(x) else "â€¦"

# ========== OpenAI ã§æ–‡å­—èµ·ã“ã— ==========
def _safe_lang(forced_lang: str | None):
    if not forced_lang:
        return None
    lang = forced_lang.strip().lower()
    if lang in {"auto", "detect", "none", ""}:
        return None
    if len(lang) != 2:
        return None
    return lang

def transcribe_openai(wav_path: str, api_key: str, forced_lang: str | None = None):
    start = time.time()
    last_err = None
    try:
        if not api_key:
            raise ValueError("OpenAI API key is empty. Set OPENAI_API_KEY or provide api_key.")
        if not wav_path or not os.path.exists(wav_path):
            raise FileNotFoundError(f"Audio file not found: {wav_path}")

        file_size_mb = os.path.getsize(wav_path) / (1024 * 1024)
        # 50MB ã¾ã§è¨±å¯ï¼ˆ>50MB ã¯å‘¼ã³å‡ºã—å´ã§åˆ†å‰²ã—ã¦ã‹ã‚‰æ¸¡ã™ãŸã‚é€šå¸¸åˆ°é”ã—ãªã„ï¼‰
        if file_size_mb > 50.0:
            raise RuntimeError(f"Audio file is too large ({file_size_mb:.1f} MB). Please split into smaller parts (<50MB).")

        client = get_openai_client(api_key)
        language = _safe_lang(forced_lang)

        with open(wav_path, "rb") as f:
            try:
                resp = client.audio.transcriptions.create(
                    model="gpt-4o-mini-transcribe",
                    file=f,
                    language=language
                )
            except Exception as e1:
                last_err = e1
                f.seek(0)
                resp = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=f,
                    language=language
                )

        text = getattr(resp, "text", None) or (resp.get("text") if isinstance(resp, dict) else None)
        if not text:
            raise RuntimeError("OpenAI returned empty transcription text.")

        detected_lang = language or "auto"
        st.sidebar.info(f"Transcribed in {time.time()-start:.1f}s, size={file_size_mb:.1f}MB, lang={detected_lang}")
        segments = [{"start": 0.0, "end": 0.0, "text": text}]
        return segments, detected_lang

    except Exception as e:
        tb = traceback.format_exc()
        debug_blob = {
            "where": "transcribe_openai",
            "wav_path": wav_path,
            "forced_lang": forced_lang,
            "safe_lang": _safe_lang(forced_lang),
            "file_exists": os.path.exists(wav_path) if wav_path else False,
            "file_size_mb": (os.path.getsize(wav_path) / (1024*1024)) if (wav_path and os.path.exists(wav_path)) else None,
            "last_err_type": type(last_err).__name__ if last_err else None,
            "last_err_str": str(last_err) if last_err else None,
            "caught_err_type": type(e).__name__,
            "caught_err": str(e),
        }
        st.error("Transcription failed. See diagnostics below.")
        st.code(json.dumps(debug_blob, ensure_ascii=False, indent=2))
        st.code(tb)
        try:
            with open("/mount/src/transcribe_error.log", "a", encoding="utf-8") as logf:
                logf.write(json.dumps(debug_blob, ensure_ascii=False) + "\n")
                logf.write(tb + "\n")
        except Exception:
            pass
        raise RuntimeError(f"Transcription failed: {last_err or e}")

# ========== ã‚¹ãƒ©ã‚¤ãƒ‰ã¨ç™ºè©±ã®å¯¾å¿œä»˜ã‘ ==========
def group_segments_by_slides(
    segments: List[Tuple[str, float, float]],
    slide_change_times: List[float]
) -> List[Dict[str, Any]]:
    last_end = max((e for _, _, e in segments), default=0.0)
    bounds = [0.0] + [t for t in slide_change_times if t < last_end] + [last_end]
    grouped = []
    for i in range(len(bounds)-1):
        start, end = bounds[i], bounds[i+1]
        bucket = []
        for t, s, e in segments:
            if e > start and s < end:
                bucket.append((t, max(s, start), min(e, end)))
        grouped.append({"index": i+1, "start": start, "end": end, "segments": bucket})
    return grouped

# ========== ã‚¹ãƒ©ã‚¤ãƒ‰æŠ½å‡º & OCR ==========
def extract_slide_keyframes_with_times(video_path: str, out_dir: str, scene_thr: float=0.35) -> tuple[list[str], list[float]]:
    os.makedirs(out_dir, exist_ok=True)
    for p in glob.glob(os.path.join(out_dir, "*.jpg")):
        try:
            os.remove(p)
        except:
            pass

    ff_cmd = str(FFMPEG_EXE) if FFMPEG_EXE else (shutil.which("ffmpeg") or "ffmpeg")

    # 1) ã‚·ãƒ¼ãƒ³å¤‰åŒ–æŠ½å‡º
    cmd = [
        ff_cmd, "-y", "-i", video_path,
        "-vf", f"select='gt(scene,{scene_thr})',showinfo",
        "-vsync", "vfr",
        os.path.join(out_dir, "%04d.jpg"),
    ]
    proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding="utf-8", errors="ignore")
    stderr = proc.stderr or ""

    times = []
    for m in re.finditer(r"pts_time:([0-9]+\.[0-9]+)", stderr):
        try:
            times.append(float(m.group(1)))
        except:
            pass

    image_paths = sorted(glob.glob(os.path.join(out_dir, "*.jpg")))
    n = min(len(image_paths), len(times))
    if n > 0:
        return image_paths[:n], times[:n]

    # 2) ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼š3ç§’é–“éš”ã§æŠ½å‡º
    for p in glob.glob(os.path.join(out_dir, "*.jpg")):
        try: os.remove(p)
        except: pass
    cmd_fb = [
        ff_cmd, "-y", "-i", video_path,
        "-vf", "fps=1/3,showinfo",
        "-vsync", "vfr",
        os.path.join(out_dir, "%04d.jpg"),
    ]
    subprocess.run(cmd_fb, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding="utf-8", errors="ignore")

    image_paths = sorted(glob.glob(os.path.join(out_dir, "*.jpg")))
    if image_paths:
        approx_times = [i * 3.0 for i in range(len(image_paths))]
        return image_paths, approx_times

    # 3) ãã‚Œã§ã‚‚0ãªã‚‰å…ˆé ­1æšã ã‘ç¢ºä¿
    one_path = os.path.join(out_dir, "0001.jpg")
    subprocess.run([ff_cmd, "-y", "-ss", "00:00:01", "-i", video_path, "-vframes", "1", one_path],
                   stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding="utf-8", errors="ignore")
    image_paths = sorted(glob.glob(os.path.join(out_dir, "*.jpg")))
    if image_paths:
        return image_paths, [0.0]

    return [], []

def _to_cv2_bgr(image_like):
    # ç”»åƒç³»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒç„¡ã‘ã‚Œã°OCRã¯ã‚¹ã‚­ãƒƒãƒ—
    if (cv2 is None) or (np is None) or (Image is None):
        return None
    try:
        if isinstance(image_like, (bytes, bytearray)):
            arr = np.frombuffer(image_like, np.uint8)
            img = cv2.imdecode(arr, cv2.IMREAD_COLOR)
            return img
        if isinstance(image_like, str):
            img = cv2.imread(image_like, cv2.IMREAD_COLOR)
            if img is None:
                try:
                    pil = Image.open(image_like).convert("RGB")
                    return cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)
                except Exception:
                    return None
            return img
        if isinstance(image_like, Image.Image):
            return cv2.cvtColor(np.array(image_like), cv2.COLOR_RGB2BGR)
        if isinstance(image_like, np.ndarray):
            if image_like.ndim == 2:
                return cv2.cvtColor(image_like, cv2.COLOR_GRAY2BGR)
            return image_like
    except Exception:
        return None
    return None

def _get_reader():
    """EasyOCR Reader ã‚’ï¼ˆã‚ã‚Œã°ï¼‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ä½¿ã„å›ã—ã€‚"""
    if easyocr is None:
        return None
    @st.cache_resource(show_spinner=False)
    def _cached_reader():
        return easyocr.Reader(['ja', 'en'], gpu=False)
    return _cached_reader()

def ocr_slides(image_paths: list) -> list[dict]:
    """
    image_paths: ç”»åƒãƒ‘ã‚¹/bytes/PIL/ndarray ãŒæ··åœ¨ã—ã¦ã„ã¦ã‚‚OK
    return: [{"index": i, "path": å…ƒã®å‚ç…§, "text": èªè­˜æ–‡å­—åˆ—}, ...]
    """
    if not image_paths:
        return []
    if easyocr is None or (cv2 is None) or (np is None) or (Image is None):
        # ä¾å­˜ãŒãªã‘ã‚Œã°ç©ºæ–‡å­—ã§è¿”ã™ï¼ˆã‚¢ãƒ—ãƒªã¯ç¶™ç¶šï¼‰
        return [{"index": i+1, "path": p, "text": ""} for i, p in enumerate(image_paths)]
    reader = _get_reader()
    results = []
    valid_found = False
    for idx, src in enumerate(image_paths, start=1):
        img = _to_cv2_bgr(src)
        if img is None or getattr(img, "size", 0) == 0:
            results.append({"index": idx, "path": src, "text": ""})
            continue
        valid_found = True
        try:
            lines = reader.readtext(img, detail=0)
            text = "\n".join(lines) if lines else ""
            results.append({"index": idx, "path": src, "text": text})
        except Exception:
            results.append({"index": idx, "path": src, "text": ""})
    if not valid_found:
        st.error("OCRç”¨ã®ç”»åƒã‚’æ­£ã—ãèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸï¼ˆãƒ‘ã‚¹ãƒ»å½¢å¼ãƒ»æŠ½å‡ºå‡¦ç†ã‚’ã”ç¢ºèªãã ã•ã„ï¼‰ã€‚")
    return results

# ========== æ•´å½¢(ç”ŸæˆAIãªã—) ==========
def to_verbatim_with_timestamps(segments: List[Tuple[str, float, float]]) -> str:
    lines: List[str] = []
    for t, s, e in segments:
        start_disp = format_timestamp(s) if math.isfinite(s) else "â€¦"
        end_disp   = format_timestamp(e) if math.isfinite(e) else "â€¦"
        lines.append(f"[{start_disp} â†’ {end_disp}] {t}")
    return "\n".join(lines)

def heuristic_minutes(segments: List[Tuple[str, float, float]]) -> str:
    block, blocks, char_limit = [], [], 300
    for t, s, e in segments:
        if sum(len(x[0]) for x in block) + len(t) > char_limit and block:
            blocks.append(block); block = []
        block.append((t, s, e))
    if block: blocks.append(block)
    out = ["ã€è­°äº‹éŒ²ï¼ˆè‡ªå‹•æ•´å½¢ãƒ»è¦ç‚¹ï¼‰ã€‘\n"]
    for i, b in enumerate(blocks, 1):
        out.append(f"â–  ãƒˆãƒ”ãƒƒã‚¯{i}ï¼ˆ{format_timestamp(b[0][1])}â€“{format_timestamp(b[-1][2])}ï¼‰")
        for t, _, _ in b: out.append(f"ãƒ»{t}")
        out.append("")
    return "\n".join(out).strip()

def heuristic_abstract(segments: List[Tuple[str, float, float]]) -> str:
    text = " ".join(t for t, _, _ in segments)
    sentences = [s.strip() for s in text.replace("ã€‚", "ã€‚\n").splitlines() if s.strip()]
    return "ã€è¦æ—¨ï¼ˆè‡ªå‹•æŠ½å‡ºï¼‰ã€‘\n" + "\n".join(sentences[:6])

def heuristic_article_academic(segments: List[Tuple[str, float, float]]) -> str:
    body = " ".join(t for t, _, _ in segments)
    lines = [
        "ã€å­¦ä¼šå ±å‘Šè¨˜äº‹ï¼ˆè‡ªå‹•æ•´å½¢ãƒ»AIä¸ä½¿ç”¨ï¼‰ã€‘",
        "",
        "â–  ãƒªãƒ¼ãƒ‰",
        "æœ¬è¬›æ¼”ã§ã¯ã€æ¼”è€…ãŒæç¤ºã—ãŸä¸»è¦ãƒã‚¤ãƒ³ãƒˆã‚’æŠœç²‹ã—ã€å†…å®¹ã‚’ç°¡æ½”ã«æ•´ç†ã™ã‚‹ã€‚æœ¬æ–‡ã¯è‡ªå‹•æ•´å½¢ã®ãŸã‚ã€è¦ç‚¹ãƒ¬ãƒ™ãƒ«ã®æŠœç²‹ã§ã‚ã‚‹ã€‚",
        "",
        "â–  èƒŒæ™¯ãƒ»ç›®çš„",
        "è¬›æ¼”ã®èƒŒæ™¯ã€è‡¨åºŠä¸Šã®æ„ç¾©ã€ç›®çš„ã‚’æœ¬æ–‡ã‹ã‚‰æ©Ÿæ¢°çš„ã«æŠ½å‡ºãƒ»å†æ§‹æˆã€‚",
        "",
        "â–  æ–¹æ³•ãƒ»è³‡æ–™",
        "ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿ã€å¯¾è±¡ã€æ‰‹æ³•ã€è©•ä¾¡æŒ‡æ¨™ãªã©ã®è¨˜è¼‰ã‚’è¦ç‚¹ã¨ã—ã¦æŠ½å‡ºã€‚",
        "",
        "â–  çµæœãƒ»æ‰€è¦‹",
        "æœ¬æ–‡ã‹ã‚‰çµæœã«ç›¸å½“ã™ã‚‹æ–‡ã‚’å„ªå…ˆçš„ã«æ‹¾ã„ä¸Šã’åæ˜ ã€‚",
        "",
        "â–  è€ƒå¯Ÿãƒ»çµè«–",
        "è‡¨åºŠç¾å ´ã¸ã®ç¤ºå”†ã€é™ç•Œã€ä»Šå¾Œã®å±•æœ›ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹ã€‚",
        "",
        "â€” ä»¥ä¸‹ã¯é€èªãƒ™ãƒ¼ã‚¹æœ¬æ–‡ï¼ˆæ©Ÿæ¢°æŠ½å‡ºï¼‰ â€”",
        body,
    ]
    return "\n".join(lines)

def heuristic_guideline_commentary(slide_groups: List[Dict[str, Any]], ocr_notes: List[dict]) -> str:
    ocr_map = {o.get("index"): (o.get("text") or "").strip() for o in (ocr_notes or [])}
    lines = [
        "ã€ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬ï¼ˆè‡ªå‹•æ•´å½¢ãƒ»AIä¸ä½¿ç”¨ï¼‰ã€‘\n",
        "â–  èƒŒæ™¯",
        "ãƒ»æœ¬è§£èª¬ã¯æ¼”è€…ã‚¹ãƒ©ã‚¤ãƒ‰ã¨ã‚¹ãƒ”ãƒ¼ãƒå†…å®¹ã‚’å¯¾å¿œä»˜ã‘ã¦å†æ§‹æˆã—ãŸã‚‚ã®ã€‚",
        "",
    ]
    for g in slide_groups:
        idx, ocr = g["index"], ocr_map.get(g["index"], "")
        lines.append(f"â–¼ Slide {idx}ï¼ˆ{format_timestamp(g['start'])}â€“{fmt_ts(g['end'])}ï¼‰")
        if ocr:
            title = ocr.splitlines()[0][:50]
            lines.append(f"ã€ã‚¹ãƒ©ã‚¤ãƒ‰è¦æ—¨ã€‘{title}")
        for t, s, e in g["segments"][:6]:
            lines.append(f"ãƒ»{t}")
        lines.append("")
    lines += ["â–  è‡¨åºŠã¸ã®å«æ„", "ãƒ»æœ¬æ”¹è¨‚ã«ã‚ˆã‚Šæƒ³å®šã•ã‚Œã‚‹è¨ºç™‚ä¸Šã®å½±éŸ¿ç‚¹ã‚’è¦ç‚¹åŒ–ã€‚", "", "â–  ä»Šå¾Œã®èª²é¡Œ", "ãƒ»ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹å¼·åŒ–ãŒå¿…è¦ãªè«–ç‚¹ã€é‹ç”¨æ™‚ã®ç•™æ„ç‚¹ã€‚"]
    return "\n".join(lines).strip()

# ========== LLMï¼ˆè¨˜äº‹åŒ–/è¦æ—¨/è­°äº‹éŒ²ï¼‰ ==========
PURPOSE_PROMPTS = {
    "å­¦ä¼šç™ºè¡¨": (
        "ä»¥ä¸‹ã®ç´ æï¼ˆéŸ³å£°é€èªã¨ä»»æ„ã®ã‚¹ãƒ©ã‚¤ãƒ‰OCRè¦ç´„ï¼‰ã‹ã‚‰ã€å­¦ä¼šå ±å‘Šè¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        "è¦‹å‡ºã—ï¼ˆå°å…¥/èƒŒæ™¯/ç›®çš„/æ–¹æ³•/çµæœ/è€ƒå¯Ÿ/çµèªï¼‰ã‚’ä»˜ã‘ã€å›ºæœ‰åè©ã¨æ•°å€¤ã¯æ”¹å¤‰ã›ãšã€"
        "èª‡å¼µã‚„å‰µä½œã¯é¿ã‘ã¦ãã ã•ã„ã€‚å°‚é–€èª­è€…å‘ã‘ã«ç°¡æ½”ã§æ­£ç¢ºã«ã€‚"
    ),
    "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬": (
        "ä»¥ä¸‹ã®ç´ æã‹ã‚‰ã€æ—¥æœ¬èªã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³æ”¹è¨‚è§£èª¬è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        "èƒŒæ™¯/æ”¹è¨‚ãƒã‚¤ãƒ³ãƒˆ/æ¨å¥¨åº¦ãƒ»ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹/è‡¨åºŠã¸ã®å½±éŸ¿/èª²é¡Œ/ä»Šå¾Œã€ã®é †ã«ä¸€åº¦ã ã‘éª¨çµ„ã¿ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚"
        "ãƒ†ã‚­ã‚¹ãƒˆãŒè¤‡æ•°ãƒ‘ãƒ¼ãƒˆã«åˆ†å‰²ã•ã‚Œã‚‹å ´åˆã§ã‚‚ã€è¦‹å‡ºã—ãƒ»å°å…¥ã®å†æ²ã¯ã—ãªã„ã§ãã ã•ã„ã€‚"
        "æ—¢å‡ºå†…å®¹ã®å†æ²ã‚’é¿ã‘ã€æ–°è¦æƒ…å ±ã®ã¿è¿½è¨˜ã™ã‚‹å½¢ã§é€£ç¶šæ€§ã‚’ä¿ã£ã¦ãã ã•ã„ã€‚"
        "è‹±èªã¯æ­£ç¢ºã«æ—¥æœ¬èªåŒ–ã—ã€å¼•ç”¨ã¯è¦æ—¨åŒ–ã—ã¦æ›¸ãç›´ã—ã¦ãã ã•ã„ã€‚"
    ),
    "ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³": (
        "ä»¥ä¸‹ã®ç´ æã‹ã‚‰ã€ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        "è«–ç‚¹æ•´ç†/è³›å¦ã®ä¸»å¼µ/æ ¹æ‹ /ä¸€è‡´ç‚¹ã¨ç›¸é•ç‚¹/çµè«–ã¨ä»Šå¾Œã®æ¤œè¨èª²é¡Œã€ã®é †ã§ã€ä¸­ç«‹ãƒ»ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚"
        "å†—é•·ãªå£èªè¡¨ç¾ã¯å‰Šé™¤ã—ã€æ–¹è¨€ã¯æ¨™æº–èªã«ç›´ã—ã¦ãã ã•ã„ã€‚"
    ),
}

def llm_rewrite(kind: str, text: str, api_key: str | None,
                purpose: str | None = None,
                source_lang: str | None = None,
                target_lang: str | None = "ja") -> str:
    if openai_mod is None:
        return "[LLMæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«] `pip install -U openai` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
    if not api_key:
        return "[APIã‚­ãƒ¼æœªå…¥åŠ›] ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§APIã‚­ãƒ¼ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚"

    sys_prompt = (
        "ã‚ãªãŸã¯åŒ»å­¦ãƒ»åŒ»ç™‚ç³»ã®æ—¥æœ¬èªç·¨é›†è€…ã§ã™ã€‚è‡¨åºŠãƒ»å­¦è¡“æ–‡è„ˆã«æ²¿ã£ã¦ã€"
        "èª­ã¿ã‚„ã™ãäº‹å®Ÿé–¢ä¿‚ã‚’ä¿ã£ãŸã¾ã¾æ•´æ–‡ã—ã¾ã™ã€‚æ•°å€¤ã‚„å¼•ç”¨ã¯æ”¹å¤‰ã—ã¾ã›ã‚“ã€‚"
    )
    pre = PURPOSE_PROMPTS.get(purpose or "å­¦ä¼šç™ºè¡¨", "")

    if (target_lang or "ja").lower() == "ja":
        lang_policy = (
            "æœ€çµ‚å‡ºåŠ›ã¯å¿…ãšæ—¥æœ¬èªã§æ›¸ã„ã¦ãã ã•ã„ã€‚éŸ³å£°/ã‚¹ãƒ©ã‚¤ãƒ‰ãŒæ—¥æœ¬èªã§ãªã„å ´åˆã¯æ­£ç¢ºã«æ—¥æœ¬èªã¸ç¿»è¨³ã—ã€"
            "å°‚é–€ç”¨èªã¯é©åˆ‡ãªæ—¥æœ¬èªè¨³ã‚’ç”¨ã„ã€å›ºæœ‰åè©ãƒ»æ•°å€¤ãƒ»å˜ä½ã¯ä¿æŒã—ã¦ãã ã•ã„ã€‚"
        )
        if source_lang and str(source_lang).lower() != "ja":
            lang_policy += "ï¼ˆå…¥åŠ›ã¯æ—¥æœ¬èªä»¥å¤–ã¨æ¤œå‡ºã•ã‚ŒãŸãŸã‚ç¿»è¨³ãŒå¿…è¦ã§ã™ï¼‰"
    else:
        lang_policy = f"æœ€çµ‚å‡ºåŠ›ã¯å¿…ãš {target_lang} ã§æ›¸ã„ã¦ãã ã•ã„ã€‚å›ºæœ‰åè©ãƒ»æ•°å€¤ãƒ»å˜ä½ã¯ä¿æŒã—ã¦ãã ã•ã„ã€‚"

    user_prompt_map = {
        "verbatim": "é€èªè¨˜éŒ²ï¼ˆè»½å¾®ãªå¥èª­ç‚¹æ•´å½¢ã®ã¿ã€æ„å‘³æ”¹å¤‰ç¦æ­¢ï¼‰ï¼š\n\n" + text,
        "minutes":  "è­°äº‹éŒ²ï¼ˆè¦‹å‡ºã—ï¼‹ç®‡æ¡æ›¸ãã€æ™‚ç³»åˆ—ï¼‰ï¼š\n\n" + text,
        "abstract": "å­¦ä¼šæŠ„éŒ²ï¼ˆç›®çš„/æ–¹æ³•/çµæœ/çµè«–ã€600-900å­—ï¼‰ï¼š\n\n" + text,
        "article":  "è¨˜äº‹åŒ–ï¼ˆå°å…¥/èƒŒæ™¯/ç›®çš„/æ–¹æ³•/çµæœ/è€ƒå¯Ÿ/çµèªï¼‰ï¼š\n\n" + text,
    }
    if kind not in user_prompt_map:
        kind = "article"

    prompt = (pre + "\n\n" + lang_policy + "\n\n" + user_prompt_map[kind]).strip()

    client = openai_mod.OpenAI(api_key=api_key) if hasattr(openai_mod, "OpenAI") else None
    try:
        if client:
            resp = client.chat.completions.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "system", "content": sys_prompt},
                          {"role": "user", "content": prompt}],
                temperature=0.1,
            )
            result = resp.choices[0].message.content
        else:
            openai_mod.api_key = api_key
            resp = openai_mod.ChatCompletion.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "system", "content": sys_prompt},
                          {"role": "user", "content": prompt}],
                temperature=0.1,
            )
            result = resp["choices"][0]["message"]["content"]
    except Exception as e:
        return f"[LLMã‚¨ãƒ©ãƒ¼] {e}"

    if kind != "verbatim":
        result = "ã€AIæ•´å½¢ã€‘\n" + result
    return result

def llm_translate_only(text: str, api_key: str | None,
                       source_lang: str | None = None,
                       target_lang: str = "ja") -> str:
    if openai_mod is None:
        return "[LLMæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«] `pip install -U openai` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
    if not api_key:
        return "[APIã‚­ãƒ¼æœªå…¥åŠ›] ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§APIã‚­ãƒ¼ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚"

    sys_prompt = (
        "ã‚ãªãŸã¯å¿ å®Ÿãªå°‚é–€ç¿»è¨³è€…ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’é€èªçš„ã«æ—¥æœ¬èªã¸ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚"
        "è¦ç´„ãƒ»æ„è¨³ãƒ»è¦‹å‡ºã—ä»˜ã‘ãƒ»ç®‡æ¡æ›¸ãåŒ–ãƒ»ä½“è£å¤‰æ›´ã¯è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚"
        "æ®µè½ã‚„æ”¹è¡Œç­‰ã®æ§‹é€ ã¯å¯èƒ½ãªé™ã‚Šä¿æŒã—ã€å›ºæœ‰åè©ãƒ»æ•°å€¤ãƒ»å˜ä½ã¯ç¶­æŒã—ã¦ãã ã•ã„ã€‚"
    )
    if (target_lang or "ja").lower() != "ja":
        sys_prompt = sys_prompt.replace("æ—¥æœ¬èª", target_lang)

    prompt = "ã€ç¿»è¨³å¯¾è±¡ã€‘\n" + text

    client = openai_mod.OpenAI(api_key=api_key) if hasattr(openai_mod, "OpenAI") else None
    try:
        if client:
            resp = client.chat.completions.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "system", "content": sys_prompt},
                          {"role": "user", "content": prompt}],
                temperature=0.0,
            )
            return resp.choices[0].message.content
        else:
            openai_mod.api_key = api_key
            resp = openai_mod.ChatCompletion.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "system", "content": sys_prompt},
                          {"role": "user", "content": prompt}],
                temperature=0.0,
            )
            return resp["choices"][0]["message"]["content"]
    except Exception as e:
        return f"[LLMã‚¨ãƒ©ãƒ¼] {e}"

def llm_article_from_literal(literal_ja: str,
                             api_key: str | None,
                             purpose: str | None = "å­¦ä¼šç™ºè¡¨") -> str:
    if openai_mod is None:
        return "[LLMæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«] `pip install -U openai` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
    if not api_key:
        return "[APIã‚­ãƒ¼æœªå…¥åŠ›] ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§APIã‚­ãƒ¼ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚"

    sys_prompt = (
        "ã‚ãªãŸã¯åŒ»ç™‚ãƒ»åŒ»å­¦åˆ†é‡ã®ç·¨é›†è€…ã€‚å…¥åŠ›ã¯æ—¢ã«æ—¥æœ¬èªã¸é€èªç›´è¨³ã•ã‚ŒãŸåŸç¨¿ã€‚"
        "é‡è¤‡ãƒ»è¨€ã„æ›ãˆã®å†—é•·ã ã‘ã‚’æ•´ç†ã—ã€æ„å‘³ãƒ»äº‹å®Ÿã¯è½ã¨ã•ãšè¨˜äº‹èª¿ï¼ˆå¸¸ä½“ï¼‰ã«æ•´ãˆã‚‹ã€‚"
        "ã€å³å®ˆã€‘é‡è¤‡ä»¥å¤–ã®å‰Šé™¤ç¦æ­¢ï¼æ•°å€¤ãƒ»è©¦é¨“åãƒ»è–¬å‰¤åãƒ»ç”¨é‡ãƒ»å˜ä½ã¯ä¿æŒã€‚"
        "è¦‹å‡ºã—ã¯ã€å°å…¥/èƒŒæ™¯/ç›®çš„/æ–¹æ³•/çµæœ/è€ƒå¯Ÿ/çµèªã€ã®é †ã§ä¸€åº¦ã ã‘ã€‚"
        "è„šè‰²ãƒ»æ–°æƒ…å ±ã®è¿½åŠ ã¯ç¦æ­¢ã€‚"
        "æ–‡æœ«ã¯å¸¸ä½“ï¼ˆã€œã ï¼ã€œã§ã‚ã‚‹ï¼‰ã«çµ±ä¸€ã—ã€ã§ã™ãƒ»ã¾ã™èª¿ã¯ç¦æ­¢ã€‚"
    )
    preface = {
        "å­¦ä¼šç™ºè¡¨": "å­¦ä¼šå ±å‘Šã®é€Ÿå ±ãƒˆãƒ¼ãƒ³ã§ã€å°‚é–€èª­è€…å‘ã‘ã«ç°¡æ½”ã§æ­£ç¢ºã«ã€‚",
        "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬": "è§£èª¬è¨˜äº‹ã®æ–‡ä½“ã§ã€èƒŒæ™¯â†’è¦ç‚¹â†’è‡¨åºŠçš„å«æ„ã‚’æ˜ç¢ºã«ã€‚",
        "ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³": "è«–ç‚¹ã‚’æ˜ç¢ºåŒ–ã—ã¤ã¤ä¸­ç«‹ã«è¨˜è¿°ã€‚"
    }.get(purpose or "å­¦ä¼šç™ºè¡¨", "å°‚é–€èª­è€…å‘ã‘ã«ç°¡æ½”ã§æ­£ç¢ºã«ã€‚")

    user_prompt = (
        f"{preface}\n\n"
        "ã€å…¥åŠ›ï¼ˆé€èªç›´è¨³ãƒ»æ—¥æœ¬èªï¼‰ã€‘\n"
        + literal_ja.strip()
        + "\n\nã€å‡ºåŠ›ä»•æ§˜ã€‘\n"
          "- TCROSS NEWS å­¦ä¼šç™ºè¡¨è¨˜äº‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«æ•´å½¢ã™ã‚‹ã“ã¨ã€‚\n"
          "- ã‚¿ã‚¤ãƒˆãƒ«ã¯ã€Œå¯¾è±¡/ç–¾æ‚£ãƒ»ä»‹å…¥: è©¦é¨“åã€ã¨ã™ã‚‹ã€‚\n"
          "- ç¬¬1æ®µè½ã¯ã€Œâ–³â–³è©¦é¨“ã‚ˆã‚Šã€â–¡â–¡ã“ã¨ãŒã€å›½ã€æ‰€å±ã€æ¼”è€…åã«ã‚ˆã‚Šã€å­¦ä¼šåã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³åã§ç™ºè¡¨ã•ã‚ŒãŸã€‚ã€ã¨ã„ã†å½¢ã§æ›¸ãï¼ˆConclusionã®å†’é ­æ–‡ã‚’åæ˜ ï¼‰ã€‚\n"
          "- ç¬¬2æ®µè½ã¯è©¦é¨“ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’è¨˜è¼‰ï¼ˆè©¦é¨“åã€ç™»éŒ²æœŸé–“ã€å›½ãƒ»æ–½è¨­æ•°ã€æ‚£è€…æ•°ã€ç¾¤å‰²ä»˜ã‘ã€å‰²ä»˜ã‘æ•°ï¼‰ã€‚\n"
          "- ç¬¬3æ®µè½ã¯æ‚£è€…èƒŒæ™¯ã‚’è©³ç´°ã«è¨˜è¼‰ï¼ˆå·®ãŒãªã‘ã‚Œã°å¹³å‡å€¤ã§ã€å¹´é½¢ãƒ»æ€§åˆ¥ãƒ»ä½µå­˜ç—‡ãƒ»è–¬å‰¤å‡¦æ–¹ç‡ã‚’å«ã‚ã‚‹ï¼‰ã€‚\n"
          "- ç¬¬4æ®µè½ã¯ä¸»è¦è©•ä¾¡é …ç›®ã®çµæœã‚’è¨˜è¼‰ï¼ˆè¿½è·¡æœŸé–“ã€ã‚¤ãƒ™ãƒ³ãƒˆç‡ã€HRã€95%CIã€på€¤ã‚’ä¿æŒï¼‰ã€‚\n"
          "- ç¬¬5æ®µè½ä»¥é™ã«ã‚µãƒ–è§£æçµæœãŒã‚ã‚Œã°è¨˜è¼‰ã€‚\n"
          "- æœ€çµ‚æ®µè½ã¯æ¼”è€…ã®ãƒ©ã‚¹ãƒˆãƒãƒ¼ãƒ ã‹ã‚‰å§‹ã‚ã€ã€Œâ€¦ã¨ã€ã¾ã¨ã‚ãŸã€‚ã€ã§å¿…ãšç· ã‚ã‚‹ã€‚\n"
          "- åŒæ™‚æ²è¼‰ãŒã‚ã‚Œã°ã€Œå°šã€â–³â–³è©¦é¨“ã¯â—‹â—‹èªŒã«æ²è¼‰ã•ã‚ŒãŸã€‚ã€ã¨åŠ ãˆã‚‹ã€‚\n"
          "- è¨˜äº‹èª¿ï¼ˆå¸¸ä½“ï¼‰ã€‚\n"
          "- è¦‹å‡ºã—ã¯ã€å°å…¥/èƒŒæ™¯/ç›®çš„/æ–¹æ³•/çµæœ/è€ƒå¯Ÿ/çµèªã€ã€‚\n"
          "- å†—é•·ãªé‡è¤‡ã¯çµ±åˆã€‚ãã®ä»–ã®å†…å®¹ã¯æ®‹ã™ï¼ˆå‰Šã‚Šã™ãç¦æ­¢ï¼‰ã€‚\n"
          "- æ•°å€¤ãƒ»ç”¨èªã¯ãã®ã¾ã¾ä¿æŒã€‚\n"
          "- ç®‡æ¡æ›¸ãã§ã¯ãªãæ®µè½ã”ã¨ã«ã¾ã¨ã‚ã€è«–ç†çš„ãªæµã‚Œã‚’æŒãŸã›ã‚‹ã€‚\n"
          "- çµæœã¯é€èªã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æƒ…å ±é‡ã‚’ä¿æŒã—ãŸã¾ã¾è¨˜äº‹èª¿ã«æ•´ãˆã‚‹ã“ã¨ã€‚\n"
    )

    client = openai_mod.OpenAI(api_key=api_key) if hasattr(openai_mod, "OpenAI") else None
    try:
        if client:
            resp = client.chat.completions.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "system", "content": sys_prompt},
                          {"role": "user", "content": user_prompt}],
                temperature=0.15,
            )
            return "ã€AIæ•´å½¢ï¼ˆç›´è¨³â†’è¨˜äº‹èª¿ï¼‰ã€‘\n" + resp.choices[0].message.content
        else:
            openai_mod.api_key = api_key
            resp = openai_mod.ChatCompletion.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "system", "content": sys_prompt},
                          {"role": "user", "content": user_prompt}],
                temperature=0.15,
            )
            return "ã€AIæ•´å½¢ï¼ˆç›´è¨³â†’è¨˜äº‹èª¿ï¼‰ã€‘\n" + resp["choices"][0]["message"]["content"]
    except Exception as e:
        return f"[LLMã‚¨ãƒ©ãƒ¼] {e}"

# ========== DOCX å‡ºåŠ› ==========
def make_docx(title: str, content: str) -> bytes:
    doc = Document()
    style = doc.styles['Normal']
    font = style.font
    font.name = 'Yu Gothic'
    font.size = Pt(11)

    doc.add_heading(title or "å‡ºåŠ›", level=1)
    for line in content.splitlines():
        if line.strip() == "":
            doc.add_paragraph("")
        else:
            doc.add_paragraph(line)

    buf = io.BytesIO()
    doc.save(buf)
    buf.seek(0)
    return buf.read()

# ========== Streamlit UI ==========
def main():
    st.set_page_config(page_title="InsighTCROSSÂ® Smart Writer v11", layout="wide")

    # 1) ãƒ­ã‚°ã‚¤ãƒ³ï¼†APIã‚­ãƒ¼å…¥åŠ›ï¼ˆæ¯å›ï¼‰
    api_key = require_login_and_api()  # â† ã“ã“ã§æ¯å›ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ï¼†APIã‚­ãƒ¼ã‚’å…¥åŠ›
    st.session_state["api_key"] = api_key  # æ¥ç¶šãƒ†ã‚¹ãƒˆç”¨ã«ä¿æŒ

    # ä½œæ¥­ãƒ•ã‚©ãƒ«ãƒ€
    if "workdir" not in st.session_state:
        st.session_state["workdir"] = os.path.abspath("./.work")
        os.makedirs(st.session_state["workdir"], exist_ok=True)

    # ã‚¿ã‚¤ãƒˆãƒ«ç­‰
    st.title("InsighTCROSSÂ® Smart Writer v11")
    if "transcript_text" not in st.session_state:
        st.session_state["transcript_text"] = ""
    if "generated_text" not in st.session_state:
        st.session_state["generated_text"] = ""
    st.write("éŸ³å£°/å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€é€èªãƒ»ç›´è¨³ãƒ»è­°äº‹éŒ²ãƒ»è¦æ—¨ãƒ»è¨˜äº‹ã«æ•´å½¢ã€‚å‹•ç”»ã¯ã‚¹ãƒ©ã‚¤ãƒ‰OCRä½µç”¨ã‚‚å¯èƒ½ã€‚")

    # ===== ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š =====
    with st.sidebar:
        st.header("è¨­å®š")
        file_type = st.radio("ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—", ["è‡ªå‹•åˆ¤å®š", "éŸ³å£°", "å‹•ç”»"], index=0, key="filetype")
        use_slide_ocr = st.toggle(
            "ã‚¹ãƒ©ã‚¤ãƒ‰OCRã‚‚ä½µç”¨ï¼ˆå‹•ç”»æ™‚ï¼‰", value=False,
            help="ã‚¹ãƒ©ã‚¤ãƒ‰ã®ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã—OCRã§æ–‡å­—ã‚‚å–ã‚Šè¾¼ã¿ã¾ã™ï¼ˆä¾å­˜ãŒç„¡ã‘ã‚Œã°ç©ºã§ç¶™ç¶šï¼‰",
            key="toggle_ocr"
        )
        scene_sensitivity = st.slider("ã‚·ãƒ¼ãƒ³å¤‰åŒ–æ„Ÿåº¦", 0.10, 0.60, 0.35, 0.01, key="scene_thr")

        # å‡ºåŠ›è¨€èª
        output_lang_label = st.selectbox("å‡ºåŠ›è¨€èª", ["æ—¥æœ¬èª (JPN)", "English (EN)"], index=0, key="out_lang")
        output_lang = "ja" if "JPN" in output_lang_label else "en"

        # ç”Ÿæˆå½¢å¼
        out_kind = st.selectbox(
            "å‡ºåŠ›ã‚¿ã‚¤ãƒ—",
            ["é€èª(ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—)", "ç›´è¨³ï¼ˆæ—¥æœ¬èªåŒ–ã®ã¿ï¼‰", "è­°äº‹éŒ²", "è¦æ—¨", "è¨˜äº‹", "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬"],
            key="out_kind"
        )
        purpose = st.selectbox("è¨˜äº‹åŒ–ã®ç›®çš„", ["å­¦ä¼šç™ºè¡¨", "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬", "ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³"], index=0, key="purpose")
        attach_verbatim = st.toggle(
            "æœ«å°¾ã«é€èªåŸæ–‡ã‚’æ·»ä»˜", value=False,
            help="åŸæ–‡è¨€èªã®é€èªãƒ†ã‚­ã‚¹ãƒˆã‚’æœ«å°¾ã«ä»˜ã‘ã¾ã™ï¼ˆé€šå¸¸ã¯OFFæ¨å¥¨ï¼‰",
            key="attach_verbatim"
        )

        # LLMæ•´å½¢ã®ON/OFFï¼ˆAPIã‚­ãƒ¼ã¯ require_login_and_api ã§å—ã‘å–ã‚Šæ¸ˆã¿ï¼‰
        use_llm = st.toggle("ç”ŸæˆAIã§æ•´å½¢ï¼ˆä»»æ„ï¼‰", value=False, key="use_llm")

        # éŸ³å£°ã®è¨€èªï¼ˆWhisperã¸ã®æŒ‡ç¤ºï¼‰
        speech_lang_label = st.selectbox("éŸ³å£°è¨€èªï¼ˆWhisperï¼‰", ["è‹±èª", "æ—¥æœ¬èª", "è‡ªå‹•"], index=0, key="speech_lang")
        _lang_map = {"è‹±èª": "en", "æ—¥æœ¬èª": "ja", "è‡ªå‹•": None}
        forced_lang = _lang_map[speech_lang_label]

        # ---- æ¥ç¶šãƒ†ã‚¹ãƒˆ ----
        st.divider()
        st.markdown("### æ¥ç¶šãƒ†ã‚¹ãƒˆ")
        if st.button("ğŸ” OpenAI æ¥ç¶šãƒ†ã‚¹ãƒˆ", key="btn_ping"):
            key = (st.session_state.get("api_key") or "").strip()
            if not key:
                st.error("å…ˆã« APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            else:
                try:
                    c = get_openai_client(key)
                    _ = c.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[{"role": "user", "content": "ping"}],
                        max_tokens=5,
                        temperature=0.0,
                    )
                    st.success("OK: OpenAI ã¸åˆ°é”ã§ãã¾ã—ãŸã€‚")
                except Exception as e:
                    st.error(
                        "NG: OpenAI ã¸æ¥ç¶š/èªè¨¼ã§ãã¾ã›ã‚“ã€‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ or APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n\n"
                        f"è©³ç´°: {e}"
                    )

        # ---- 10ç§’ã‚µãƒ³ãƒ—ãƒ«ã§è»¢å†™ãƒ†ã‚¹ãƒˆï¼ˆä»»æ„ï¼‰----
        st.markdown("### è»¢å†™ãƒŸãƒ‹è¨ºæ–­")
        test_wav = "/mount/src/sample_10s.wav"
        if not os.path.exists(test_wav):
            st.caption(f"ã‚µãƒ³ãƒ—ãƒ«éŸ³å£°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {test_wav}ï¼ˆä»»æ„ã€‚ç½®ã‘ã°ãƒ†ã‚¹ãƒˆã§ãã¾ã™ï¼‰")
        if st.button("ğŸ” 10ç§’ã‚µãƒ³ãƒ—ãƒ«ã§è»¢å†™ãƒ†ã‚¹ãƒˆ", key="btn_sample_transcribe"):
            if not os.path.exists(test_wav):
                st.error(f"ã‚µãƒ³ãƒ—ãƒ«éŸ³å£°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {test_wav}")
            else:
                try:
                    segs, lang = transcribe_openai(
                        test_wav,
                        api_key=api_key,
                        forced_lang="ja"
                    )
                    st.success(f"Sample OK. lang={lang}")
                    st.write(segs[0]["text"][:500])
                except Exception as e:
                    st.error(f"Sample failed: {e}")

    # ===== ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ =====
    uploaded = st.file_uploader(
        "éŸ³å£°/å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (mp3, m4a, wav, mp4, mov ãªã©)",
        type=["mp3","m4a","wav","mp4","mov","mkv","aac","flac"],
        key="uploader"
    )
    if not uploaded:
        return

    st.info(f"å—ä¿¡: {uploaded.name} / {uploaded.size/1024:.1f} KB")
    temp_path = save_uploaded_file_to_temp(uploaded)
    guessed = (uploaded.type or mimetypes.guess_type(uploaded.name)[0] or "")
    is_video = (st.session_state["filetype"] == "å‹•ç”»") or (st.session_state["filetype"] == "è‡ªå‹•åˆ¤å®š" and guessed.startswith("video/"))

    # å¤‰æ› â†’ WAV 16kHz mono
    with st.spinner("å¤‰æ›ä¸­ï¼ˆWAV 16kHz monoï¼‰..."):
        wav_path = ensure_wav(temp_path)

    # æ–‡å­—èµ·ã“ã—ï¼š50MBã¾ã§ç›´æ¥ã€‚è¶…éã¯è‡ªå‹•ã§åˆ†å‰²
    with st.spinner("ğŸ§  OpenAIã§æ–‡å­—èµ·ã“ã—ä¸­â€¦"):
        upload_path, up_mb, how = shrink_audio_for_upload(wav_path, target_mb=50.0)
        if how != "too_large":
            # ãã®ã¾ã¾ï¼ˆor mp3åŒ–ï¼‰ã§1ç™ºè»¢å†™
            segments, detected_lang = transcribe_openai(
                upload_path, api_key, forced_lang=forced_lang
            )
        else:
            # >50MB â†’ åˆ†å‰²ã—ã¦é€£çµ
            st.warning(f"éŸ³å£°ãŒ {up_mb:.1f}MB ã¨å¤§ãã„ãŸã‚ã€10åˆ†åˆ»ã¿ã«åˆ†å‰²ã—ã¦ã‹ã‚‰è»¢å†™ã—ã¾ã™ã€‚")
            parts = chunk_wav_by_time(wav_path, chunk_sec=600)  # 10åˆ†
            segments, detected_lang = [], (forced_lang or "auto")
            offset = 0.0
            for i, p in enumerate(parts, start=1):
                st.caption(f"Part {i}/{len(parts)} ã‚’è»¢å†™ä¸­â€¦")
                segs_i, lang_i = transcribe_openai(p, api_key, forced_lang=forced_lang)
                try:
                    d_sec = AudioSegment.from_file(p).duration_seconds
                except Exception:
                    d_sec = 0.0
                txt = " ".join(s.get("text","") for s in segs_i)
                segments.append({"start": offset, "end": offset + d_sec, "text": txt})
                offset += d_sec

    st.success(f"æ–‡å­—èµ·ã“ã—å®Œäº†ã€‚ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(segments)} / è¨€èªæ¤œå‡º: {detected_lang}")

    # é€èªï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰åŸç¨¿ï¼ˆç°¡æ˜“ï¼š1ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆæˆå‰æï¼‰
    # åˆ†å‰²è»¢å†™æ™‚ã¯ä¸Šã§start/endã‚’è©°ã‚ã¦ã„ã‚‹ã®ã§åŒºåˆ‡ã‚ŠãŒå‡ºã¾ã™
    def _to_triplets(segs_dicts):
        trips = []
        for s in segs_dicts:
            trips.append((s.get("text",""), float(s.get("start", 0.0)), float(s.get("end", 0.0))))
        return trips

    segments_triplets: List[Tuple[str, float, float]] = _to_triplets(segments)
    verbatim_text = to_verbatim_with_timestamps(segments_triplets)
    st.session_state["transcript_text"] = verbatim_text

    st.subheader("âœï¸ é€èªãƒ†ã‚­ã‚¹ãƒˆï¼ˆç·¨é›†å¯ï¼‰")
    st.session_state["transcript_text"] = st.text_area(
        "é€èªï¼ˆå¿…è¦ã«å¿œã˜ã¦ä¿®æ­£ã—ã¦ãã ã•ã„ï¼‰",
        value=st.session_state["transcript_text"],
        height=300,
        key="verbatim_editor"
    )

    # ã‚¹ãƒ©ã‚¤ãƒ‰OCRï¼ˆä»»æ„ï¼‰
    slide_groups, slide_notes, slide_digest = [], [], ""
    if is_video and st.session_state["toggle_ocr"]:
        with st.spinner("ã‚¹ãƒ©ã‚¤ãƒ‰æŠ½å‡ºï¼ˆã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ +æ™‚åˆ»ï¼‰â†’ OCR ä¸­..."):
            frames, slide_times = extract_slide_keyframes_with_times(
                video_path=temp_path,
                out_dir=os.path.join(st.session_state["workdir"], "slides"),
                scene_thr=st.session_state["scene_thr"],
            )

            st.write(f"æŠ½å‡ºãƒ•ãƒ¬ãƒ¼ãƒ æšæ•°: {len(frames)} / åˆ‡æ›¿æ¤œå‡º: {len(slide_times)}")
            if frames:
                st.write("å…ˆé ­3æšã®ãƒ‘ã‚¹:", frames[:3])
                try:
                    st.image(frames[0], caption="ã‚¹ãƒ©ã‚¤ãƒ‰æŠ½å‡ºãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå…ˆé ­ï¼‰", use_container_width=True)
                except Exception as e:
                    st.warning(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºã«å¤±æ•—: {e}")
            else:
                st.warning("æŠ½å‡ºã•ã‚ŒãŸç”»åƒãŒ0æšã§ã™ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒåŠ¹ã„ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

            slide_notes = ocr_slides(frames)
            slide_groups = group_segments_by_slides(segments_triplets, slide_times)
            slide_digest = "\n\n".join(
                [f"[Slide {s['index']}]\n{s.get('text','')}" for s in slide_notes if s.get('text','').strip()]
            )
        st.success(f"ã‚¹ãƒ©ã‚¤ãƒ‰æŠ½å‡º: {len(slide_notes)} æš / åˆ‡æ›¿: {len(slide_times)} ç‚¹")

    edited_transcript = st.session_state["transcript_text"]
    cleaned_for_llm = strip_timestamps(edited_transcript)

    if st.session_state["out_kind"] == "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬" and slide_groups:
        chunks = []
        for g in slide_groups:
            idx = g["index"]
            ocr_text = ""
            for s in (slide_notes or []):
                if s.get("index") == idx:
                    ocr_text = (s.get("text") or "").strip()
                    break
            speech_text = "\n".join([t for (t, _, _) in g["segments"]])
            chunks.append(
                f"[Slide {idx} {format_timestamp(g['start'])}â€“{fmt_ts(g['end'])}]\n"
                f"<OCR>\n{ocr_text}\n</OCR>\n<SPEECH>\n{speech_text}\n</SPEECH>"
            )
        llm_source = "ã€ã‚¹ãƒ©ã‚¤ãƒ‰åˆ¥ç´ æã€‘\n" + "\n\n".join(chunks)
    else:
        llm_source = cleaned_for_llm if not slide_digest else (
            f"ã€éŸ³å£°é€èªã€‘\n{cleaned_for_llm}\n\nã€ã‚¹ãƒ©ã‚¤ãƒ‰OCRã€‘\n{slide_digest}"
        )

    # æ—¢å®šï¼ˆãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ï¼‰å‡ºåŠ›
    out_kind = st.session_state["out_kind"]
    if out_kind == "é€èª(ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—)":
        base_out = to_verbatim_with_timestamps(segments_triplets); kind_key = "verbatim"
    elif out_kind == "è­°äº‹éŒ²":
        base_out = heuristic_minutes(segments_triplets); kind_key = "minutes"
    elif out_kind == "è¦æ—¨":
        base_out = heuristic_abstract(segments_triplets); kind_key = "abstract"
    elif out_kind == "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬":
        base_out = heuristic_guideline_commentary(slide_groups, slide_notes) if slide_groups else \
                   "ã€ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬ï¼ˆç°¡æ˜“ï¼‰ã€‘\n" + heuristic_article_academic(segments_triplets)
        kind_key = "article"
    else:
        base_out = heuristic_article_academic(segments_triplets); kind_key = "article"

    final_out = base_out

    # ----- ç”ŸæˆAIã§æ•´å½¢ -----
    st.markdown("---")
    st.subheader("ğŸ§  ç”ŸæˆAIã§æ•´å½¢ã™ã‚‹")
    label_lang = "æ—¥æœ¬èª" if output_lang == "ja" else "English"

    auto_generate = st.session_state["use_llm"]
    clicked = st.button(f"âœ¨ ç”ŸæˆAIã§æ•´å½¢ï¼ˆ{label_lang}ã§å‡ºåŠ›ï¼‰", key="btn_gen")
    do_generate = auto_generate or clicked

    if not do_generate:
        st.text_area("çµæœãƒ†ã‚­ã‚¹ãƒˆ", value=final_out or "", height=400, key="no_gen_area")
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã ã‘ã¯æä¾›
        st.download_button("TXTãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=final_out.encode("utf-8"), file_name="output.txt", key="dl_txt_nogen")
        docx_bytes = make_docx(title=f"{out_kind}ï¼ˆ{purpose}ï¼‰", content=final_out)
        st.download_button("DOCXãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=docx_bytes, file_name="output.docx", key="dl_docx_nogen")
        return

    # æŠ¼ä¸‹å¾Œ
    if not st.session_state["use_llm"]:
        st.info("ç”ŸæˆAIãŒOFFã®ãŸã‚ã€ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯æ•´å½¢ã®çµæœã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
        st.text_area("çµæœãƒ†ã‚­ã‚¹ãƒˆ", value=final_out or "", height=400, key="gen_off_area")
        st.download_button("TXTãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=final_out.encode("utf-8"), file_name="output.txt", key="dl_txt_off")
        docx_bytes = make_docx(title=f"{out_kind}ï¼ˆ{purpose}ï¼‰", content=final_out)
        st.download_button("DOCXãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=docx_bytes, file_name="output.docx", key="dl_docx_off")
        return

    if not api_key:
        st.error("ç”ŸæˆAIã®æ•´å½¢ã«ã¯ OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã§å…¥åŠ›ï¼‰ã€‚")
        st.stop()

    st.session_state.pop("ja_literal_for_article", None)

    final_out = base_out
    try:
        if out_kind == "é€èª(ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—)":
            with st.spinner("ç”ŸæˆAIã§æ•´å½¢ä¸­..."):
                final_out = llm_rewrite(
                    kind="verbatim",
                    text="ã€å‡ºåŠ›ã¯å¿…ãšæ—¥æœ¬èªã€‘\n" + st.session_state["transcript_text"],
                    api_key=api_key,
                    purpose=purpose,
                    source_lang=detected_lang,
                    target_lang=output_lang,
                )
        elif out_kind == "ç›´è¨³ï¼ˆæ—¥æœ¬èªåŒ–ã®ã¿ï¼‰":
            with st.spinner("ç›´è¨³ä¸­..."):
                final_out = llm_translate_only(
                    text=cleaned_for_llm,
                    api_key=api_key,
                    source_lang=detected_lang,
                    target_lang="ja",
                )
        else:
            if out_kind == "è¨˜äº‹" and (output_lang == "ja"):
                with st.spinner("è‹±èªâ†’æ—¥æœ¬èª ç›´è¨³ â†’ è¨˜äº‹èª¿ ã¸æ•´å½¢ä¸­..."):
                    ja_literal_for_article = llm_translate_only(
                        text=cleaned_for_llm,
                        api_key=api_key,
                        source_lang=detected_lang,
                        target_lang="ja",
                    )
                    final_out = llm_article_from_literal(
                        literal_ja=ja_literal_for_article,
                        api_key=api_key,
                        purpose=purpose,
                    )
                    st.caption("route: ARTICLE_FROM_LITERAL (ja) âœ“ ç›´è¨³â†’è¨˜äº‹èª¿ãƒ«ãƒ¼ãƒˆã‚’é€šé")
                    st.session_state["ja_literal_for_article"] = ja_literal_for_article
            else:
                llm_kind_call = {"è­°äº‹éŒ²": "minutes", "è¦æ—¨": "abstract"}.get(out_kind, "article")
                parts = split_text_by_chars(llm_source, chunk_size=6000, overlap=300)
                outs = []
                N = len(parts)
                for i, part in enumerate(parts, start=1):
                    meta = (
                        f"ã€åˆ†å‰²ãƒ‘ãƒ¼ãƒˆ {i}/{N}ã€‘\n"
                        "ã“ã®ãƒ‘ãƒ¼ãƒˆã§ã¯æ–°è¦æƒ…å ±ã®ã¿ã‚’åæ˜ ã—ã€æ—¢å‡ºã®è¦‹å‡ºã—ã‚„å°å…¥ã¯å†æ²ã—ãªã„ã§ãã ã•ã„ã€‚"
                    )
                    out_i = llm_rewrite(
                        kind=llm_kind_call,
                        text="ã€å‡ºåŠ›ã¯å¿…ãšæ—¥æœ¬èªã€‘\n" + meta + "\n\n" + part,
                        api_key=api_key,
                        purpose=purpose,
                        source_lang=detected_lang,
                        target_lang=output_lang,
                    )
                    outs.append(out_i.strip())
                final_out = "\n\n".join(outs)
        st.success("ç”ŸæˆAIã§ã®æ•´å½¢ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        st.error(f"æ•´å½¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    # ===== ä¸‰æ®µè¡¨ç¤º =====
    st.subheader("ğŸ“ åŸæ–‡ï¼ˆå¤‰æ›´å‰ãƒ»è‹±èªï¼ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—é™¤å»ï¼‰")
    st.text_area("åŸæ–‡", value=cleaned_for_llm, height=260, key="orig_area")

    st.subheader("ğŸ‡¯ğŸ‡µ è‹±èªâ†’æ—¥æœ¬èªï¼ˆç›´è¨³ãƒ»æ•´å½¢ãªã—ï¼‰")
    if st.session_state["use_llm"] and api_key:
        cached_literal = st.session_state.get("ja_literal_for_article")
        if cached_literal:
            ja_literal = cached_literal
        else:
            with st.spinner("è‹±èªâ†’æ—¥æœ¬èª ç›´è¨³ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ï¼‰..."):
                ja_literal = llm_translate_only(
                    text=cleaned_for_llm,
                    api_key=api_key,
                    source_lang=detected_lang,
                    target_lang="ja",
                )
        st.text_area("ç›´è¨³", value=ja_literal, height=260, key="literal_area")
    else:
        st.text_area("ç›´è¨³", value="(ç”ŸæˆAIãŒOFFã¾ãŸã¯APIã‚­ãƒ¼æœªå…¥åŠ›ã®ãŸã‚ç›´è¨³ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“)", height=260, key="literal_off")

    st.subheader("ğŸ“„ æ•´å½¢çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    if out_kind == "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬" and output_lang == "ja" and final_out:
        for _p in ["èƒŒæ™¯", "æ”¹è¨‚ãƒã‚¤ãƒ³ãƒˆ", "æ¨å¥¨åº¦ãƒ»ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹", "è‡¨åºŠã¸ã®å½±éŸ¿", "èª²é¡Œ", "ä»Šå¾Œ"]:
            final_out = re.sub(rf"(#+\s*{_p}\s*\n)(\s*\1)+", r"\1", final_out)
    st.text_area("æ•´å½¢çµæœ", value=final_out, height=380, key="final_area")

    st.download_button("TXTãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=final_out.encode("utf-8"), file_name="output.txt", key="dl_txt")
    docx_bytes = make_docx(title=f"{out_kind}ï¼ˆ{purpose}ï¼‰", content=final_out)
    st.download_button("DOCXãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=docx_bytes, file_name="output.docx", key="dl_docx")

if __name__ == "__main__":
    main()

