# transcribe_editor_v11.py
# -------------------------------------------------------------
# æ©Ÿèƒ½:
# 1) éŸ³å£°/å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ â†’ OpenAIã§æ–‡å­—èµ·ã“ã—
# 2) å‡ºåŠ›é¸æŠ: é€èª(ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—) / ç›´è¨³ï¼ˆæ—¥æœ¬èªåŒ–ã®ã¿ï¼‰/ è­°äº‹éŒ² / è¦æ—¨ / è¨˜äº‹ / ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬
# 3) ç›®çš„é¸æŠ: å­¦ä¼šç™ºè¡¨ / ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬ / ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ï¼ˆLLMæ•´å½¢ã«åæ˜ ï¼‰
# 4) å‹•ç”»ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ã‚¹ãƒ©ã‚¤ãƒ‰OCR(ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º + OCR) ä½µç”¨ã®å¯å¦ï¼ˆä¾å­˜ãŒç„¡ã‘ã‚Œã°è‡ªå‹•ã§ã‚¹ã‚­ãƒƒãƒ—ï¼‰
# 5) TXT/DOCXã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½
# 6) ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§æ¯å›ã€Œå…±é€šãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã€ã¨ã€ŒOpenAI APIã‚­ãƒ¼ã€ã‚’å…¥åŠ›ï¼ˆSecretsä¸è¦ï¼‰
# -------------------------------------------------------------

import os
import io
import time
import glob
import shutil
import subprocess
import mimetypes
from datetime import timedelta
import re
from typing import List, Tuple, Dict, Any

import math
from pathlib import Path

import streamlit as st
from pydub import AudioSegment
from pydub.utils import which
from docx import Document
from docx.shared import Pt

# ï¼ˆLLMã®æ•´å½¢ã« chat.completions ã‚’ä½¿ã†ãŸã‚ã®äº’æ›ãƒãƒ³ãƒ‰ãƒ«ï¼‰
try:
    import openai as openai_mod  # pip install openai
except Exception:
    openai_mod = None

# EasyOCR ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã‚‚è½ã¡ãªã„ã‚ˆã†ã«ï¼‰
try:
    import easyocr  # pip install easyocr
except Exception:
    easyocr = None

# ç”»åƒç³»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯é…å»¶ãƒ»ä»»æ„ï¼ˆæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’è¨±å®¹ï¼‰
try:
    import numpy as np
    import cv2
    from PIL import Image
except Exception:
    np = None
    cv2 = None
    Image = None


from openai import OpenAI
# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å®‰å…¨ã«ç”Ÿæˆ
def get_openai_client(api_key: str) -> OpenAI:
    return OpenAI(api_key=api_key)

# ========== ãƒ©ãƒ³ã‚¿ã‚¤ãƒ å…±é€šã‚¹ãƒˆã‚¢ï¼ˆèµ·å‹•ä¸­ã®ã¿ä¿æŒã€‚æ¯å›ã®èµ·å‹•æ™‚ã«è¨­å®šã—ç›´ã—ï¼‰ ==========
@st.cache_resource(show_spinner=False)
def runtime_config():
    return {
        "common_password": None,   # åˆå›ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã§ç®¡ç†è€…ãŒè¨­å®š
        "default_api_key": None,   # ä»»æ„ï¼šæ—¢å®šã®APIã‚­ãƒ¼ã€‚æœªè¨­å®šãªã‚‰å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¯å›å…¥åŠ›
    }
# ========== ãƒ­ã‚°ã‚¤ãƒ³ï¼†APIã‚­ãƒ¼å–å¾—ï¼ˆæ¯å›ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§å…¥åŠ›ï¼‰ ==========
def require_login_and_api() -> str:
    cfg = runtime_config()

    with st.sidebar:
        st.header("ğŸ” ã‚¢ã‚¯ã‚»ã‚¹")

        # âš™ï¸ ç®¡ç†è€…ãƒªã‚»ãƒƒãƒˆï¼ˆä»»æ„ï¼‰
        with st.expander("âš™ï¸ ç®¡ç†è€…ãƒ¡ãƒ‹ãƒ¥ãƒ¼ï¼ˆãƒªã‚»ãƒƒãƒˆï¼‰"):
            reset_token = st.text_input("RESET ã¨å…¥åŠ›ã—ã¦æœ‰åŠ¹åŒ–", key="reset_token")
            if st.button("åˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’ã‚„ã‚Šç›´ã™"):
                if reset_token.strip().upper() != "RESET":
                    st.warning("RESET ã¨å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                else:
                    cfg["common_password"] = None
                    cfg["default_api_key"] = None
                    st.session_state.clear()
                    try:
                        st.rerun()
                    except Exception:
                        try:
                            st.experimental_rerun()
                        except Exception:
                            pass

        # â”€â”€ åˆå›ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼šå…±é€šãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã®ã¿è¨­å®šï¼ˆAPIã‚­ãƒ¼ã¯ä¿å­˜ã—ãªã„ï¼‰
        if not cfg["common_password"]:
            st.info("åˆå›ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼šå…±é€šãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã®ã¿è¨­å®šï¼ˆAPIã‚­ãƒ¼ã¯ä¿å­˜ã—ã¾ã›ã‚“ï¼‰")
            new_pw = st.text_input("å…±é€šãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ï¼ˆå¿…é ˆï¼‰", type="password")
            if st.button("ä¿å­˜"):
                if not new_pw:
                    st.error("å…±é€šãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¯å¿…é ˆã§ã™ã€‚")
                else:
                    cfg["common_password"] = new_pw
                    cfg["default_api_key"] = None
                    st.success("ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ã€‚ä»¥é™ã¯ã“ã®ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã§ãƒ­ã‚°ã‚¤ãƒ³ã§ãã¾ã™ã€‚")
                    try:
                        st.rerun()
                    except Exception:
                        try:
                            st.experimental_rerun()
                        except Exception:
                            pass
            st.stop()

        # â”€â”€ é€šå¸¸ãƒ­ã‚°ã‚¤ãƒ³ï¼šæ¯å› ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ï¼‹APIã‚­ãƒ¼ ã‚’å…¥åŠ›
        pw = st.text_input("å…±é€šãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›", type="password")
        user_key = st.text_input("OpenAI APIã‚­ãƒ¼ï¼ˆå¿…é ˆï¼‰", type="password")

        if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
            if pw != cfg["common_password"]:
                st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™ã€‚")
                st.stop()
            if not user_key.strip():
                st.error("OpenAI APIã‚­ãƒ¼ã¯å¿…é ˆã§ã™ã€‚")
                st.stop()
            st.session_state["auth_ok"] = True
            st.session_state["user_api_key"] = user_key.strip()
            try:
                st.rerun()
            except Exception:
                try:
                    st.experimental_rerun()
                except Exception:
                    pass

        if not st.session_state.get("auth_ok"):
            st.stop()

    api_key = st.session_state.get("user_api_key", "")
    if not api_key:
        st.error("OpenAI APIã‚­ãƒ¼ãŒæœªå…¥åŠ›ã§ã™ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    return api_key
# ========== OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç”Ÿæˆ ==========
def get_openai_client(api_key: str) -> OpenAI:
    base = os.environ.get("OPENAI_BASE_URL")  # Azureã‚’ä½¿ã†ãªã‚‰ç’°å¢ƒå¤‰æ•°ã§ãƒ™ãƒ¼ã‚¹URLã‚’æŒ‡å®š
    return OpenAI(api_key=api_key, base_url=base)


# ========== æ–‡å­—ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ==========
def split_text_by_chars(text: str, chunk_size: int = 6000, overlap: int = 300) -> list[str]:
    text = text.strip()
    if len(text) <= chunk_size:
        return [text]
    chunks = []
    start = 0
    while start < len(text):
        end = min(len(text), start + chunk_size)
        cut = end
        for p in ("ã€‚", "ï¼", "ï¼Ÿ", "\n"):
            idx = text.rfind(p, start, end)
            if idx != -1 and idx > start + 1000:
                cut = idx + 1
                break
        chunks.append(text[start:cut].strip())
        if cut >= len(text):
            break
        start = max(cut - overlap, 0)
    return [c for c in chunks if c]


def strip_timestamps(text: str) -> str:
    pattern = re.compile(
        r"^\s*\[\d{2}:\d{2}:\d{2}(?:\.\d{3})?\s*(?:â†’|->|-|ï¼|â€”)\s*\d{2}:\d{2}:\d{2}(?:\.\d{3})?\]\s*",
        re.MULTILINE,
    )
    return pattern.sub("", text).strip()


# ========== FFmpeg/ffprobe æ¤œå‡ºï¼ˆCloudã§ã¯ packages.txt: ffmpeg ã§OKï¼‰ ==========
PROJECT_DIR = Path(__file__).parent
FFBIN_CANDIDATES = [
    PROJECT_DIR / "ffmpeg-7.0.2-essentials_build" / "bin",
    Path(r"C:\\Users\\s-has\\Desktop\\å‹•ç”»éŸ³å£°åŸç¨¿ä½œæˆ082025\\ffmpeg-7.0.2-essentials_build\\bin"),
    Path(r"C:\\Users\\s-has\\Desktop\\ffmpeg-7.0.2-essentials_build\\bin"),
]

FFMPEG_EXE = None
FFPROBE_EXE = None
for _bin in FFBIN_CANDIDATES:
    ff = _bin / "ffmpeg.exe"
    fp = _bin / "ffprobe.exe"
    if ff.exists():
        FFMPEG_EXE, FFPROBE_EXE = ff, (fp if fp.exists() else None)
        os.environ["PATH"] = str(_bin) + os.pathsep + os.environ.get("PATH", "")
        os.environ["FFMPEG_BINARY"] = str(ff)
        os.environ["IMAGEIO_FFMPEG_EXE"] = str(ff)
        AudioSegment.converter = str(ff)
        AudioSegment.ffmpeg = str(ff)
        if FFPROBE_EXE:
            AudioSegment.ffprobe = str(FFPROBE_EXE)
        break
else:
    ffmpeg_found = which("ffmpeg")
    ffprobe_found = which("ffprobe")
    if ffmpeg_found:
        FFMPEG_EXE = Path(ffmpeg_found)
        AudioSegment.converter = ffmpeg_found
        AudioSegment.ffmpeg = ffmpeg_found
    if ffprobe_found:
        FFPROBE_EXE = Path(ffprobe_found)
        AudioSegment.ffprobe = ffprobe_found


# ========== I/O ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ==========
def save_uploaded_file_to_temp(uploaded_file) -> str:
    suffix = os.path.splitext(uploaded_file.name)[1]
    tmp_path = os.path.join(st.session_state["workdir"], f"upload_{int(time.time())}{suffix}")
    with open(tmp_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return tmp_path


def ensure_wav(input_path: str) -> str:
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ 16kHz/mono ã® WAV ã«å¤‰æ›ã€‚
       pydubâ†’å¤±æ•—æ™‚ã¯ ffmpeg CLI ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚"""
    wav_path = os.path.splitext(input_path)[0] + "_16k.wav"

    # 1) ã¾ãšã¯ pydub ã§æ™®é€šã«èª­ã‚€
    try:
        audio = AudioSegment.from_file(input_path)
        audio = audio.set_channels(1).set_frame_rate(16000)
        audio.export(wav_path, format="wav")
        return wav_path
    except Exception as e1:
        pass  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¸

    # 2) ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ffmpeg CLI ã§ â€œä¿®å¾©â†’éŸ³å£°æŠ½å‡ºâ€
    ff = shutil.which("ffmpeg") or "ffmpeg"

    # 2-1) moov ä½ç½®ã®å•é¡Œã‚’å›é¿ï¼ˆã‚³ãƒ”ãƒ¼ãƒªãƒãƒƒã‚¯ã‚¹ï¼‰
    fixed_mp4 = os.path.splitext(input_path)[0] + "_fixed.mp4"
    try:
        p1 = subprocess.run(
            [ff, "-y", "-v", "error", "-i", input_path, "-c", "copy", "-movflags", "+faststart", fixed_mp4],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding="utf-8", errors="ignore"
        )
        # ãƒªãƒãƒƒã‚¯ã‚¹ã«å¤±æ•—ã—ã¦ã‚‚ç¶šè¡Œï¼ˆå…ƒã‚’ä½¿ã†ï¼‰
        src_for_audio = fixed_mp4 if os.path.exists(fixed_mp4) and p1.returncode == 0 else input_path

        # 2-2) éŸ³å£°ã ã‘å–ã‚Šå‡ºã—ã¦ WAV åŒ–
        p2 = subprocess.run(
            [ff, "-y", "-v", "error", "-i", src_for_audio,
             "-vn", "-ac", "1", "-ar", "16000", "-map", "0:a:0?",
             "-c:a", "pcm_s16le", wav_path],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding="utf-8", errors="ignore"
        )
        if p2.returncode == 0 and os.path.exists(wav_path):
            return wav_path
        raise RuntimeError(p2.stderr or "ffmpeg failed")
    except Exception as e2:
        st.error(
            "éŸ³å£°/å‹•ç”»ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n"
            "ãƒ•ã‚¡ã‚¤ãƒ«ãŒå£Šã‚Œã¦ã„ã‚‹ã‹ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒé€”ä¸­ã§åˆ‡ã‚ŒãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n"
            "ï¼ˆå°ã•ã‚ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§å†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€ã‚ã‚‹ã„ã¯ mp3/m4a ã§ã®ã‚¢ãƒƒãƒ—ã‚’ãŠè©¦ã—ãã ã•ã„ï¼‰\n\n"
            f"è©³ç´°: {e2}"
        )
        st.stop()

    audio = audio.set_channels(1).set_frame_rate(16000)
    wav_path = os.path.splitext(input_path)[0] + "_16k.wav"
    audio.export(wav_path, format="wav")
    return wav_path


def format_timestamp(seconds: float) -> str:
    td = timedelta(seconds=float(seconds))
    total_seconds = int(td.total_seconds())
    ms = int((td.total_seconds() - total_seconds) * 1000)
    return f"{total_seconds//3600:02d}:{(total_seconds%3600)//60:02d}:{total_seconds%60:02d}.{ms:03d}"


def fmt_ts(x: float) -> str:
    return format_timestamp(x) if math.isfinite(x) else "â€¦"


# ========== OpenAI ã§æ–‡å­—èµ·ã“ã— ==========
# ========== OpenAI ã§æ–‡å­—èµ·ã“ã— ==========
def transcribe_openai(
    wav_path: str,
    api_key: str,
    forced_lang: str | None = None
) -> tuple[list[tuple[str, float, float]], str | None]:
    """OpenAIã§æ–‡å­—èµ·ã“ã—ã€‚å¯èƒ½ãªã‚‰ã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼ˆé–‹å§‹/çµ‚äº†ï¼‰ã‚‚è¿”ã™ã€‚"""
    # å…¬å¼ã® OpenAI ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’æ˜ç¤ºï¼ˆç’°å¢ƒå¤‰æ•°ã®å½±éŸ¿ã‚’å—ã‘ãªã„ï¼‰
    client = OpenAI(api_key=api_key, base_url="https://api.openai.com/v1")

    # ãƒ¢ãƒ‡ãƒ«ã¯ç’°å¢ƒå¤‰æ•°ã§ä¸Šæ›¸ãå¯ã€‚æœªæŒ‡å®šã¯ whisper-1
    candidates = [os.environ.get("OPENAI_TRANSCRIBE_MODEL") or "", "whisper-1"]
    candidates = [m for m in candidates if m]

    last_err = None
    with open(wav_path, "rb") as f:
        # 1) verbose_json ã§ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå–å¾—ã‚’è©¦ã™
        for m in candidates:
            try:
                f.seek(0)
                kwargs = {
                    "model": m,
                    "file": f,
                    "response_format": "verbose_json",
                }
                # â˜… è¨€èªã‚’å¼·åˆ¶æŒ‡å®šï¼ˆè‹±èª/æ—¥æœ¬èª/è‡ªå‹•ï¼‰
                if forced_lang:
                    kwargs["language"] = forced_lang

                resp = client.audio.transcriptions.create(**kwargs)

                text = getattr(resp, "text", "") or ""
                segs = []
                seg_attr = getattr(resp, "segments", None)
                if seg_attr:
                    for s in seg_attr:
                        if isinstance(s, dict):
                            t = (s.get("text") or "").strip()
                            stt = float(s.get("start", 0.0) or 0.0)
                            endt = float(s.get("end", 0.0) or 0.0)
                        else:
                            t = (getattr(s, "text", "") or "").strip()
                            stt = float(getattr(s, "start", 0.0) or 0.0)
                            endt = float(getattr(s, "end", 0.0) or 0.0)
                        segs.append((t, stt, endt))
                else:
                    segs = [(text, float("nan"), float("nan"))]

                # è¡¨ç¤ºç”¨ã®æ¤œå‡ºè¨€èªã€‚å¼·åˆ¶ã—ãŸå ´åˆã¯ãã®ã‚³ãƒ¼ãƒ‰ã‚’æ¡ç”¨
                detected = forced_lang or getattr(resp, "language", None)
                return segs, detected
            except Exception as e:
                last_err = e

        # 2) ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ†ã‚­ã‚¹ãƒˆã®ã¿
        try:
            f.seek(0)
            fallback_model = candidates[-1] if candidates else "whisper-1"
            kwargs = {"model": fallback_model, "file": f}
            if forced_lang:
                kwargs["language"] = forced_lang
            resp = client.audio.transcriptions.create(**kwargs)
            text = getattr(resp, "text", "") or ""
            return [(text, float("nan"), float("nan"))], forced_lang or None
        except Exception as e:
            raise RuntimeError(f"Transcription failed: {last_err or e}")

# ========== ã‚¹ãƒ©ã‚¤ãƒ‰ã¨ç™ºè©±ã®å¯¾å¿œä»˜ã‘ ==========
def group_segments_by_slides(
    segments: List[Tuple[str, float, float]],
    slide_change_times: List[float]
) -> List[Dict[str, Any]]:
    last_end = max((e for _, _, e in segments), default=0.0)
    bounds = [0.0] + [t for t in slide_change_times if t < last_end] + [last_end]
    grouped = []
    for i in range(len(bounds)-1):
        start, end = bounds[i], bounds[i+1]
        bucket = []
        for t, s, e in segments:
            if e > start and s < end:
                bucket.append((t, max(s, start), min(e, end)))
        grouped.append({"index": i+1, "start": start, "end": end, "segments": bucket})
    return grouped

# ========== ã‚¹ãƒ©ã‚¤ãƒ‰æŠ½å‡º & OCR ==========
def extract_slide_keyframes_with_times(video_path: str, out_dir: str, scene_thr: float=0.35) -> tuple[list[str], list[float]]:
    os.makedirs(out_dir, exist_ok=True)
    for p in glob.glob(os.path.join(out_dir, "*.jpg")):
        try:
            os.remove(p)
        except:
            pass

    ff_cmd = str(FFMPEG_EXE) if FFMPEG_EXE else (shutil.which("ffmpeg") or "ffmpeg")

    # 1) ã‚·ãƒ¼ãƒ³å¤‰åŒ–æŠ½å‡º
    cmd = [
        ff_cmd, "-y", "-i", video_path,
        "-vf", f"select='gt(scene,{scene_thr})',showinfo",
        "-vsync", "vfr",
        os.path.join(out_dir, "%04d.jpg"),
    ]
    proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding="utf-8", errors="ignore")
    stderr = proc.stderr or ""

    times = []
    for m in re.finditer(r"pts_time:([0-9]+\.[0-9]+)", stderr):
        try:
            times.append(float(m.group(1)))
        except:
            pass

    image_paths = sorted(glob.glob(os.path.join(out_dir, "*.jpg")))
    n = min(len(image_paths), len(times))
    if n > 0:
        return image_paths[:n], times[:n]

    # 2) ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼š3ç§’é–“éš”ã§æŠ½å‡º
    for p in glob.glob(os.path.join(out_dir, "*.jpg")):
        try: os.remove(p)
        except: pass
    cmd_fb = [
        ff_cmd, "-y", "-i", video_path,
        "-vf", "fps=1/3,showinfo",
        "-vsync", "vfr",
        os.path.join(out_dir, "%04d.jpg"),
    ]
    subprocess.run(cmd_fb, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding="utf-8", errors="ignore")

    image_paths = sorted(glob.glob(os.path.join(out_dir, "*.jpg")))
    if image_paths:
        approx_times = [i * 3.0 for i in range(len(image_paths))]
        return image_paths, approx_times

    # 3) ãã‚Œã§ã‚‚0ãªã‚‰å…ˆé ­1æšã ã‘ç¢ºä¿
    one_path = os.path.join(out_dir, "0001.jpg")
    subprocess.run([ff_cmd, "-y", "-ss", "00:00:01", "-i", video_path, "-vframes", "1", one_path],
                   stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding="utf-8", errors="ignore")
    image_paths = sorted(glob.glob(os.path.join(out_dir, "*.jpg")))
    if image_paths:
        return image_paths, [0.0]

    return [], []


def _to_cv2_bgr(image_like):
    # ç”»åƒç³»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒç„¡ã‘ã‚Œã°OCRã¯ã‚¹ã‚­ãƒƒãƒ—
    if (cv2 is None) or (np is None) or (Image is None):
        return None
    try:
        if isinstance(image_like, (bytes, bytearray)):
            arr = np.frombuffer(image_like, np.uint8)
            img = cv2.imdecode(arr, cv2.IMREAD_COLOR)
            return img
        if isinstance(image_like, str):
            img = cv2.imread(image_like, cv2.IMREAD_COLOR)
            if img is None:
                try:
                    pil = Image.open(image_like).convert("RGB")
                    return cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)
                except Exception:
                    return None
            return img
        if isinstance(image_like, Image.Image):
            return cv2.cvtColor(np.array(image_like), cv2.COLOR_RGB2BGR)
        if isinstance(image_like, np.ndarray):
            if image_like.ndim == 2:
                return cv2.cvtColor(image_like, cv2.COLOR_GRAY2BGR)
            return image_like
    except Exception:
        return None
    return None


def _get_reader():
    """EasyOCR Reader ã‚’ï¼ˆã‚ã‚Œã°ï¼‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ä½¿ã„å›ã—ã€‚"""
    if easyocr is None:
        return None
    @st.cache_resource(show_spinner=False)
    def _cached_reader():
        return easyocr.Reader(['ja', 'en'], gpu=False)
    return _cached_reader()


def ocr_slides(image_paths: list) -> list[dict]:
    """
    image_paths: ç”»åƒãƒ‘ã‚¹/bytes/PIL/ndarray ãŒæ··åœ¨ã—ã¦ã„ã¦ã‚‚OK
    return: [{"index": i, "path": å…ƒã®å‚ç…§, "text": èªè­˜æ–‡å­—åˆ—}, ...]
    """
    if not image_paths:
        return []

    if easyocr is None or (cv2 is None) or (np is None) or (Image is None):
        # ä¾å­˜ãŒãªã‘ã‚Œã°ç©ºæ–‡å­—ã§è¿”ã™ï¼ˆã‚¢ãƒ—ãƒªã¯ç¶™ç¶šï¼‰
        return [{"index": i+1, "path": p, "text": ""} for i, p in enumerate(image_paths)]

    reader = _get_reader()
    results = []
    valid_found = False

    for idx, src in enumerate(image_paths, start=1):
        img = _to_cv2_bgr(src)
        if img is None or getattr(img, "size", 0) == 0:
            results.append({"index": idx, "path": src, "text": ""})
            continue

        valid_found = True
        try:
            lines = reader.readtext(img, detail=0)
            text = "\n".join(lines) if lines else ""
            results.append({"index": idx, "path": src, "text": text})
        except Exception:
            results.append({"index": idx, "path": src, "text": ""})

    if not valid_found:
        st.error("OCRç”¨ã®ç”»åƒã‚’æ­£ã—ãèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸï¼ˆãƒ‘ã‚¹ãƒ»å½¢å¼ãƒ»æŠ½å‡ºå‡¦ç†ã‚’ã”ç¢ºèªãã ã•ã„ï¼‰ã€‚")

    return results


# ========== æ•´å½¢(ç”ŸæˆAIãªã—) ==========
def to_verbatim_with_timestamps(segments: List[Tuple[str, float, float]]) -> str:
    lines: List[str] = []
    for t, s, e in segments:
        start_disp = format_timestamp(s) if math.isfinite(s) else "â€¦"
        end_disp   = format_timestamp(e) if math.isfinite(e) else "â€¦"
        lines.append(f"[{start_disp} â†’ {end_disp}] {t}")
    return "\n".join(lines)


def heuristic_minutes(segments: List[Tuple[str, float, float]]) -> str:
    block, blocks, char_limit = [], [], 300
    for t, s, e in segments:
        if sum(len(x[0]) for x in block) + len(t) > char_limit and block:
            blocks.append(block); block = []
        block.append((t, s, e))
    if block: blocks.append(block)
    out = ["ã€è­°äº‹éŒ²ï¼ˆè‡ªå‹•æ•´å½¢ãƒ»è¦ç‚¹ï¼‰ã€‘\n"]
    for i, b in enumerate(blocks, 1):
        out.append(f"â–  ãƒˆãƒ”ãƒƒã‚¯{i}ï¼ˆ{format_timestamp(b[0][1])}â€“{format_timestamp(b[-1][2])}ï¼‰")
        for t, _, _ in b: out.append(f"ãƒ»{t}")
        out.append("")
    return "\n".join(out).strip()


def heuristic_abstract(segments: List[Tuple[str, float, float]]) -> str:
    text = " ".join(t for t, _, _ in segments)
    sentences = [s.strip() for s in text.replace("ã€‚", "ã€‚\n").splitlines() if s.strip()]
    return "ã€è¦æ—¨ï¼ˆè‡ªå‹•æŠ½å‡ºï¼‰ã€‘\n" + "\n".join(sentences[:6])


def heuristic_article_academic(segments: List[Tuple[str, float, float]]) -> str:
    body = " ".join(t for t, _, _ in segments)
    lines = [
        "ã€å­¦ä¼šå ±å‘Šè¨˜äº‹ï¼ˆè‡ªå‹•æ•´å½¢ãƒ»AIä¸ä½¿ç”¨ï¼‰ã€‘",
        "",
        "â–  ãƒªãƒ¼ãƒ‰",
        "æœ¬è¬›æ¼”ã§ã¯ã€æ¼”è€…ãŒæç¤ºã—ãŸä¸»è¦ãƒã‚¤ãƒ³ãƒˆã‚’æŠœç²‹ã—ã€å†…å®¹ã‚’ç°¡æ½”ã«æ•´ç†ã™ã‚‹ã€‚æœ¬æ–‡ã¯è‡ªå‹•æ•´å½¢ã®ãŸã‚ã€è¦ç‚¹ãƒ¬ãƒ™ãƒ«ã®æŠœç²‹ã§ã‚ã‚‹ã€‚",
        "",
        "â–  èƒŒæ™¯ãƒ»ç›®çš„",
        "è¬›æ¼”ã®èƒŒæ™¯ã€è‡¨åºŠä¸Šã®æ„ç¾©ã€ç›®çš„ã‚’æœ¬æ–‡ã‹ã‚‰æ©Ÿæ¢°çš„ã«æŠ½å‡ºãƒ»å†æ§‹æˆã€‚",
        "",
        "â–  æ–¹æ³•ãƒ»è³‡æ–™",
        "ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿ã€å¯¾è±¡ã€æ‰‹æ³•ã€è©•ä¾¡æŒ‡æ¨™ãªã©ã®è¨˜è¼‰ã‚’è¦ç‚¹ã¨ã—ã¦æŠ½å‡ºã€‚",
        "",
        "â–  çµæœãƒ»æ‰€è¦‹",
        "æœ¬æ–‡ã‹ã‚‰çµæœã«ç›¸å½“ã™ã‚‹æ–‡ã‚’å„ªå…ˆçš„ã«æ‹¾ã„ä¸Šã’åæ˜ ã€‚",
        "",
        "â–  è€ƒå¯Ÿãƒ»çµè«–",
        "è‡¨åºŠç¾å ´ã¸ã®ç¤ºå”†ã€é™ç•Œã€ä»Šå¾Œã®å±•æœ›ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹ã€‚",
        "",
        "â€” ä»¥ä¸‹ã¯é€èªãƒ™ãƒ¼ã‚¹æœ¬æ–‡ï¼ˆæ©Ÿæ¢°æŠ½å‡ºï¼‰ â€”",
        body,
    ]
    return "\n".join(lines)


def heuristic_guideline_commentary(slide_groups: List[Dict[str, Any]], ocr_notes: List[dict]) -> str:
    ocr_map = {o.get("index"): (o.get("text") or "").strip() for o in (ocr_notes or [])}
    lines = [
        "ã€ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬ï¼ˆè‡ªå‹•æ•´å½¢ãƒ»AIä¸ä½¿ç”¨ï¼‰ã€‘\n",
        "â–  èƒŒæ™¯",
        "ãƒ»æœ¬è§£èª¬ã¯æ¼”è€…ã‚¹ãƒ©ã‚¤ãƒ‰ã¨ã‚¹ãƒ”ãƒ¼ãƒå†…å®¹ã‚’å¯¾å¿œä»˜ã‘ã¦å†æ§‹æˆã—ãŸã‚‚ã®ã€‚",
        "",
    ]
    for g in slide_groups:
        idx, ocr = g["index"], ocr_map.get(g["index"], "")
        lines.append(f"â–¼ Slide {idx}ï¼ˆ{format_timestamp(g['start'])}â€“{fmt_ts(g['end'])}ï¼‰")
        if ocr:
            title = ocr.splitlines()[0][:50]
            lines.append(f"ã€ã‚¹ãƒ©ã‚¤ãƒ‰è¦æ—¨ã€‘{title}")
        for t, s, e in g["segments"][:6]:
            lines.append(f"ãƒ»{t}")
        lines.append("")
    lines += ["â–  è‡¨åºŠã¸ã®å«æ„", "ãƒ»æœ¬æ”¹è¨‚ã«ã‚ˆã‚Šæƒ³å®šã•ã‚Œã‚‹è¨ºç™‚ä¸Šã®å½±éŸ¿ç‚¹ã‚’è¦ç‚¹åŒ–ã€‚", "", "â–  ä»Šå¾Œã®èª²é¡Œ", "ãƒ»ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹å¼·åŒ–ãŒå¿…è¦ãªè«–ç‚¹ã€é‹ç”¨æ™‚ã®ç•™æ„ç‚¹ã€‚"]
    return "\n".join(lines).strip()


# ========== LLMï¼ˆè¨˜äº‹åŒ–/è¦æ—¨/è­°äº‹éŒ²ï¼‰ ==========
PURPOSE_PROMPTS = {
    "å­¦ä¼šç™ºè¡¨": (
        "ä»¥ä¸‹ã®ç´ æï¼ˆéŸ³å£°é€èªã¨ä»»æ„ã®ã‚¹ãƒ©ã‚¤ãƒ‰OCRè¦ç´„ï¼‰ã‹ã‚‰ã€å­¦ä¼šå ±å‘Šè¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        "è¦‹å‡ºã—ï¼ˆå°å…¥/èƒŒæ™¯/ç›®çš„/æ–¹æ³•/çµæœ/è€ƒå¯Ÿ/çµèªï¼‰ã‚’ä»˜ã‘ã€å›ºæœ‰åè©ã¨æ•°å€¤ã¯æ”¹å¤‰ã›ãšã€"
        "èª‡å¼µã‚„å‰µä½œã¯é¿ã‘ã¦ãã ã•ã„ã€‚å°‚é–€èª­è€…å‘ã‘ã«ç°¡æ½”ã§æ­£ç¢ºã«ã€‚"
    ),
    "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬": (
        "ä»¥ä¸‹ã®ç´ æã‹ã‚‰ã€æ—¥æœ¬èªã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³æ”¹è¨‚è§£èª¬è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        "èƒŒæ™¯/æ”¹è¨‚ãƒã‚¤ãƒ³ãƒˆ/æ¨å¥¨åº¦ãƒ»ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹/è‡¨åºŠã¸ã®å½±éŸ¿/èª²é¡Œ/ä»Šå¾Œã€ã®é †ã«ä¸€åº¦ã ã‘éª¨çµ„ã¿ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚"
        "ãƒ†ã‚­ã‚¹ãƒˆãŒè¤‡æ•°ãƒ‘ãƒ¼ãƒˆã«åˆ†å‰²ã•ã‚Œã‚‹å ´åˆã§ã‚‚ã€è¦‹å‡ºã—ãƒ»å°å…¥ã®å†æ²ã¯ã—ãªã„ã§ãã ã•ã„ã€‚"
        "æ—¢å‡ºå†…å®¹ã®å†æ²ã‚’é¿ã‘ã€æ–°è¦æƒ…å ±ã®ã¿è¿½è¨˜ã™ã‚‹å½¢ã§é€£ç¶šæ€§ã‚’ä¿ã£ã¦ãã ã•ã„ã€‚"
        "è‹±èªã¯æ­£ç¢ºã«æ—¥æœ¬èªåŒ–ã—ã€å¼•ç”¨ã¯è¦æ—¨åŒ–ã—ã¦æ›¸ãç›´ã—ã¦ãã ã•ã„ã€‚"
    ),
    "ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³": (
        "ä»¥ä¸‹ã®ç´ æã‹ã‚‰ã€ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        "è«–ç‚¹æ•´ç†/è³›å¦ã®ä¸»å¼µ/æ ¹æ‹ /ä¸€è‡´ç‚¹ã¨ç›¸é•ç‚¹/çµè«–ã¨ä»Šå¾Œã®æ¤œè¨èª²é¡Œã€ã®é †ã§ã€ä¸­ç«‹ãƒ»ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚"
        "å†—é•·ãªå£èªè¡¨ç¾ã¯å‰Šé™¤ã—ã€æ–¹è¨€ã¯æ¨™æº–èªã«ç›´ã—ã¦ãã ã•ã„ã€‚"
    ),
}


def llm_rewrite(kind: str, text: str, api_key: str | None,
                purpose: str | None = None,
                source_lang: str | None = None,
                target_lang: str | None = "ja") -> str:
    if openai_mod is None:
        return "[LLMæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«] `pip install -U openai` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
    if not api_key:
        return "[APIã‚­ãƒ¼æœªå…¥åŠ›] ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§APIã‚­ãƒ¼ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚"

    sys_prompt = (
        "ã‚ãªãŸã¯åŒ»å­¦ãƒ»åŒ»ç™‚ç³»ã®æ—¥æœ¬èªç·¨é›†è€…ã§ã™ã€‚è‡¨åºŠãƒ»å­¦è¡“æ–‡è„ˆã«æ²¿ã£ã¦ã€"
        "èª­ã¿ã‚„ã™ãäº‹å®Ÿé–¢ä¿‚ã‚’ä¿ã£ãŸã¾ã¾æ•´æ–‡ã—ã¾ã™ã€‚æ•°å€¤ã‚„å¼•ç”¨ã¯æ”¹å¤‰ã—ã¾ã›ã‚“ã€‚"
    )
    pre = PURPOSE_PROMPTS.get(purpose or "å­¦ä¼šç™ºè¡¨", "")

    if (target_lang or "ja").lower() == "ja":
        lang_policy = (
            "æœ€çµ‚å‡ºåŠ›ã¯å¿…ãšæ—¥æœ¬èªã§æ›¸ã„ã¦ãã ã•ã„ã€‚éŸ³å£°/ã‚¹ãƒ©ã‚¤ãƒ‰ãŒæ—¥æœ¬èªã§ãªã„å ´åˆã¯æ­£ç¢ºã«æ—¥æœ¬èªã¸ç¿»è¨³ã—ã€"
            "å°‚é–€ç”¨èªã¯é©åˆ‡ãªæ—¥æœ¬èªè¨³ã‚’ç”¨ã„ã€å›ºæœ‰åè©ãƒ»æ•°å€¤ãƒ»å˜ä½ã¯ä¿æŒã—ã¦ãã ã•ã„ã€‚"
        )
        if source_lang and str(source_lang).lower() != "ja":
            lang_policy += "ï¼ˆå…¥åŠ›ã¯æ—¥æœ¬èªä»¥å¤–ã¨æ¤œå‡ºã•ã‚ŒãŸãŸã‚ç¿»è¨³ãŒå¿…è¦ã§ã™ï¼‰"
    else:
        lang_policy = f"æœ€çµ‚å‡ºåŠ›ã¯å¿…ãš {target_lang} ã§æ›¸ã„ã¦ãã ã•ã„ã€‚å›ºæœ‰åè©ãƒ»æ•°å€¤ãƒ»å˜ä½ã¯ä¿æŒã—ã¦ãã ã•ã„ã€‚"

    user_prompt_map = {
        "verbatim": "é€èªè¨˜éŒ²ï¼ˆè»½å¾®ãªå¥èª­ç‚¹æ•´å½¢ã®ã¿ã€æ„å‘³æ”¹å¤‰ç¦æ­¢ï¼‰ï¼š\n\n" + text,
        "minutes":  "è­°äº‹éŒ²ï¼ˆè¦‹å‡ºã—ï¼‹ç®‡æ¡æ›¸ãã€æ™‚ç³»åˆ—ï¼‰ï¼š\n\n" + text,
        "abstract": "å­¦ä¼šæŠ„éŒ²ï¼ˆç›®çš„/æ–¹æ³•/çµæœ/çµè«–ã€600-900å­—ï¼‰ï¼š\n\n" + text,
        "article":  "è¨˜äº‹åŒ–ï¼ˆå°å…¥/èƒŒæ™¯/ç›®çš„/æ–¹æ³•/çµæœ/è€ƒå¯Ÿ/çµèªï¼‰ï¼š\n\n" + text,
    }
    if kind not in user_prompt_map:
        kind = "article"

    prompt = (pre + "\n\n" + lang_policy + "\n\n" + user_prompt_map[kind]).strip()

    client = openai_mod.OpenAI(api_key=api_key) if hasattr(openai_mod, "OpenAI") else None
    try:
        if client:
            resp = client.chat.completions.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "system", "content": sys_prompt},
                          {"role": "user", "content": prompt}],
                temperature=0.1,
            )
            result = resp.choices[0].message.content
        else:
            openai_mod.api_key = api_key
            resp = openai_mod.ChatCompletion.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "system", "content": sys_prompt},
                          {"role": "user", "content": prompt}],
                temperature=0.1,
            )
            result = resp["choices"][0]["message"]["content"]
    except Exception as e:
        return f"[LLMã‚¨ãƒ©ãƒ¼] {e}"

    if kind != "verbatim":
        result = "ã€AIæ•´å½¢ã€‘\n" + result
    return result


def llm_translate_only(text: str, api_key: str | None,
                       source_lang: str | None = None,
                       target_lang: str = "ja") -> str:
    if openai_mod is None:
        return "[LLMæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«] `pip install -U openai` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
    if not api_key:
        return "[APIã‚­ãƒ¼æœªå…¥åŠ›] ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§APIã‚­ãƒ¼ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚"

    sys_prompt = (
        "ã‚ãªãŸã¯å¿ å®Ÿãªå°‚é–€ç¿»è¨³è€…ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’é€èªçš„ã«æ—¥æœ¬èªã¸ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚"
        "è¦ç´„ãƒ»æ„è¨³ãƒ»è¦‹å‡ºã—ä»˜ã‘ãƒ»ç®‡æ¡æ›¸ãåŒ–ãƒ»ä½“è£å¤‰æ›´ã¯è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚"
        "æ®µè½ã‚„æ”¹è¡Œç­‰ã®æ§‹é€ ã¯å¯èƒ½ãªé™ã‚Šä¿æŒã—ã€å›ºæœ‰åè©ãƒ»æ•°å€¤ãƒ»å˜ä½ã¯ç¶­æŒã—ã¦ãã ã•ã„ã€‚"
    )
    if (target_lang or "ja").lower() != "ja":
        sys_prompt = sys_prompt.replace("æ—¥æœ¬èª", target_lang)

    prompt = "ã€ç¿»è¨³å¯¾è±¡ã€‘\n" + text

    client = openai_mod.OpenAI(api_key=api_key) if hasattr(openai_mod, "OpenAI") else None
    try:
        if client:
            resp = client.chat.completions.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "system", "content": sys_prompt},
                          {"role": "user", "content": prompt}],
                temperature=0.0,
            )
            return resp.choices[0].message.content
        else:
            openai_mod.api_key = api_key
            resp = openai_mod.ChatCompletion.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "system", "content": sys_prompt},
                          {"role": "user", "content": prompt}],
                temperature=0.0,
            )
            return resp["choices"][0]["message"]["content"]
    except Exception as e:
        return f"[LLMã‚¨ãƒ©ãƒ¼] {e}"


def llm_article_from_literal(literal_ja: str,
                             api_key: str | None,
                             purpose: str | None = "å­¦ä¼šç™ºè¡¨") -> str:
    if openai_mod is None:
        return "[LLMæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«] `pip install -U openai` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
    if not api_key:
        return "[APIã‚­ãƒ¼æœªå…¥åŠ›] ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§APIã‚­ãƒ¼ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚"

    sys_prompt = (
        "ã‚ãªãŸã¯åŒ»ç™‚ãƒ»åŒ»å­¦åˆ†é‡ã®ç·¨é›†è€…ã€‚å…¥åŠ›ã¯æ—¢ã«æ—¥æœ¬èªã¸é€èªç›´è¨³ã•ã‚ŒãŸåŸç¨¿ã€‚"
        "é‡è¤‡ãƒ»è¨€ã„æ›ãˆã®å†—é•·ã ã‘ã‚’æ•´ç†ã—ã€æ„å‘³ãƒ»äº‹å®Ÿã¯è½ã¨ã•ãšè¨˜äº‹èª¿ï¼ˆå¸¸ä½“ï¼‰ã«æ•´ãˆã‚‹ã€‚"
        "ã€å³å®ˆã€‘é‡è¤‡ä»¥å¤–ã®å‰Šé™¤ç¦æ­¢ï¼æ•°å€¤ãƒ»è©¦é¨“åãƒ»è–¬å‰¤åãƒ»ç”¨é‡ãƒ»å˜ä½ã¯ä¿æŒã€‚"
        "è¦‹å‡ºã—ã¯ã€å°å…¥/èƒŒæ™¯/ç›®çš„/æ–¹æ³•/çµæœ/è€ƒå¯Ÿ/çµèªã€ã®é †ã§ä¸€åº¦ã ã‘ã€‚"
        "è„šè‰²ãƒ»æ–°æƒ…å ±ã®è¿½åŠ ã¯ç¦æ­¢ã€‚"
        "æ–‡æœ«ã¯å¸¸ä½“ï¼ˆã€œã ï¼ã€œã§ã‚ã‚‹ï¼‰ã«çµ±ä¸€ã—ã€ã§ã™ãƒ»ã¾ã™èª¿ã¯ç¦æ­¢ã€‚"
    )
    preface = {
        "å­¦ä¼šç™ºè¡¨": "å­¦ä¼šå ±å‘Šã®é€Ÿå ±ãƒˆãƒ¼ãƒ³ã§ã€å°‚é–€èª­è€…å‘ã‘ã«ç°¡æ½”ã§æ­£ç¢ºã«ã€‚",
        "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬": "è§£èª¬è¨˜äº‹ã®æ–‡ä½“ã§ã€èƒŒæ™¯â†’è¦ç‚¹â†’è‡¨åºŠçš„å«æ„ã‚’æ˜ç¢ºã«ã€‚",
        "ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³": "è«–ç‚¹ã‚’æ˜ç¢ºåŒ–ã—ã¤ã¤ä¸­ç«‹ã«è¨˜è¿°ã€‚"
    }.get(purpose or "å­¦ä¼šç™ºè¡¨", "å°‚é–€èª­è€…å‘ã‘ã«ç°¡æ½”ã§æ­£ç¢ºã«ã€‚")

    user_prompt = (
        f"{preface}\n\n"
        "ã€å…¥åŠ›ï¼ˆé€èªç›´è¨³ãƒ»æ—¥æœ¬èªï¼‰ã€‘\n"
        + literal_ja.strip()
        + "\n\nã€å‡ºåŠ›ä»•æ§˜ã€‘\n"
          "- TCROSS NEWS å­¦ä¼šç™ºè¡¨è¨˜äº‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«æ•´å½¢ã™ã‚‹ã“ã¨ã€‚\n"
          "- ã‚¿ã‚¤ãƒˆãƒ«ã¯ã€Œå¯¾è±¡/ç–¾æ‚£ãƒ»ä»‹å…¥: è©¦é¨“åã€ã¨ã™ã‚‹ã€‚\n"
          "- ç¬¬1æ®µè½ã¯ã€Œâ–³â–³è©¦é¨“ã‚ˆã‚Šã€â–¡â–¡ã“ã¨ãŒã€å›½ã€æ‰€å±ã€æ¼”è€…åã«ã‚ˆã‚Šã€å­¦ä¼šåã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³åã§ç™ºè¡¨ã•ã‚ŒãŸã€‚ã€ã¨ã„ã†å½¢ã§æ›¸ãï¼ˆConclusionã®å†’é ­æ–‡ã‚’åæ˜ ï¼‰ã€‚\n"
          "- ç¬¬2æ®µè½ã¯è©¦é¨“ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’è¨˜è¼‰ï¼ˆè©¦é¨“åã€ç™»éŒ²æœŸé–“ã€å›½ãƒ»æ–½è¨­æ•°ã€æ‚£è€…æ•°ã€ç¾¤å‰²ä»˜ã‘ã€å‰²ä»˜ã‘æ•°ï¼‰ã€‚\n"
          "- ç¬¬3æ®µè½ã¯æ‚£è€…èƒŒæ™¯ã‚’è©³ç´°ã«è¨˜è¼‰ï¼ˆå·®ãŒãªã‘ã‚Œã°å¹³å‡å€¤ã§ã€å¹´é½¢ãƒ»æ€§åˆ¥ãƒ»ä½µå­˜ç—‡ãƒ»è–¬å‰¤å‡¦æ–¹ç‡ã‚’å«ã‚ã‚‹ï¼‰ã€‚\n"
          "- ç¬¬4æ®µè½ã¯ä¸»è¦è©•ä¾¡é …ç›®ã®çµæœã‚’è¨˜è¼‰ï¼ˆè¿½è·¡æœŸé–“ã€ã‚¤ãƒ™ãƒ³ãƒˆç‡ã€HRã€95%CIã€på€¤ã‚’ä¿æŒï¼‰ã€‚\n"
          "- ç¬¬5æ®µè½ä»¥é™ã«ã‚µãƒ–è§£æçµæœãŒã‚ã‚Œã°è¨˜è¼‰ã€‚\n"
          "- æœ€çµ‚æ®µè½ã¯æ¼”è€…ã®ãƒ©ã‚¹ãƒˆãƒãƒ¼ãƒ ã‹ã‚‰å§‹ã‚ã€ã€Œâ€¦ã¨ã€ã¾ã¨ã‚ãŸã€‚ã€ã§å¿…ãšç· ã‚ã‚‹ã€‚\n"
          "- åŒæ™‚æ²è¼‰ãŒã‚ã‚Œã°ã€Œå°šã€â–³â–³è©¦é¨“ã¯â—‹â—‹èªŒã«æ²è¼‰ã•ã‚ŒãŸã€‚ã€ã¨åŠ ãˆã‚‹ã€‚\n"
          "- è¨˜äº‹èª¿ï¼ˆå¸¸ä½“ï¼‰ã€‚\n"
          "- è¦‹å‡ºã—ã¯ã€å°å…¥/èƒŒæ™¯/ç›®çš„/æ–¹æ³•/çµæœ/è€ƒå¯Ÿ/çµèªã€ã€‚\n"
          "- å†—é•·ãªé‡è¤‡ã¯çµ±åˆã€‚ãã®ä»–ã®å†…å®¹ã¯æ®‹ã™ï¼ˆå‰Šã‚Šã™ãç¦æ­¢ï¼‰ã€‚\n"
          "- æ•°å€¤ãƒ»ç”¨èªã¯ãã®ã¾ã¾ä¿æŒã€‚\n"
          "- ç®‡æ¡æ›¸ãã§ã¯ãªãæ®µè½ã”ã¨ã«ã¾ã¨ã‚ã€è«–ç†çš„ãªæµã‚Œã‚’æŒãŸã›ã‚‹ã€‚\n"
          "- çµæœã¯é€èªã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æƒ…å ±é‡ã‚’ä¿æŒã—ãŸã¾ã¾è¨˜äº‹èª¿ã«æ•´ãˆã‚‹ã“ã¨ã€‚\n"
    )

    client = openai_mod.OpenAI(api_key=api_key) if hasattr(openai_mod, "OpenAI") else None
    try:
        if client:
            resp = client.chat.completions.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "system", "content": sys_prompt},
                          {"role": "user", "content": user_prompt}],
                temperature=0.15,
            )
            return "ã€AIæ•´å½¢ï¼ˆç›´è¨³â†’è¨˜äº‹èª¿ï¼‰ã€‘\n" + resp.choices[0].message.content
        else:
            openai_mod.api_key = api_key
            resp = openai_mod.ChatCompletion.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "system", "content": sys_prompt},
                          {"role": "user", "content": user_prompt}],
                temperature=0.15,
            )
            return "ã€AIæ•´å½¢ï¼ˆç›´è¨³â†’è¨˜äº‹èª¿ï¼‰ã€‘\n" + resp["choices"][0]["message"]["content"]
    except Exception as e:
        return f"[LLMã‚¨ãƒ©ãƒ¼] {e}"


# ========== DOCX å‡ºåŠ› ==========
def make_docx(title: str, content: str) -> bytes:
    doc = Document()
    style = doc.styles['Normal']
    font = style.font
    font.name = 'Yu Gothic'
    font.size = Pt(11)

    doc.add_heading(title or "å‡ºåŠ›", level=1)
    for line in content.splitlines():
        if line.strip() == "":
            doc.add_paragraph("")
        else:
            doc.add_paragraph(line)

    buf = io.BytesIO()
    doc.save(buf)
    buf.seek(0)
    return buf.read()


# ========== Streamlit UI ==========
def main():
    st.set_page_config(page_title="InsighTCROSSÂ® Smart Writer v11", layout="wide")

    # 1) ãƒ­ã‚°ã‚¤ãƒ³ï¼†APIã‚­ãƒ¼å…¥åŠ›ï¼ˆæ¯å›ï¼‰
    api_key = require_login_and_api()

    if "workdir" not in st.session_state:
        st.session_state["workdir"] = os.path.abspath("./.work")
        os.makedirs(st.session_state["workdir"], exist_ok=True)

    st.title("InsighTCROSSÂ® Smart Writer v11")
    if "transcript_text" not in st.session_state:
        st.session_state["transcript_text"] = ""
    if "generated_text" not in st.session_state:
        st.session_state["generated_text"] = ""
    st.write("éŸ³å£°/å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€é€èªãƒ»ç›´è¨³ãƒ»è­°äº‹éŒ²ãƒ»è¦æ—¨ãƒ»è¨˜äº‹ã«æ•´å½¢ã€‚å‹•ç”»ã¯ã‚¹ãƒ©ã‚¤ãƒ‰OCRä½µç”¨ã‚‚å¯èƒ½ã€‚")

    with st.sidebar:
        st.header("è¨­å®š")
        file_type = st.radio("ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—", ["è‡ªå‹•åˆ¤å®š", "éŸ³å£°", "å‹•ç”»"], index=0)
        use_slide_ocr = st.toggle("ã‚¹ãƒ©ã‚¤ãƒ‰OCRã‚‚ä½µç”¨ï¼ˆå‹•ç”»æ™‚ï¼‰", value=False,
                                  help="ã‚¹ãƒ©ã‚¤ãƒ‰ã®ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã—OCRã§æ–‡å­—ã‚‚å–ã‚Šè¾¼ã¿ã¾ã™ï¼ˆä¾å­˜ãŒç„¡ã‘ã‚Œã°ç©ºã§ç¶™ç¶šï¼‰")
        scene_sensitivity = st.slider("ã‚·ãƒ¼ãƒ³å¤‰åŒ–æ„Ÿåº¦", 0.10, 0.60, 0.35, 0.01)

        output_lang_label = st.selectbox("å‡ºåŠ›è¨€èª", ["æ—¥æœ¬èª (JPN)", "English (EN)"], index=0)
        output_lang = "ja" if "JPN" in output_lang_label else "en"

        out_kind = st.selectbox(
            "å‡ºåŠ›ã‚¿ã‚¤ãƒ—",
            ["é€èª(ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—)", "ç›´è¨³ï¼ˆæ—¥æœ¬èªåŒ–ã®ã¿ï¼‰", "è­°äº‹éŒ²", "è¦æ—¨", "è¨˜äº‹", "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬"]
        )
        purpose = st.selectbox("è¨˜äº‹åŒ–ã®ç›®çš„", ["å­¦ä¼šç™ºè¡¨", "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬", "ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³"], index=0)
        attach_verbatim = st.toggle("æœ«å°¾ã«é€èªåŸæ–‡ã‚’æ·»ä»˜", value=False,
                                    help="åŸæ–‡è¨€èªã®é€èªãƒ†ã‚­ã‚¹ãƒˆã‚’æœ«å°¾ã«ä»˜ã‘ã¾ã™ï¼ˆé€šå¸¸ã¯OFFæ¨å¥¨ï¼‰")
        use_llm = st.toggle("ç”ŸæˆAIã§æ•´å½¢ï¼ˆä»»æ„ï¼‰", value=False)
        # éŸ³å£°ã®è¨€èªï¼ˆWhisperã¸ã®æŒ‡ç¤ºï¼‰
        speech_lang_label = st.selectbox("éŸ³å£°è¨€èªï¼ˆWhisperï¼‰", ["è‹±èª", "æ—¥æœ¬èª", "è‡ªå‹•"], index=0)
        _lang_map = {"è‹±èª": "en", "æ—¥æœ¬èª": "ja", "è‡ªå‹•": None}
        forced_lang = _lang_map[speech_lang_label]


    uploaded = st.file_uploader(
        "éŸ³å£°/å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (mp3, m4a, wav, mp4, mov ãªã©)",
        type=["mp3","m4a","wav","mp4","mov","mkv","aac","flac"]
    )

    if not uploaded:
        return

    st.info(f"å—ä¿¡: {uploaded.name} / {uploaded.size/1024:.1f} KB")
    temp_path = save_uploaded_file_to_temp(uploaded)
    guessed = (uploaded.type or mimetypes.guess_type(uploaded.name)[0] or "")
    is_video = (file_type == "å‹•ç”»") or (file_type == "è‡ªå‹•åˆ¤å®š" and guessed.startswith("video/"))

    with st.spinner("å¤‰æ›ä¸­ï¼ˆWAV 16kHz monoï¼‰..."):
        wav_path = ensure_wav(temp_path)

    with st.spinner("ğŸ§  OpenAIã§æ–‡å­—èµ·ã“ã—ä¸­â€¦"):
        segments, detected_lang = transcribe_openai(wav_path, api_key, forced_lang=forced_lang)

    st.success(f"æ–‡å­—èµ·ã“ã—å®Œäº†ã€‚ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(segments)} / è¨€èªæ¤œå‡º: {detected_lang}")

    # é€èªï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰åŸç¨¿
    verbatim_text = to_verbatim_with_timestamps(segments)
    st.session_state["transcript_text"] = verbatim_text

    st.subheader("âœï¸ é€èªãƒ†ã‚­ã‚¹ãƒˆï¼ˆç·¨é›†å¯ï¼‰")
    st.session_state["transcript_text"] = st.text_area(
        "é€èªï¼ˆå¿…è¦ã«å¿œã˜ã¦ä¿®æ­£ã—ã¦ãã ã•ã„ï¼‰",
        value=st.session_state["transcript_text"],
        height=300
    )

    # ã‚¹ãƒ©ã‚¤ãƒ‰OCRï¼ˆä»»æ„ï¼‰
    slide_groups, slide_notes, slide_digest = [], [], ""
    if is_video and use_slide_ocr:
        with st.spinner("ã‚¹ãƒ©ã‚¤ãƒ‰æŠ½å‡ºï¼ˆã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ +æ™‚åˆ»ï¼‰â†’ OCR ä¸­..."):
            frames, slide_times = extract_slide_keyframes_with_times(
                video_path=temp_path,
                out_dir=os.path.join(st.session_state["workdir"], "slides"),
                scene_thr=scene_sensitivity,
            )

            st.write(f"æŠ½å‡ºãƒ•ãƒ¬ãƒ¼ãƒ æšæ•°: {len(frames)} / åˆ‡æ›¿æ¤œå‡º: {len(slide_times)}")
            if frames:
                st.write("å…ˆé ­3æšã®ãƒ‘ã‚¹:", frames[:3])
                try:
                    st.image(frames[0], caption="ã‚¹ãƒ©ã‚¤ãƒ‰æŠ½å‡ºãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå…ˆé ­ï¼‰", use_container_width=True)
                except Exception as e:
                    st.warning(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºã«å¤±æ•—: {e}")
            else:
                st.warning("æŠ½å‡ºã•ã‚ŒãŸç”»åƒãŒ0æšã§ã™ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒåŠ¹ã„ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

            slide_notes = ocr_slides(frames)
            slide_groups = group_segments_by_slides(segments, slide_times)
            slide_digest = "\n\n".join(
                [f"[Slide {s['index']}]\n{s.get('text','')}" for s in slide_notes if s.get('text','').strip()]
            )
        st.success(f"ã‚¹ãƒ©ã‚¤ãƒ‰æŠ½å‡º: {len(slide_notes)} æš / åˆ‡æ›¿: {len(slide_times)} ç‚¹")

    edited_transcript = st.session_state["transcript_text"]
    cleaned_for_llm = strip_timestamps(edited_transcript)

    if out_kind == "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬" and slide_groups:
        chunks = []
        for g in slide_groups:
            idx = g["index"]
            ocr_text = ""
            for s in (slide_notes or []):
                if s.get("index") == idx:
                    ocr_text = (s.get("text") or "").strip()
                    break
            speech_text = "\n".join([t for (t, _, _) in g["segments"]])
            chunks.append(
                f"[Slide {idx} {format_timestamp(g['start'])}â€“{fmt_ts(g['end'])}]\n"
                f"<OCR>\n{ocr_text}\n</OCR>\n<SPEECH>\n{speech_text}\n</SPEECH>"
            )
        llm_source = "ã€ã‚¹ãƒ©ã‚¤ãƒ‰åˆ¥ç´ æã€‘\n" + "\n\n".join(chunks)
    else:
        llm_source = cleaned_for_llm if not slide_digest else (
            f"ã€éŸ³å£°é€èªã€‘\n{cleaned_for_llm}\n\nã€ã‚¹ãƒ©ã‚¤ãƒ‰OCRã€‘\n{slide_digest}"
        )

    # æ—¢å®šï¼ˆãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ï¼‰å‡ºåŠ›
    if out_kind == "é€èª(ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—)":
        base_out = to_verbatim_with_timestamps(segments); kind_key = "verbatim"
    elif out_kind == "è­°äº‹éŒ²":
        base_out = heuristic_minutes(segments); kind_key = "minutes"
    elif out_kind == "è¦æ—¨":
        base_out = heuristic_abstract(segments); kind_key = "abstract"
    elif out_kind == "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬":
        base_out = heuristic_guideline_commentary(slide_groups, slide_notes) if slide_groups else \
                   "ã€ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬ï¼ˆç°¡æ˜“ï¼‰ã€‘\n" + heuristic_article_academic(segments)
        kind_key = "article"
    else:
        base_out = heuristic_article_academic(segments); kind_key = "article"

    final_out = base_out

    # ç”ŸæˆAIã§æ•´å½¢ãƒœã‚¿ãƒ³
    st.markdown("---")
    st.subheader("ğŸ§  ç”ŸæˆAIã§æ•´å½¢ã™ã‚‹")
    label_lang = "æ—¥æœ¬èª" if output_lang == "ja" else "English"
    do_generate = st.button(f"âœ¨ ç”ŸæˆAIã§æ•´å½¢ï¼ˆ{label_lang}ã§å‡ºåŠ›ï¼‰")

    if not do_generate:
        st.text_area("çµæœãƒ†ã‚­ã‚¹ãƒˆ", value=final_out or "", height=400)
        return

    # æŠ¼ä¸‹å¾Œ
    if use_llm is False:
        st.info("ç”ŸæˆAIãŒOFFã®ãŸã‚ã€ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯æ•´å½¢ã®çµæœã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
        st.text_area("çµæœãƒ†ã‚­ã‚¹ãƒˆ", value=final_out or "", height=400)
        return

    if not api_key:
        st.error("ç”ŸæˆAIã®æ•´å½¢ã«ã¯ OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã§å…¥åŠ›ï¼‰ã€‚")
        st.stop()

    st.session_state.pop("ja_literal_for_article", None)

    final_out = base_out
    try:
        if out_kind == "é€èª(ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—)":
            with st.spinner("ç”ŸæˆAIã§æ•´å½¢ä¸­..."):
                final_out = llm_rewrite(
                    kind="verbatim",
                    text="ã€å‡ºåŠ›ã¯å¿…ãšæ—¥æœ¬èªã€‘\n" + st.session_state["transcript_text"],
                    api_key=api_key,
                    purpose=purpose,
                    source_lang=detected_lang,
                    target_lang=output_lang,
                )
        elif out_kind == "ç›´è¨³ï¼ˆæ—¥æœ¬èªåŒ–ã®ã¿ï¼‰":
            with st.spinner("è‹±èªâ†’æ—¥æœ¬èª ç›´è¨³ä¸­..."):
                final_out = llm_translate_only(
                    text=cleaned_for_llm,
                    api_key=api_key,
                    source_lang=detected_lang,
                    target_lang="ja",
                )
        else:
            if out_kind == "è¨˜äº‹" and (output_lang == "ja"):
                with st.spinner("è‹±èªâ†’æ—¥æœ¬èª ç›´è¨³ â†’ è¨˜äº‹èª¿ ã¸æ•´å½¢ä¸­..."):
                    ja_literal_for_article = llm_translate_only(
                        text=cleaned_for_llm,
                        api_key=api_key,
                        source_lang=detected_lang,
                        target_lang="ja",
                    )
                    final_out = llm_article_from_literal(
                        literal_ja=ja_literal_for_article,
                        api_key=api_key,
                        purpose=purpose,
                    )
                    st.caption("route: ARTICLE_FROM_LITERAL (ja) âœ“ ç›´è¨³â†’è¨˜äº‹èª¿ãƒ«ãƒ¼ãƒˆã‚’é€šé")
                    st.session_state["ja_literal_for_article"] = ja_literal_for_article
            else:
                llm_kind_call = {"è­°äº‹éŒ²": "minutes", "è¦æ—¨": "abstract"}.get(out_kind, "article")
                parts = split_text_by_chars(llm_source, chunk_size=6000, overlap=300)
                outs = []
                N = len(parts)
                for i, part in enumerate(parts, start=1):
                    meta = (
                        f"ã€åˆ†å‰²ãƒ‘ãƒ¼ãƒˆ {i}/{N}ã€‘\n"
                        "ã“ã®ãƒ‘ãƒ¼ãƒˆã§ã¯æ–°è¦æƒ…å ±ã®ã¿ã‚’åæ˜ ã—ã€æ—¢å‡ºã®è¦‹å‡ºã—ã‚„å°å…¥ã¯å†æ²ã—ãªã„ã§ãã ã•ã„ã€‚"
                    )
                    out_i = llm_rewrite(
                        kind=llm_kind_call,
                        text="ã€å‡ºåŠ›ã¯å¿…ãšæ—¥æœ¬èªã€‘\n" + meta + "\n\n" + part,
                        api_key=api_key,
                        purpose=purpose,
                        source_lang=detected_lang,
                        target_lang=output_lang,
                    )
                    outs.append(out_i.strip())
                final_out = "\n\n".join(outs)
        st.success("ç”ŸæˆAIã§ã®æ•´å½¢ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        st.error(f"æ•´å½¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    # ===== ä¸‰æ®µè¡¨ç¤º =====
    st.subheader("ğŸ“ åŸæ–‡ï¼ˆå¤‰æ›´å‰ãƒ»è‹±èªï¼ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—é™¤å»ï¼‰")
    st.text_area("åŸæ–‡", value=cleaned_for_llm, height=260)

    st.subheader("ğŸ‡¯ğŸ‡µ è‹±èªâ†’æ—¥æœ¬èªï¼ˆç›´è¨³ãƒ»æ•´å½¢ãªã—ï¼‰")
    if use_llm and api_key:
        cached_literal = st.session_state.get("ja_literal_for_article")
        if cached_literal:
            ja_literal = cached_literal
        else:
            with st.spinner("è‹±èªâ†’æ—¥æœ¬èª ç›´è¨³ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ï¼‰..."):
                ja_literal = llm_translate_only(
                    text=cleaned_for_llm,
                    api_key=api_key,
                    source_lang=detected_lang,
                    target_lang="ja",
                )
        st.text_area("ç›´è¨³", value=ja_literal, height=260)
    else:
        st.text_area("ç›´è¨³", value="(ç”ŸæˆAIãŒOFFã¾ãŸã¯APIã‚­ãƒ¼æœªå…¥åŠ›ã®ãŸã‚ç›´è¨³ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“)", height=260)

    st.subheader("ğŸ“„ æ•´å½¢çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    if out_kind == "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬" and output_lang == "ja" and final_out:
        for _p in ["èƒŒæ™¯", "æ”¹è¨‚ãƒã‚¤ãƒ³ãƒˆ", "æ¨å¥¨åº¦ãƒ»ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹", "è‡¨åºŠã¸ã®å½±éŸ¿", "èª²é¡Œ", "ä»Šå¾Œ"]:
            final_out = re.sub(rf"(#+\s*{_p}\s*\n)(\s*\1)+", r"\1", final_out)
    st.text_area("æ•´å½¢çµæœ", value=final_out, height=380)

    st.download_button("TXTãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=final_out.encode("utf-8"), file_name="output.txt")
    docx_bytes = make_docx(title=f"{out_kind}ï¼ˆ{purpose}ï¼‰", content=final_out)
    st.download_button("DOCXãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=docx_bytes, file_name="output.docx")


if __name__ == "__main__":
    main()
