# transcribe_editor_v8.py
# -------------------------------------------------------------
# æ©Ÿèƒ½:
# 1) éŸ³å£°/å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ â†’ Whisperç³»(faster-whisper)ã§æ–‡å­—èµ·ã“ã—
# 2) å‡ºåŠ›é¸æŠ: é€èª(ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—) / ç›´è¨³ï¼ˆæ—¥æœ¬èªåŒ–ã®ã¿ï¼‰/ è­°äº‹éŒ² / è¦æ—¨ / è¨˜äº‹ / ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬
# 3) ç›®çš„é¸æŠ: å­¦ä¼šç™ºè¡¨ / ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬ / ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ï¼ˆLLMæ•´å½¢ã«åæ˜ ï¼‰
# 4) å‹•ç”»ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ã‚¹ãƒ©ã‚¤ãƒ‰OCR(ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º + OCR) ä½µç”¨ã®å¯å¦
# 5) ç”ŸæˆAIã¯ä»»æ„ã€‚APIã‚­ãƒ¼æœªå…¥åŠ›ã§ã‚‚ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯æ•´å½¢ã§å‹•ä½œ
# 6) TXT/DOCXã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½
# 7) ç”ŸæˆAIã§æ•´å½¢ï¼ˆæ—¥æœ¬èªï¼‰â†’ ä¸Šã‹ã‚‰ã€ŒåŸæ–‡è‹±èªï¼ç›´è¨³ï¼æ•´å½¢çµæœã€ã®ä¸‰æ®µè¡¨ç¤º
# -------------------------------------------------------------

import os
import io
import time
import glob
import shutil
import subprocess
import mimetypes
from datetime import timedelta
import re
from typing import List, Tuple, Dict, Any

import streamlit as st
from pydub import AudioSegment
from pydub.utils import which
from docx import Document
from docx.shared import Pt

from faster_whisper import WhisperModel

# ä»»æ„: OpenAI
try:
    import openai as openai_mod  # pip install openai
except Exception:
    openai_mod = None

# ä»»æ„: ã‚¹ãƒ©ã‚¤ãƒ‰OCRï¼ˆeasyocrï¼‰
try:
    import easyocr  # pip install easyocr
except Exception:
    easyocr = None

import math
from pathlib import Path

# ğŸ” ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼ç”¨é–¢æ•°
def require_password():
    """å…±é€šãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã§ç°¡æ˜“ãƒ­ã‚°ã‚¤ãƒ³ã€‚é€šéã—ãªã„é™ã‚Šã‚¢ãƒ—ãƒªæœ¬ä½“ã‚’è¡¨ç¤ºã—ãªã„ã€‚"""
    if st.session_state.get("auth_ok", False):
        # ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³ï¼ˆä»»æ„ï¼‰
        with st.sidebar:
            if st.button("ğŸ”’ ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ"):
                st.session_state.clear()
                st.experimental_rerun()
        return

    with st.sidebar:
        st.header("ç¤¾å†…ãƒ­ã‚°ã‚¤ãƒ³")
        pw = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password", help="ç¤¾å†…å…±é€šãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›")
        submitted = st.button("ãƒ­ã‚°ã‚¤ãƒ³")

    correct = st.secrets.get("APP_PASSWORD", None)

    if submitted:
        if correct is None:
            st.error("APP_PASSWORD ãŒæœªè¨­å®šã§ã™ã€‚.streamlit/secrets.toml ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        elif pw == correct:
            st.session_state["auth_ok"] = True
            st.success("ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ")
            st.experimental_rerun()
        else:
            st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™ã€‚")

    if not st.session_state.get("auth_ok", False):
        st.stop()

# ---------------------- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ----------------------

def split_text_by_chars(text: str, chunk_size: int = 6000, overlap: int = 300) -> list[str]:
    text = text.strip()
    if len(text) <= chunk_size:
        return [text]
    chunks = []
    start = 0
    while start < len(text):
        end = min(len(text), start + chunk_size)
        cut = end
        for p in ("ã€‚", "ï¼", "ï¼Ÿ", "\n"):
            idx = text.rfind(p, start, end)
            if idx != -1 and idx > start + 1000:
                cut = idx + 1
                break
        chunks.append(text[start:cut].strip())
        if cut >= len(text):
            break
        start = max(cut - overlap, 0)
    return [c for c in chunks if c]


def strip_timestamps(text: str) -> str:
    pattern = re.compile(
        r"^\s*\[\d{2}:\d{2}:\d{2}(?:\.\d{3})?\s*(?:â†’|->|-|ï¼|â€”)\s*\d{2}:\d{2}:\d{2}(?:\.\d{3})?\]\s*",
        re.MULTILINE,
    )
    return pattern.sub("", text).strip()


# ====================== FFmpeg/ffprobe ã®æ˜ç¤ºè¨­å®š ======================
PROJECT_DIR = Path(__file__).parent
FFBIN_CANDIDATES = [
    PROJECT_DIR / "ffmpeg-7.0.2-essentials_build" / "bin",
    Path(r"C:\\Users\\s-has\\Desktop\\å‹•ç”»éŸ³å£°åŸç¨¿ä½œæˆ082025\\ffmpeg-7.0.2-essentials_build\\bin"),
    Path(r"C:\\Users\\s-has\\Desktop\\ffmpeg-7.0.2-essentials_build\\bin"),
]

FFMPEG_EXE = None
FFPROBE_EXE = None
for _bin in FFBIN_CANDIDATES:
    ff = _bin / "ffmpeg.exe"
    fp = _bin / "ffprobe.exe"
    if ff.exists():
        FFMPEG_EXE, FFPROBE_EXE = ff, (fp if fp.exists() else None)
        os.environ["PATH"] = str(_bin) + os.pathsep + os.environ.get("PATH", "")
        os.environ["FFMPEG_BINARY"] = str(ff)
        os.environ["IMAGEIO_FFMPEG_EXE"] = str(ff)
        AudioSegment.converter = str(ff)
        AudioSegment.ffmpeg = str(ff)
        if FFPROBE_EXE:
            AudioSegment.ffprobe = str(FFPROBE_EXE)
        break
else:
    ffmpeg_found = which("ffmpeg")
    ffprobe_found = which("ffprobe")
    if ffmpeg_found:
        FFMPEG_EXE = Path(ffmpeg_found)
        AudioSegment.converter = ffmpeg_found
        AudioSegment.ffmpeg = ffmpeg_found
    if ffprobe_found:
        FFPROBE_EXE = Path(ffprobe_found)
        AudioSegment.ffprobe = ffprobe_found
# ======================================================================


def save_uploaded_file_to_temp(uploaded_file) -> str:
    suffix = os.path.splitext(uploaded_file.name)[1]
    tmp_path = os.path.join(st.session_state["workdir"], f"upload_{int(time.time())}{suffix}")
    with open(tmp_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return tmp_path


def ensure_wav(input_path: str) -> str:
    try:
        audio = AudioSegment.from_file(input_path)
    except Exception as e:
        st.error(
            "éŸ³å£°/å‹•ç”»ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n"
            "ffmpeg/ffprobe ãŒå®Ÿè¡Œå¯èƒ½ã‹ã€PATH/ã‚³ãƒ¼ãƒ‰è¨­å®šãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n\n"
            f"è©³ç´°: {e}"
        )
        st.stop()
    audio = audio.set_channels(1).set_frame_rate(16000)
    wav_path = os.path.splitext(input_path)[0] + "_16k.wav"
    audio.export(wav_path, format="wav")
    return wav_path


def format_timestamp(seconds: float) -> str:
    td = timedelta(seconds=float(seconds))
    total_seconds = int(td.total_seconds())
    ms = int((td.total_seconds() - total_seconds) * 1000)
    return f"{total_seconds//3600:02d}:{(total_seconds%3600)//60:02d}:{total_seconds%60:02d}.{ms:03d}"


def fmt_ts(x: float) -> str:
    return format_timestamp(x) if math.isfinite(x) else "â€¦"


# ---------------------- ã‚¹ãƒ©ã‚¤ãƒ‰ã¨ç™ºè©±ã®å¯¾å¿œä»˜ã‘ ----------------------

def group_segments_by_slides(
    segments: List[Tuple[str, float, float]],
    slide_change_times: List[float]
) -> List[Dict[str, Any]]:
    last_end = max((e for _, _, e in segments), default=0.0)
    bounds = [0.0] + [t for t in slide_change_times if t < last_end] + [last_end]
    grouped = []
    for i in range(len(bounds)-1):
        start, end = bounds[i], bounds[i+1]
        bucket = []
        for t, s, e in segments:
            if e > start and s < end:
                bucket.append((t, max(s, start), min(e, end)))
        grouped.append({"index": i+1, "start": start, "end": end, "segments": bucket})
    return grouped


# ---------------------- æ–‡å­—èµ·ã“ã—æœ¬ä½“ ----------------------

def transcribe_faster_whisper(
    wav_path: str,
    model_size: str = "small",
    language: str | None = "auto",
    compute_type: str = "auto",
    beam_size: int = 5,
) -> tuple[list[tuple[str, float, float]], str | None]:
    lang_arg = None if (language is None or str(language).lower() == "auto") else language
    model = WhisperModel(model_size, device="auto", compute_type=compute_type)
    segments_gen, info = model.transcribe(
        wav_path,
        language=lang_arg,
        beam_size=beam_size,
        vad_filter=True,
        vad_parameters=dict(min_silence_duration_ms=500),
    )
    results: list[tuple[str, float, float]] = []
    for seg in segments_gen:
        results.append((seg.text.strip(), seg.start, seg.end))
    detected = getattr(info, "language", None)
    return results, detected


# ---------------------- ã‚¹ãƒ©ã‚¤ãƒ‰æŠ½å‡º & OCR ----------------------
def extract_slide_keyframes_with_times(video_path: str, out_dir: str, scene_thr: float=0.35) -> tuple[list[str], list[float]]:
    os.makedirs(out_dir, exist_ok=True)
    for p in glob.glob(os.path.join(out_dir, "*.jpg")):
        try:
            os.remove(p)
        except:
            pass

    ff_cmd = str(FFMPEG_EXE) if FFMPEG_EXE else (shutil.which("ffmpeg") or "ffmpeg")

    # 1) ã‚·ãƒ¼ãƒ³å¤‰åŒ–æŠ½å‡º
    cmd = [
        ff_cmd, "-y", "-i", video_path,
        "-vf", f"select='gt(scene,{scene_thr})',showinfo",
        "-vsync", "vfr",
        os.path.join(out_dir, "%04d.jpg"),
    ]
    proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding="utf-8", errors="ignore")
    stderr = proc.stderr or ""

    times = []
    for m in re.finditer(r"pts_time:([0-9]+\.[0-9]+)", stderr):
        try:
            times.append(float(m.group(1)))
        except:
            pass

    image_paths = sorted(glob.glob(os.path.join(out_dir, "*.jpg")))
    n = min(len(image_paths), len(times))
    if n > 0:
        return image_paths[:n], times[:n]

    # 2) ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼š3ç§’é–“éš”ã§æŠ½å‡º
    for p in glob.glob(os.path.join(out_dir, "*.jpg")):
        try: os.remove(p)
        except: pass
    cmd_fb = [
        ff_cmd, "-y", "-i", video_path,
        "-vf", "fps=1/3,showinfo",
        "-vsync", "vfr",
        os.path.join(out_dir, "%04d.jpg"),
    ]
    proc_fb = subprocess.run(cmd_fb, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding="utf-8", errors="ignore")

    image_paths = sorted(glob.glob(os.path.join(out_dir, "*.jpg")))
    if image_paths:
        approx_times = [i * 3.0 for i in range(len(image_paths))]
        return image_paths, approx_times

    # 3) ãã‚Œã§ã‚‚0ãªã‚‰å…ˆé ­1æšã ã‘ç¢ºä¿
    one_path = os.path.join(out_dir, "0001.jpg")
    subprocess.run([ff_cmd, "-y", "-ss", "00:00:01", "-i", video_path, "-vframes", "1", one_path],
                   stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding="utf-8", errors="ignore")
    image_paths = sorted(glob.glob(os.path.join(out_dir, "*.jpg")))
    if image_paths:
        return image_paths, [0.0]

    return [], []

# å…ˆé ­ä»˜è¿‘ï¼ˆimport ã®è¿‘ãï¼‰ã«å¿…è¦ãªã‚‰è¿½åŠ 
import numpy as np
import cv2
from PIL import Image

def _to_cv2_bgr(image_like):
    try:
        if isinstance(image_like, (bytes, bytearray)):
            arr = np.frombuffer(image_like, np.uint8)
            img = cv2.imdecode(arr, cv2.IMREAD_COLOR)
            return img

        if isinstance(image_like, str):
            img = cv2.imread(image_like, cv2.IMREAD_COLOR)
            if img is None:  # â† æ—¥æœ¬èªãƒ‘ã‚¹ç­‰ã§å¤±æ•—ã™ã‚‹ã‚±ãƒ¼ã‚¹ã«å¯¾å¿œ
                try:
                    pil = Image.open(image_like).convert("RGB")
                    return cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)
                except Exception:
                    return None
            return img

        if isinstance(image_like, Image.Image):
            return cv2.cvtColor(np.array(image_like), cv2.COLOR_RGB2BGR)

        if isinstance(image_like, np.ndarray):
            if image_like.ndim == 2:
                return cv2.cvtColor(image_like, cv2.COLOR_GRAY2BGR)
            return image_like
    except Exception:
        return None
    return None

def _get_reader():
    """EasyOCR Reader ã‚’ï¼ˆã‚ã‚Œã°ï¼‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ä½¿ã„å›ã—ã€‚"""
    try:
        import streamlit as st
        @st.cache_resource(show_spinner=False)
        def _cached_reader():
            return easyocr.Reader(['ja', 'en'], gpu=False)
        return _cached_reader()
    except Exception:
        return easyocr.Reader(['ja', 'en'], gpu=False)

def ocr_slides(image_paths: list) -> list[dict]:
    """
    image_paths: ç”»åƒãƒ‘ã‚¹/bytes/PIL/ndarray ãŒæ··åœ¨ã—ã¦ã„ã¦ã‚‚OK
    return: [{"index": i, "path": å…ƒã®å‚ç…§, "text": èªè­˜æ–‡å­—åˆ—}, ...]
    """
    if not image_paths:
        return []

    if easyocr is None:
        # EasyOCR ãŒç„¡ã„ç’°å¢ƒã§ã‚‚è½ã¡ãªã„ã‚ˆã†ã«ç©ºæ–‡å­—ã§è¿”ã™
        return [{"index": i+1, "path": p, "text": ""} for i, p in enumerate(image_paths)]

    reader = _get_reader()
    results = []
    valid_found = False

    for idx, src in enumerate(image_paths, start=1):
        img = _to_cv2_bgr(src)
        if img is None or getattr(img, "size", 0) == 0:
            # ç”»åƒåŒ–ã§ããªã‹ã£ãŸå ´åˆã§ã‚‚ç©ºæ–‡å­—ã§ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’è¿”ã™ï¼ˆè½ã¨ã•ãªã„ï¼‰
            results.append({"index": idx, "path": src, "text": ""})
            continue

        valid_found = True
        try:
            # detail=0 ã ã¨ãƒ†ã‚­ã‚¹ãƒˆã®ã¿è¿”ã‚‹ã€‚detail=1 ã§ã‚‚å¯ã€‚
            lines = reader.readtext(img, detail=0)
            text = "\n".join(lines) if lines else ""
            results.append({"index": idx, "path": src, "text": text})
        except Exception:
            # 1æšNGã§ã‚‚å…¨ä½“ã¯ç¶™ç¶š
            results.append({"index": idx, "path": src, "text": ""})

    # 1æšã‚‚æœ‰åŠ¹ç”»åƒãŒä½œã‚Œãªã‹ã£ãŸã¨ãã¯ãƒ¦ãƒ¼ã‚¶ã«é€šçŸ¥ï¼ˆStreamlitãŒã‚ã‚‹å ´åˆï¼‰
    if not valid_found:
        try:
            import streamlit as st
            st.error("OCRç”¨ã®ç”»åƒã‚’æ­£ã—ãèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸï¼ˆãƒ‘ã‚¹ãƒ»å½¢å¼ãƒ»æŠ½å‡ºå‡¦ç†ã‚’ã”ç¢ºèªãã ã•ã„ï¼‰ã€‚")
        except Exception:
            pass

    return results

# ---------------------- æ•´å½¢(ç”ŸæˆAIãªã—) ----------------------

def to_verbatim_with_timestamps(segments: List[Tuple[str, float, float]]) -> str:
    lines: List[str] = []
    for t, s, e in segments:
        start_disp = format_timestamp(s) if math.isfinite(s) else "â€¦"
        end_disp   = format_timestamp(e) if math.isfinite(e) else "â€¦"
        lines.append(f"[{start_disp} â†’ {end_disp}] {t}")
    return "\n".join(lines)


def heuristic_minutes(segments: List[Tuple[str, float, float]]) -> str:
    block, blocks, char_limit = [], [], 300
    for t, s, e in segments:
        if sum(len(x[0]) for x in block) + len(t) > char_limit and block:
            blocks.append(block); block = []
        block.append((t, s, e))
    if block: blocks.append(block)
    out = ["ã€è­°äº‹éŒ²ï¼ˆè‡ªå‹•æ•´å½¢ãƒ»è¦ç‚¹ï¼‰ã€‘\n"]
    for i, b in enumerate(blocks, 1):
        out.append(f"â–  ãƒˆãƒ”ãƒƒã‚¯{i}ï¼ˆ{format_timestamp(b[0][1])}â€“{format_timestamp(b[-1][2])}ï¼‰")
        for t, _, _ in b: out.append(f"ãƒ»{t}")
        out.append("")
    return "\n".join(out).strip()


def heuristic_abstract(segments: List[Tuple[str, float, float]]) -> str:
    text = " ".join(t for t, _, _ in segments)
    sentences = [s.strip() for s in text.replace("ã€‚", "ã€‚\n").splitlines() if s.strip()]
    return "ã€è¦æ—¨ï¼ˆè‡ªå‹•æŠ½å‡ºï¼‰ã€‘\n" + "\n".join(sentences[:6])


def heuristic_article_academic(segments: List[Tuple[str, float, float]]) -> str:
    body = " ".join(t for t, _, _ in segments)
    lines = [
        "ã€å­¦ä¼šå ±å‘Šè¨˜äº‹ï¼ˆè‡ªå‹•æ•´å½¢ãƒ»AIä¸ä½¿ç”¨ï¼‰ã€‘",
        "",
        "â–  ãƒªãƒ¼ãƒ‰",
        "æœ¬è¬›æ¼”ã§ã¯ã€æ¼”è€…ãŒæç¤ºã—ãŸä¸»è¦ãƒã‚¤ãƒ³ãƒˆã‚’æŠœç²‹ã—ã€å†…å®¹ã‚’ç°¡æ½”ã«æ•´ç†ã™ã‚‹ã€‚æœ¬æ–‡ã¯è‡ªå‹•æ•´å½¢ã®ãŸã‚ã€è¦ç‚¹ãƒ¬ãƒ™ãƒ«ã®æŠœç²‹ã§ã‚ã‚‹ã€‚",
        "",
        "â–  èƒŒæ™¯ãƒ»ç›®çš„",
        "è¬›æ¼”ã®èƒŒæ™¯ã€è‡¨åºŠä¸Šã®æ„ç¾©ã€ç›®çš„ã‚’æœ¬æ–‡ã‹ã‚‰æ©Ÿæ¢°çš„ã«æŠ½å‡ºãƒ»å†æ§‹æˆã€‚",
        "",
        "â–  æ–¹æ³•ãƒ»è³‡æ–™",
        "ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿ã€å¯¾è±¡ã€æ‰‹æ³•ã€è©•ä¾¡æŒ‡æ¨™ãªã©ã®è¨˜è¼‰ã‚’è¦ç‚¹ã¨ã—ã¦æŠ½å‡ºã€‚",
        "",
        "â–  çµæœãƒ»æ‰€è¦‹",
        "æœ¬æ–‡ã‹ã‚‰çµæœã«ç›¸å½“ã™ã‚‹æ–‡ã‚’å„ªå…ˆçš„ã«æ‹¾ã„ä¸Šã’åæ˜ ã€‚",
        "",
        "â–  è€ƒå¯Ÿãƒ»çµè«–",
        "è‡¨åºŠç¾å ´ã¸ã®ç¤ºå”†ã€é™ç•Œã€ä»Šå¾Œã®å±•æœ›ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹ã€‚",
        "",
        "â€” ä»¥ä¸‹ã¯é€èªãƒ™ãƒ¼ã‚¹æœ¬æ–‡ï¼ˆæ©Ÿæ¢°æŠ½å‡ºï¼‰ â€”",
        body,
    ]
    return "\n".join(lines)


def heuristic_guideline_commentary(slide_groups: List[Dict[str, Any]], ocr_notes: List[dict]) -> str:
    ocr_map = {o.get("index"): (o.get("text") or "").strip() for o in (ocr_notes or [])}
    lines = [
        "ã€ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬ï¼ˆè‡ªå‹•æ•´å½¢ãƒ»AIä¸ä½¿ç”¨ï¼‰ã€‘\n",
        "â–  èƒŒæ™¯",
        "ãƒ»æœ¬è§£èª¬ã¯æ¼”è€…ã‚¹ãƒ©ã‚¤ãƒ‰ã¨ã‚¹ãƒ”ãƒ¼ãƒå†…å®¹ã‚’å¯¾å¿œä»˜ã‘ã¦å†æ§‹æˆã—ãŸã‚‚ã®ã€‚",
        "",
    ]
    for g in slide_groups:
        idx, ocr = g["index"], ocr_map.get(g["index"], "")
        lines.append(f"â–¼ Slide {idx}ï¼ˆ{format_timestamp(g['start'])}â€“{fmt_ts(g['end'])}ï¼‰")
        if ocr:
            title = ocr.splitlines()[0][:50]
            lines.append(f"ã€ã‚¹ãƒ©ã‚¤ãƒ‰è¦æ—¨ã€‘{title}")
        for t, s, e in g["segments"][:6]:
            lines.append(f"ãƒ»{t}")
        lines.append("")
    lines += ["â–  è‡¨åºŠã¸ã®å«æ„", "ãƒ»æœ¬æ”¹è¨‚ã«ã‚ˆã‚Šæƒ³å®šã•ã‚Œã‚‹è¨ºç™‚ä¸Šã®å½±éŸ¿ç‚¹ã‚’è¦ç‚¹åŒ–ã€‚", "", "â–  ä»Šå¾Œã®èª²é¡Œ", "ãƒ»ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹å¼·åŒ–ãŒå¿…è¦ãªè«–ç‚¹ã€é‹ç”¨æ™‚ã®ç•™æ„ç‚¹ã€‚"]
    return "\n".join(lines).strip()


# ---------------------- ç›®çš„åˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆè¨˜äº‹åŒ–/è¦æ—¨/è­°äº‹éŒ² ç”¨ï¼‰ ----------------------

PURPOSE_PROMPTS = {
    "å­¦ä¼šç™ºè¡¨": (
        "ä»¥ä¸‹ã®ç´ æï¼ˆéŸ³å£°é€èªã¨ä»»æ„ã®ã‚¹ãƒ©ã‚¤ãƒ‰OCRè¦ç´„ï¼‰ã‹ã‚‰ã€å­¦ä¼šå ±å‘Šè¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        "è¦‹å‡ºã—ï¼ˆå°å…¥/èƒŒæ™¯/ç›®çš„/æ–¹æ³•/çµæœ/è€ƒå¯Ÿ/çµèªï¼‰ã‚’ä»˜ã‘ã€å›ºæœ‰åè©ã¨æ•°å€¤ã¯æ”¹å¤‰ã›ãšã€"
        "èª‡å¼µã‚„å‰µä½œã¯é¿ã‘ã¦ãã ã•ã„ã€‚å°‚é–€èª­è€…å‘ã‘ã«ç°¡æ½”ã§æ­£ç¢ºã«ã€‚"
    ),
    "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬": (
        "ä»¥ä¸‹ã®ç´ æã‹ã‚‰ã€æ—¥æœ¬èªã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³æ”¹è¨‚è§£èª¬è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        "èƒŒæ™¯/æ”¹è¨‚ãƒã‚¤ãƒ³ãƒˆ/æ¨å¥¨åº¦ãƒ»ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹/è‡¨åºŠã¸ã®å½±éŸ¿/èª²é¡Œ/ä»Šå¾Œã€ã®é †ã«ä¸€åº¦ã ã‘éª¨çµ„ã¿ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚"
        "ãƒ†ã‚­ã‚¹ãƒˆãŒè¤‡æ•°ãƒ‘ãƒ¼ãƒˆã«åˆ†å‰²ã•ã‚Œã‚‹å ´åˆã§ã‚‚ã€è¦‹å‡ºã—ãƒ»å°å…¥ã®å†æ²ã¯ã—ãªã„ã§ãã ã•ã„ã€‚"
        "æ—¢å‡ºå†…å®¹ã®å†æ²ã‚’é¿ã‘ã€æ–°è¦æƒ…å ±ã®ã¿è¿½è¨˜ã™ã‚‹å½¢ã§é€£ç¶šæ€§ã‚’ä¿ã£ã¦ãã ã•ã„ã€‚"
        "è‹±èªã¯æ­£ç¢ºã«æ—¥æœ¬èªåŒ–ã—ã€å¼•ç”¨ã¯è¦æ—¨åŒ–ã—ã¦æ›¸ãç›´ã—ã¦ãã ã•ã„ã€‚"
    ),
    "ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³": (
        "ä»¥ä¸‹ã®ç´ æã‹ã‚‰ã€ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        "è«–ç‚¹æ•´ç†/è³›å¦ã®ä¸»å¼µ/æ ¹æ‹ /ä¸€è‡´ç‚¹ã¨ç›¸é•ç‚¹/çµè«–ã¨ä»Šå¾Œã®æ¤œè¨èª²é¡Œã€ã®é †ã§ã€ä¸­ç«‹ãƒ»ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚"
        "å†—é•·ãªå£èªè¡¨ç¾ã¯å‰Šé™¤ã—ã€æ–¹è¨€ã¯æ¨™æº–èªã«ç›´ã—ã¦ãã ã•ã„ã€‚"
    ),
}


# ---------------------- LLM å‡ºåŠ›ï¼ˆè¨˜äº‹åŒ–/è¦æ—¨/è­°äº‹éŒ²ï¼‰ ----------------------

def llm_rewrite(kind: str, text: str, api_key: str | None,
                purpose: str | None = None,
                source_lang: str | None = None,
                target_lang: str | None = "ja") -> str:
    """
    è¨˜äº‹åŒ–ãƒ»è¦æ—¨ãƒ»è­°äº‹éŒ²ãƒ»é€èªï¼ˆè»½æ•´å½¢ï¼‰ç”¨ã€‚
    â€» ç›´è¨³ã¯ä½¿ã‚ãšã€åˆ¥é–¢æ•° llm_translate_only() ã‚’ä½¿ã†ã“ã¨ï¼
    """
    if openai_mod is None:
        return "[LLMæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«] `pip install -U openai` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"

    if not api_key:
        api_key = os.getenv("OPENAI_API_KEY", "")
    if not api_key:
        return "[APIã‚­ãƒ¼æœªå…¥åŠ›] ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§APIã‚­ãƒ¼ã‚’å…¥ã‚Œã‚‹ã‹ã€ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"

    sys_prompt = (
        "ã‚ãªãŸã¯åŒ»å­¦ãƒ»åŒ»ç™‚ç³»ã®æ—¥æœ¬èªç·¨é›†è€…ã§ã™ã€‚è‡¨åºŠãƒ»å­¦è¡“æ–‡è„ˆã«æ²¿ã£ã¦ã€"
        "èª­ã¿ã‚„ã™ãäº‹å®Ÿé–¢ä¿‚ã‚’ä¿ã£ãŸã¾ã¾æ•´æ–‡ã—ã¾ã™ã€‚æ•°å€¤ã‚„å¼•ç”¨ã¯æ”¹å¤‰ã—ã¾ã›ã‚“ã€‚"
    )
    pre = PURPOSE_PROMPTS.get(purpose or "å­¦ä¼šç™ºè¡¨", "")

    if (target_lang or "ja").lower() == "ja":
        lang_policy = (
            "æœ€çµ‚å‡ºåŠ›ã¯å¿…ãšæ—¥æœ¬èªã§æ›¸ã„ã¦ãã ã•ã„ã€‚éŸ³å£°/ã‚¹ãƒ©ã‚¤ãƒ‰ãŒæ—¥æœ¬èªã§ãªã„å ´åˆã¯æ­£ç¢ºã«æ—¥æœ¬èªã¸ç¿»è¨³ã—ã€"
            "å°‚é–€ç”¨èªã¯é©åˆ‡ãªæ—¥æœ¬èªè¨³ã‚’ç”¨ã„ã€å›ºæœ‰åè©ãƒ»æ•°å€¤ãƒ»å˜ä½ã¯ä¿æŒã—ã¦ãã ã•ã„ã€‚"
        )
        if source_lang and str(source_lang).lower() != "ja":
            lang_policy += "ï¼ˆå…¥åŠ›ã¯æ—¥æœ¬èªä»¥å¤–ã¨æ¤œå‡ºã•ã‚ŒãŸãŸã‚ç¿»è¨³ãŒå¿…è¦ã§ã™ï¼‰"
    else:
        lang_policy = f"æœ€çµ‚å‡ºåŠ›ã¯å¿…ãš {target_lang} ã§æ›¸ã„ã¦ãã ã•ã„ã€‚å›ºæœ‰åè©ãƒ»æ•°å€¤ãƒ»å˜ä½ã¯ä¿æŒã—ã¦ãã ã•ã„ã€‚"

    user_prompt_map = {
        "verbatim": "é€èªè¨˜éŒ²ï¼ˆè»½å¾®ãªå¥èª­ç‚¹æ•´å½¢ã®ã¿ã€æ„å‘³æ”¹å¤‰ç¦æ­¢ï¼‰ï¼š\n\n" + text,
        "minutes":  "è­°äº‹éŒ²ï¼ˆè¦‹å‡ºã—ï¼‹ç®‡æ¡æ›¸ãã€æ™‚ç³»åˆ—ï¼‰ï¼š\n\n" + text,
        "abstract": "å­¦ä¼šæŠ„éŒ²ï¼ˆç›®çš„/æ–¹æ³•/çµæœ/çµè«–ã€600-900å­—ï¼‰ï¼š\n\n" + text,
        "article":  "è¨˜äº‹åŒ–ï¼ˆå°å…¥/èƒŒæ™¯/ç›®çš„/æ–¹æ³•/çµæœ/è€ƒå¯Ÿ/çµèªï¼‰ï¼š\n\n" + text,
    }
    if kind not in user_prompt_map:
        kind = "article"

    prompt = (pre + "\n\n" + lang_policy + "\n\n" + user_prompt_map[kind]).strip()

    client = openai_mod.OpenAI(api_key=api_key) if hasattr(openai_mod, "OpenAI") else None
    try:
        if client:
            resp = client.chat.completions.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "system", "content": sys_prompt},
                          {"role": "user", "content": prompt}],
                temperature=0.1,
            )
            result = resp.choices[0].message.content
        else:
            openai_mod.api_key = api_key
            resp = openai_mod.ChatCompletion.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "system", "content": sys_prompt},
                          {"role": "user", "content": prompt}],
                temperature=0.1,
            )
            result = resp["choices"][0]["message"]["content"]
    except Exception as e:
        return f"[LLMã‚¨ãƒ©ãƒ¼] {e}"

    if kind != "verbatim":
        result = "ã€AIæ•´å½¢ã€‘\n" + result
    return result


# ---------------------- LLM ç›´è¨³ï¼ˆç¿»è¨³å°‚ç”¨ãƒ»æ•´å½¢ä¸€åˆ‡ãªã—ï¼‰ ----------------------

def llm_translate_only(text: str, api_key: str | None,
                       source_lang: str | None = None,
                       target_lang: str = "ja") -> str:
    """
    é€èªçš„ãªç¿»è¨³ã«ç‰¹åŒ–ã€‚è¨˜äº‹åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¸€åˆ‡ä»˜ã‘ãªã„ã€‚
    - è¦ç´„ãƒ»è¦‹å‡ºã—ãƒ»ç®‡æ¡æ›¸ãã®è¿½åŠ ã¯ç¦æ­¢
    - ã€Œã€AIæ•´å½¢ã€‘ã€ç­‰ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚‚ä»˜ã‘ãªã„
    """
    if openai_mod is None:
        return "[LLMæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«] `pip install -U openai` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
    if not api_key:
        api_key = os.getenv("OPENAI_API_KEY", "")
    if not api_key:
        return "[APIã‚­ãƒ¼æœªå…¥åŠ›] ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§APIã‚­ãƒ¼ã‚’å…¥ã‚Œã‚‹ã‹ã€ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"

    sys_prompt = (
        "ã‚ãªãŸã¯å¿ å®Ÿãªå°‚é–€ç¿»è¨³è€…ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’é€èªçš„ã«æ—¥æœ¬èªã¸ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚"
        "è¦ç´„ãƒ»æ„è¨³ãƒ»è¦‹å‡ºã—ä»˜ã‘ãƒ»ç®‡æ¡æ›¸ãåŒ–ãƒ»ä½“è£å¤‰æ›´ã¯è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚"
        "æ®µè½ã‚„æ”¹è¡Œç­‰ã®æ§‹é€ ã¯å¯èƒ½ãªé™ã‚Šä¿æŒã—ã€å›ºæœ‰åè©ãƒ»æ•°å€¤ãƒ»å˜ä½ã¯ç¶­æŒã—ã¦ãã ã•ã„ã€‚"
    )
    if (target_lang or "ja").lower() != "ja":
        sys_prompt = sys_prompt.replace("æ—¥æœ¬èª", target_lang)

    prompt = "ã€ç¿»è¨³å¯¾è±¡ã€‘\n" + text

    client = openai_mod.OpenAI(api_key=api_key) if hasattr(openai_mod, "OpenAI") else None
    try:
        if client:
            resp = client.chat.completions.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "system", "content": sys_prompt},
                          {"role": "user", "content": prompt}],
                temperature=0.0,
            )
            return resp.choices[0].message.content
        else:
            openai_mod.api_key = api_key
            resp = openai_mod.ChatCompletion.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "system", "content": sys_prompt},
                          {"role": "user", "content": prompt}],
                temperature=0.0,
            )
            return resp["choices"][0]["message"]["content"]
    except Exception as e:
        return f"[LLMã‚¨ãƒ©ãƒ¼] {e}"

# ---------------------- LLM: ç›´è¨³æ—¥æœ¬èª â†’ è¨˜äº‹èª¿ï¼ˆé‡è¤‡ä»¥å¤–ã‚’å‰Šã‚‰ãªã„ï¼‰ ----------------------
def llm_article_from_literal(literal_ja: str,
                             api_key: str | None,
                             purpose: str | None = "å­¦ä¼šç™ºè¡¨") -> str:
    """
    é€èªç›´è¨³ï¼ˆæ—¥æœ¬èªï¼‰ã‚’ç´ æã«ã€å‰Šã‚Šã™ãã‚’é¿ã‘ã¤ã¤è¨˜äº‹èª¿ï¼ˆå¸¸ä½“ï¼‰ã¸æ•´æ–‡ã€‚
    - é‡è¤‡ä»¥å¤–ã¯å‰Šã‚‰ãªã„ï¼ˆ=æ„å‘³ã®è½ã¡ã‚’é˜²ãï¼‰
    - æ•°å€¤ãƒ»è©¦é¨“åãƒ»è–¬å‰¤åã¯ä¿æŒ
    - èªé †ã‚„ã¤ãªãã®èª¿æ•´ã¯å¯ï¼ˆèª­ã¿ã‚„ã™ã•ç¢ºä¿ï¼‰
    """
    if openai_mod is None:
        return "[LLMæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«] `pip install -U openai` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
    if not api_key:
        api_key = os.getenv("OPENAI_API_KEY", "")
    if not api_key:
        return "[APIã‚­ãƒ¼æœªå…¥åŠ›] ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§APIã‚­ãƒ¼ã‚’å…¥ã‚Œã‚‹ã‹ã€OPENAI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"

    sys_prompt = (
        "ã‚ãªãŸã¯åŒ»ç™‚ãƒ»åŒ»å­¦åˆ†é‡ã®ç·¨é›†è€…ã€‚å…¥åŠ›ã¯æ—¢ã«æ—¥æœ¬èªã¸é€èªç›´è¨³ã•ã‚ŒãŸåŸç¨¿ã€‚"
        "é‡è¤‡ãƒ»è¨€ã„æ›ãˆã®å†—é•·ã ã‘ã‚’æ•´ç†ã—ã€æ„å‘³ãƒ»äº‹å®Ÿã¯è½ã¨ã•ãšè¨˜äº‹èª¿ï¼ˆå¸¸ä½“ï¼‰ã«æ•´ãˆã‚‹ã€‚"
        "ã€å³å®ˆã€‘é‡è¤‡ä»¥å¤–ã®å‰Šé™¤ç¦æ­¢ï¼æ•°å€¤ãƒ»è©¦é¨“åãƒ»è–¬å‰¤åãƒ»ç”¨é‡ãƒ»å˜ä½ã¯ä¿æŒã€‚"
        "è¦‹å‡ºã—ã¯ã€å°å…¥/èƒŒæ™¯/ç›®çš„/æ–¹æ³•/çµæœ/è€ƒå¯Ÿ/çµèªã€ã®é †ã§ä¸€åº¦ã ã‘ã€‚"
        "è„šè‰²ãƒ»æ–°æƒ…å ±ã®è¿½åŠ ã¯ç¦æ­¢ã€‚"
        "æ–‡æœ«ã¯å¸¸ä½“ï¼ˆã€œã ï¼ã€œã§ã‚ã‚‹ï¼‰ã«çµ±ä¸€ã—ã€ã§ã™ãƒ»ã¾ã™èª¿ã¯ç¦æ­¢ã€‚"  # â† è¿½åŠ 
    )
    preface = {
        "å­¦ä¼šç™ºè¡¨": "å­¦ä¼šå ±å‘Šã®é€Ÿå ±ãƒˆãƒ¼ãƒ³ã§ã€å°‚é–€èª­è€…å‘ã‘ã«ç°¡æ½”ã§æ­£ç¢ºã«ã€‚",
        "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬": "è§£èª¬è¨˜äº‹ã®æ–‡ä½“ã§ã€èƒŒæ™¯â†’è¦ç‚¹â†’è‡¨åºŠçš„å«æ„ã‚’æ˜ç¢ºã«ã€‚",
        "ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³": "è«–ç‚¹ã‚’æ˜ç¢ºåŒ–ã—ã¤ã¤ä¸­ç«‹ã«è¨˜è¿°ã€‚"
    }.get(purpose or "å­¦ä¼šç™ºè¡¨", "å°‚é–€èª­è€…å‘ã‘ã«ç°¡æ½”ã§æ­£ç¢ºã«ã€‚")

    user_prompt = (
        f"{preface}\n\n"
        "ã€å…¥åŠ›ï¼ˆé€èªç›´è¨³ãƒ»æ—¥æœ¬èªï¼‰ã€‘\n"
        + literal_ja.strip()
        + "\n\nã€å‡ºåŠ›ä»•æ§˜ã€‘\n"
          "- TCROSS NEWS å­¦ä¼šç™ºè¡¨è¨˜äº‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«æ•´å½¢ã™ã‚‹ã“ã¨ã€‚\n"
          "- ã‚¿ã‚¤ãƒˆãƒ«ã¯ã€Œå¯¾è±¡/ç–¾æ‚£ãƒ»ä»‹å…¥: è©¦é¨“åã€ã¨ã™ã‚‹ã€‚\n"
          "- ç¬¬1æ®µè½ã¯ã€Œâ–³â–³è©¦é¨“ã‚ˆã‚Šã€â–¡â–¡ã“ã¨ãŒã€å›½ã€æ‰€å±ã€æ¼”è€…åã«ã‚ˆã‚Šã€å­¦ä¼šåã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³åã§ç™ºè¡¨ã•ã‚ŒãŸã€‚ã€ã¨ã„ã†å½¢ã§æ›¸ãï¼ˆConclusionã®å†’é ­æ–‡ã‚’åæ˜ ï¼‰ã€‚\n"
          "- ç¬¬2æ®µè½ã¯è©¦é¨“ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’è¨˜è¼‰ï¼ˆè©¦é¨“åã€ç™»éŒ²æœŸé–“ã€å›½ãƒ»æ–½è¨­æ•°ã€æ‚£è€…æ•°ã€ç¾¤å‰²ä»˜ã‘ã€å‰²ä»˜ã‘æ•°ï¼‰ã€‚\n"
          "- ç¬¬3æ®µè½ã¯æ‚£è€…èƒŒæ™¯ã‚’è©³ç´°ã«è¨˜è¼‰ï¼ˆå·®ãŒãªã‘ã‚Œã°å¹³å‡å€¤ã§ã€å¹´é½¢ãƒ»æ€§åˆ¥ãƒ»ä½µå­˜ç—‡ãƒ»è–¬å‰¤å‡¦æ–¹ç‡ã‚’å«ã‚ã‚‹ï¼‰ã€‚\n"
          "- ç¬¬4æ®µè½ã¯ä¸»è¦è©•ä¾¡é …ç›®ã®çµæœã‚’è¨˜è¼‰ï¼ˆè¿½è·¡æœŸé–“ã€ã‚¤ãƒ™ãƒ³ãƒˆç‡ã€HRã€95%CIã€på€¤ã‚’ä¿æŒï¼‰ã€‚\n"
          "- ç¬¬5æ®µè½ä»¥é™ã«ã‚µãƒ–è§£æçµæœãŒã‚ã‚Œã°è¨˜è¼‰ã€‚\n"
          "- æœ€çµ‚æ®µè½ã¯æ¼”è€…ã®ãƒ©ã‚¹ãƒˆãƒãƒ¼ãƒ ã‹ã‚‰å§‹ã‚ã€ã€Œâ€¦ã¨ã€ã¾ã¨ã‚ãŸã€‚ã€ã§å¿…ãšç· ã‚ã‚‹ã€‚\n"
          "- åŒæ™‚æ²è¼‰ãŒã‚ã‚Œã°ã€Œå°šã€â–³â–³è©¦é¨“ã¯â—‹â—‹èªŒã«æ²è¼‰ã•ã‚ŒãŸã€‚ã€ã¨åŠ ãˆã‚‹ã€‚\n"
          "- è¨˜äº‹èª¿ï¼ˆå¸¸ä½“ï¼‰ã€‚\n"
          "- è¦‹å‡ºã—ã¯ã€å°å…¥/èƒŒæ™¯/ç›®çš„/æ–¹æ³•/çµæœ/è€ƒå¯Ÿ/çµèªã€ã€‚\n"
          "- å†—é•·ãªé‡è¤‡ã¯çµ±åˆã€‚ãã®ä»–ã®å†…å®¹ã¯æ®‹ã™ï¼ˆå‰Šã‚Šã™ãç¦æ­¢ï¼‰ã€‚\n"
          "- æ•°å€¤ãƒ»ç”¨èªã¯ãã®ã¾ã¾ä¿æŒã€‚\n"
          "- ç®‡æ¡æ›¸ãã§ã¯ãªãæ®µè½ã”ã¨ã«ã¾ã¨ã‚ã€è«–ç†çš„ãªæµã‚Œã‚’æŒãŸã›ã‚‹ã€‚\n"
          "- è©¦é¨“èƒŒæ™¯â†’æ–¹æ³•â†’æ‚£è€…èƒŒæ™¯â†’çµæœâ†’è§£é‡ˆâ†’åˆ¶é™â†’çµè«–ã®æµã‚Œã‚’åŸºæœ¬ã¨ã™ã‚‹ã€‚\n"
          "- å…¨ä½“ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚’è½ã¨ã•ãšã€åŸæ–‡ã¨åŒç­‰ã®æƒ…å ±é‡ã‚’ä¿ã¤ã€‚\n"
          "- è¦ç´„ã§ã¯ãªãã€æ§‹æˆæ•´ç†ã¨æ–‡ä½“å¤‰æ›ã‚’ä¸»ç›®çš„ã¨ã™ã‚‹ã€‚\n"
          "- åŒ»å­¦ç³»ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚„å­¦è¡“èªŒé€Ÿå ±è¨˜äº‹ã«ãµã•ã‚ã—ã„æ–‡ä½“ã‚’ç”¨ã„ã‚‹ã€‚\n"
          "- æ¼”è€…ãŒæç¤ºã—ãŸæ‚£è€…èƒŒæ™¯ã€æ‰‹æŠ€ç‰¹å¾´ã€è–¬ç‰©ç™‚æ³•ã®è©³ç´°ã¯å¿…ãšå«ã‚ã‚‹ï¼ˆæ•°å€¤ãƒ»å‰²åˆãƒ»ãƒ¬ã‚¸ãƒ¡ãƒ³ã‚’çœç•¥ã—ãªã„ï¼‰ã€‚\n"
          "- çµæœéƒ¨åˆ†ã¯é€èªæ€§ã‚’å„ªå…ˆã—ã€çœç•¥ã‚„è¦ç´„ã¯ä¸€åˆ‡ç¦æ­¢ã™ã‚‹ï¼ˆçµ±è¨ˆå€¤ãƒ»HRãƒ»På€¤ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆç‡ãªã©ã‚’å¿…ãšæ®‹ã™ï¼‰ã€‚\n"
          "- æœˆæ•°ã®è¡¨è¨˜ã¯ã€Œã‹æœˆã€ã§ã¯ãªãã€Œãƒ¶æœˆã€ã‚’ç”¨ã„ã‚‹ï¼ˆä¾‹ï¼š6ãƒ¶æœˆã€12ãƒ¶æœˆï¼‰ã€‚\n"
          "- è‹±èªã‚¹ã‚¯ãƒªãƒ—ãƒˆã«å«ã¾ã‚Œã‚‹ã€Œçµæœã€ã®é€èªå†…å®¹ã¯å‰Šã‚‰ãšã€å…¨ã¦æ—¥æœ¬èªã«åæ˜ ã™ã‚‹ã€‚\n"
          "- çµæœã«é–¢ã™ã‚‹é€èªçš„ãªçµ±è¨ˆæ•°å€¤ãƒ»ç™ºè¨€å†…å®¹ï¼ˆã‚¤ãƒ™ãƒ³ãƒˆç‡ãƒ»ãƒã‚¶ãƒ¼ãƒ‰æ¯”ãƒ»på€¤ãƒ»ã‚µãƒ–è§£æãªã©ï¼‰ã¯çœç•¥ç¦æ­¢ã€‚\n"
          "- çµæœã¯é€èªã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æƒ…å ±é‡ã‚’ä¿æŒã—ãŸã¾ã¾è¨˜äº‹èª¿ã«æ•´ãˆã‚‹ã“ã¨ã€‚\n"
          "- å‡ºåŠ›ã¯å…¥åŠ›ã¨åŒç­‰ã®æƒ…å ±é‡ã‚’ä¿æŒã—ã€æ–‡å­—æ•°ã¯ãŠãŠã‚€ã­ {int(target_chars*0.95)}ã€œ{int(target_chars*1.05)} æ–‡å­—ï¼ˆÂ±5%ï¼‰ã«åã‚ã‚‹ã€‚\n"
          "- çŸ­ç¸®ãƒ»è¦ç´„ã‚’ç¦æ­¢ã€‚æ®µè½æ•´ç†ãƒ»æ–‡ä½“æ•´å½¢ãƒ»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåŒ–ã®ã¿è¡Œã†ã€‚\n"
          "- çµæœãƒ»æ‚£è€…èƒŒæ™¯ãƒ»æ‰‹æŠ€ãƒ»è–¬ç‰©ç™‚æ³•ãƒ»é™ç•Œãƒ»è€ƒå¯Ÿã®é€èªæƒ…å ±ã¯çœç•¥ç¦æ­¢ï¼ˆçµ±è¨ˆå€¤ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆç‡ãƒ»HRãƒ»95%CIãƒ»på€¤ãƒ»ã‚µãƒ–è§£æã‚’å«ã‚€ï¼‰ã€‚\n"
    )

    client = openai_mod.OpenAI(api_key=api_key) if hasattr(openai_mod, "OpenAI") else None
    try:
        if client:
            resp = client.chat.completions.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "system", "content": sys_prompt},
                          {"role": "user", "content": user_prompt}],
                temperature=0.15,
            )
            return "ã€AIæ•´å½¢ï¼ˆç›´è¨³â†’è¨˜äº‹èª¿ï¼‰ã€‘\n" + resp.choices[0].message.content
        else:
            openai_mod.api_key = api_key
            resp = openai_mod.ChatCompletion.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "system", "content": sys_prompt},
                          {"role": "user", "content": user_prompt}],
                temperature=0.15,
            )
            return "ã€AIæ•´å½¢ï¼ˆç›´è¨³â†’è¨˜äº‹èª¿ï¼‰ã€‘\n" + resp["choices"][0]["message"]["content"]
    except Exception as e:
        return f"[LLMã‚¨ãƒ©ãƒ¼] {e}"

# ---------------------- DOCXå‡ºåŠ› ----------------------

def make_docx(title: str, content: str) -> bytes:
    doc = Document()
    style = doc.styles['Normal']
    font = style.font
    font.name = 'Yu Gothic'
    font.size = Pt(11)

    doc.add_heading(title or "å‡ºåŠ›", level=1)
    for line in content.splitlines():
        if line.strip() == "":
            doc.add_paragraph("")
        else:
            doc.add_paragraph(line)

    buf = io.BytesIO()
    doc.save(buf)
    buf.seek(0)
    return buf.read()


# ---------------------- Streamlit UI ----------------------

def main():
    st.set_page_config(page_title="InsighTCROSSÂ® Smart Writer v11", layout="wide")
    # ğŸ” æœ€åˆã«èªè¨¼ã‚’ã‹ã‘ã‚‹
    require_password()
        
    if "workdir" not in st.session_state:
        st.session_state["workdir"] = os.path.abspath("./.work")
        os.makedirs(st.session_state["workdir"], exist_ok=True)

    st.title("InsighTCROSSÂ® Smart Writer v11")
    if "transcript_text" not in st.session_state:
        st.session_state["transcript_text"] = ""
    if "generated_text" not in st.session_state:
        st.session_state["generated_text"] = ""
    st.write("éŸ³å£°/å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€é€èªãƒ»ç›´è¨³ãƒ»è­°äº‹éŒ²ãƒ»è¦æ—¨ãƒ»è¨˜äº‹ã«æ•´å½¢ã€‚å‹•ç”»ã¯ã‚¹ãƒ©ã‚¤ãƒ‰OCRä½µç”¨ã‚‚å¯èƒ½ã€‚ç”ŸæˆAIã¯ä»»æ„ã§ã™ã€‚")

    with st.sidebar:
        st.header("è¨­å®š")
        file_type = st.radio("ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—", ["è‡ªå‹•åˆ¤å®š", "éŸ³å£°", "å‹•ç”»"], index=0)
        use_slide_ocr = st.toggle("ã‚¹ãƒ©ã‚¤ãƒ‰OCRã‚‚ä½µç”¨ï¼ˆå‹•ç”»æ™‚ï¼‰", value=False,
                                  help="ã‚¹ãƒ©ã‚¤ãƒ‰ã®ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã—OCRã§æ–‡å­—ã‚‚å–ã‚Šè¾¼ã¿ã¾ã™")
        scene_sensitivity = st.slider("ã‚·ãƒ¼ãƒ³å¤‰åŒ–æ„Ÿåº¦", 0.10, 0.60, 0.35, 0.01)

        model_size = st.selectbox("Whisperãƒ¢ãƒ‡ãƒ«", ["tiny","base","small","medium"], index=2)
        compute_type = st.selectbox("Compute type", ["auto","int8","int8_float16","float16","float32"], index=0)
        language = st.text_input("è¨€èªã‚³ãƒ¼ãƒ‰", value="auto")

        output_lang_label = st.selectbox("å‡ºåŠ›è¨€èª", ["æ—¥æœ¬èª (JPN)", "English (EN)"], index=0)
        output_lang = "ja" if "JPN" in output_lang_label else "en"

        out_kind = st.selectbox(
            "å‡ºåŠ›ã‚¿ã‚¤ãƒ—",
            ["é€èª(ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—)", "ç›´è¨³ï¼ˆæ—¥æœ¬èªåŒ–ã®ã¿ï¼‰", "è­°äº‹éŒ²", "è¦æ—¨", "è¨˜äº‹", "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬"]
        )
        purpose = st.selectbox("è¨˜äº‹åŒ–ã®ç›®çš„", ["å­¦ä¼šç™ºè¡¨", "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬", "ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³"], index=0)
        attach_verbatim = st.toggle("æœ«å°¾ã«é€èªåŸæ–‡ã‚’æ·»ä»˜", value=False,
                                    help="åŸæ–‡è¨€èªã®é€èªãƒ†ã‚­ã‚¹ãƒˆã‚’æœ«å°¾ã«ä»˜ã‘ã¾ã™ï¼ˆé€šå¸¸ã¯OFFæ¨å¥¨ï¼‰")
        use_llm = st.toggle("ç”ŸæˆAIã§æ•´å½¢ï¼ˆä»»æ„ï¼‰", value=False)
        api_key_input = ""
        if use_llm:
            api_key_input = st.text_input("OpenAI API Key", type="password",
                                          help="æœªå…¥åŠ›ãªã‚‰ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã‚’å‚ç…§")
            if not api_key_input:
                st.warning("ç”ŸæˆAIã§æ•´å½¢ãŒONã§ã™ãŒ APIã‚­ãƒ¼ãŒæœªå…¥åŠ›ã§ã™ã€‚AIæ•´å½¢ã¯å®Ÿè¡Œã•ã‚Œãšã€å…ƒè¨€èªã®ã¾ã¾å‡ºåŠ›ã•ã‚Œã¾ã™ã€‚")

    uploaded = st.file_uploader(
        "éŸ³å£°/å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (mp3, m4a, wav, mp4, mov ãªã©)",
        type=["mp3","m4a","wav","mp4","mov","mkv","aac","flac"]
    )

    if not uploaded:
        return

    st.info(f"å—ä¿¡: {uploaded.name} / {uploaded.size/1024:.1f} KB")
    temp_path = save_uploaded_file_to_temp(uploaded)
    guessed = (uploaded.type or mimetypes.guess_type(uploaded.name)[0] or "")
    is_video = (file_type == "å‹•ç”»") or (file_type == "è‡ªå‹•åˆ¤å®š" and guessed.startswith("video/"))

    with st.spinner("å¤‰æ›ä¸­ï¼ˆWAV 16kHz monoï¼‰..."):
        wav_path = ensure_wav(temp_path)
    segments, detected_lang = transcribe_faster_whisper(
        wav_path=wav_path,
        model_size=model_size,
        language="en",
        compute_type=compute_type,
    )
    st.success(f"æ–‡å­—èµ·ã“ã—å®Œäº†ã€‚ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(segments)} / è¨€èªæ¤œå‡º: {detected_lang}")

    # é€èªï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰åŸç¨¿
    verbatim_text = to_verbatim_with_timestamps(segments)
    st.session_state["transcript_text"] = verbatim_text

    st.subheader("âœï¸ é€èªãƒ†ã‚­ã‚¹ãƒˆï¼ˆç·¨é›†å¯ï¼‰")
    st.session_state["transcript_text"] = st.text_area(
        "é€èªï¼ˆå¿…è¦ã«å¿œã˜ã¦ä¿®æ­£ã—ã¦ãã ã•ã„ï¼‰",
        value=st.session_state["transcript_text"],
        height=300
    )

    # ã‚¹ãƒ©ã‚¤ãƒ‰OCRï¼ˆä»»æ„ï¼‰
    slide_groups, slide_notes, slide_digest = [], [], ""
    if is_video and use_slide_ocr:
        with st.spinner("ã‚¹ãƒ©ã‚¤ãƒ‰æŠ½å‡ºï¼ˆã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ +æ™‚åˆ»ï¼‰â†’ OCR ä¸­..."):
            frames, slide_times = extract_slide_keyframes_with_times(
                video_path=temp_path,
                out_dir=os.path.join(st.session_state["workdir"], "slides"),
                scene_thr=scene_sensitivity,
            )

            # === ã“ã“ã‹ã‚‰è¿½åŠ ã®è¦‹ãˆã‚‹åŒ–ãƒ‡ãƒãƒƒã‚° ===
            st.write(f"æŠ½å‡ºãƒ•ãƒ¬ãƒ¼ãƒ æšæ•°: {len(frames)} / åˆ‡æ›¿æ¤œå‡º: {len(slide_times)}")
            if frames:
                st.write("å…ˆé ­3æšã®ãƒ‘ã‚¹:", frames[:3])
                try:
                    st.image(frames[0], caption="ã‚¹ãƒ©ã‚¤ãƒ‰æŠ½å‡ºãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå…ˆé ­ï¼‰", use_container_width=True)
                except Exception as e:
                    st.warning(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºã«å¤±æ•—: {e}")
            else:
                st.warning("æŠ½å‡ºã•ã‚ŒãŸç”»åƒãŒ0æšã§ã™ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒåŠ¹ã„ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            # === ã“ã“ã¾ã§è¿½åŠ  ===

            slide_notes = ocr_slides(frames)
            slide_groups = group_segments_by_slides(segments, slide_times)
            slide_digest = "\n\n".join(
                [f"[Slide {s['index']}]\n{s.get('text','')}" for s in slide_notes if s.get('text','').strip()]
            )
        st.success(f"ã‚¹ãƒ©ã‚¤ãƒ‰æŠ½å‡º: {len(slide_notes)} æš / åˆ‡æ›¿: {len(slide_times)} ç‚¹")

    edited_transcript = st.session_state["transcript_text"]
    cleaned_for_llm = strip_timestamps(edited_transcript)

    if out_kind == "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬" and slide_groups:
        chunks = []
        for g in slide_groups:
            idx = g["index"]
            ocr_text = ""
            for s in (slide_notes or []):
                if s.get("index") == idx:
                    ocr_text = (s.get("text") or "").strip()
                    break
            speech_text = "\n".join([t for (t, _, _) in g["segments"]])
            chunks.append(
                f"[Slide {idx} {format_timestamp(g['start'])}â€“{fmt_ts(g['end'])}]\n"
                f"<OCR>\n{ocr_text}\n</OCR>\n<SPEECH>\n{speech_text}\n</SPEECH>"
            )
        llm_source = "ã€ã‚¹ãƒ©ã‚¤ãƒ‰åˆ¥ç´ æã€‘\n" + "\n\n".join(chunks)
    else:
        llm_source = cleaned_for_llm if not slide_digest else (
            f"ã€éŸ³å£°é€èªã€‘\n{cleaned_for_llm}\n\nã€ã‚¹ãƒ©ã‚¤ãƒ‰OCRã€‘\n{slide_digest}"
        )

    # ---- æ—¢å®šï¼ˆãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ï¼‰å‡ºåŠ›
    if out_kind == "é€èª(ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—)":
        base_out = to_verbatim_with_timestamps(segments); kind_key = "verbatim"
    elif out_kind == "è­°äº‹éŒ²":
        base_out = heuristic_minutes(segments); kind_key = "minutes"
    elif out_kind == "è¦æ—¨":
        base_out = heuristic_abstract(segments); kind_key = "abstract"
    elif out_kind == "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬":
        base_out = heuristic_guideline_commentary(slide_groups, slide_notes) if slide_groups else \
                   "ã€ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬ï¼ˆç°¡æ˜“ï¼‰ã€‘\n" + heuristic_article_academic(segments)
        kind_key = "article"
    else:
        base_out = heuristic_article_academic(segments); kind_key = "article"

    final_out = base_out

    # ---------------- ç”ŸæˆAIã§æ•´å½¢ãƒœã‚¿ãƒ³ ----------------
    st.markdown("---")
    st.subheader("ğŸ§  ç”ŸæˆAIã§æ•´å½¢ã™ã‚‹")
    label_lang = "æ—¥æœ¬èª" if output_lang == "ja" else "English"
    do_generate = st.button(f"âœ¨ ç”ŸæˆAIã§æ•´å½¢ï¼ˆ{label_lang}ã§å‡ºåŠ›ï¼‰")

    if not do_generate:
        st.text_area("çµæœãƒ†ã‚­ã‚¹ãƒˆ", value=final_out or "", height=400)
        return

    # æŠ¼ä¸‹å¾Œ
    if use_llm and not api_key_input:
        st.error("ç”ŸæˆAIã§æ•´å½¢ãŒONã§ã™ãŒ APIã‚­ãƒ¼ãŒæœªå…¥åŠ›ã§ã™ã€‚AIæ•´å½¢ã¯å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
        st.stop()
    
    # ï¼ˆä»»æ„ï¼‰å¤ã„ç›´è¨³ã‚’ã‚¯ãƒªã‚¢ã—ã¦ãŠã
    st.session_state.pop("ja_literal_for_article", None)

    final_out = base_out
    try:
        if use_llm and api_key_input:
            if out_kind == "é€èª(ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—)":
                with st.spinner("ç”ŸæˆAIã§æ•´å½¢ä¸­..."):
                    final_out = llm_rewrite(
                        kind="verbatim",
                        text="ã€å‡ºåŠ›ã¯å¿…ãšæ—¥æœ¬èªã€‘\n" + st.session_state["transcript_text"],
                        api_key=api_key_input,
                        purpose=purpose,
                        source_lang=detected_lang,
                        target_lang=output_lang,
                    )
            elif out_kind == "ç›´è¨³ï¼ˆæ—¥æœ¬èªåŒ–ã®ã¿ï¼‰":
                with st.spinner("è‹±èªâ†’æ—¥æœ¬èª ç›´è¨³ä¸­..."):
                    final_out = llm_translate_only(
                        text=cleaned_for_llm,              # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—é™¤å»ç‰ˆã‚’ç¿»è¨³
                        api_key=api_key_input,
                        source_lang=detected_lang,
                        target_lang="ja",
                    )
            else:
                # â˜…â˜…â˜… ã“ã“ã‹ã‚‰è¿½åŠ ï¼šè¨˜äº‹ã ã‘â€œç›´è¨³â†’è¨˜äº‹èª¿â€ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ â˜…â˜…â˜…
                if out_kind == "è¨˜äº‹" and (output_lang == "ja"):
                    with st.spinner("è‹±èªâ†’æ—¥æœ¬èª ç›´è¨³ â†’ è¨˜äº‹èª¿ ã¸æ•´å½¢ä¸­..."):
                        # 1) ã¾ãšã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—é™¤å»ç‰ˆã‚’â€œç›´è¨³ï¼ˆæ—¥æœ¬èªï¼‰â€
                        ja_literal_for_article = llm_translate_only(
                            text=cleaned_for_llm,
                            api_key=api_key_input,
                            source_lang=detected_lang,
                            target_lang="ja",
                        )
                        # 2) ç›´è¨³ã‚’ç´ æã«ã€é‡è¤‡ã ã‘ã‚’æ•´ç†ã—â€œè¨˜äº‹èª¿ï¼ˆå¸¸ä½“ï¼‰â€ã«
                        final_out = llm_article_from_literal(
                            literal_ja=ja_literal_for_article,
                            api_key=api_key_input,
                            purpose=purpose,
                        )
                        # â˜… ã“ã®ç›´å¾Œã«ç½®ã
                        st.caption("route: ARTICLE_FROM_LITERAL (ja) âœ“ ç›´è¨³â†’è¨˜äº‹èª¿ãƒ«ãƒ¼ãƒˆã‚’é€šé")
                        
                        # â˜… è¿½åŠ ï¼šãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã«ã‚‚åŒã˜ç›´è¨³ã‚’ä½¿ãˆã‚‹ã‚ˆã†ä¿å­˜
                        st.session_state["ja_literal_for_article"] = ja_literal_for_article
                else:
                    llm_kind_call = {"è­°äº‹éŒ²": "minutes", "è¦æ—¨": "abstract"}.get(out_kind, "article")
                    parts = split_text_by_chars(llm_source, chunk_size=6000, overlap=300)
                    outs = []
                    N = len(parts)
                    for i, part in enumerate(parts, start=1):
                        meta = (
                            f"ã€åˆ†å‰²ãƒ‘ãƒ¼ãƒˆ {i}/{N}ã€‘\n"
                            "ã“ã®ãƒ‘ãƒ¼ãƒˆã§ã¯æ–°è¦æƒ…å ±ã®ã¿ã‚’åæ˜ ã—ã€æ—¢å‡ºã®è¦‹å‡ºã—ã‚„å°å…¥ã¯å†æ²ã—ãªã„ã§ãã ã•ã„ã€‚"
                        )
                        out_i = llm_rewrite(
                            kind=llm_kind_call,
                            text="ã€å‡ºåŠ›ã¯å¿…ãšæ—¥æœ¬èªã€‘\n" + meta + "\n\n" + part,
                            api_key=api_key_input,
                            purpose=purpose,
                            source_lang=detected_lang,
                            target_lang=output_lang,
                        )
                        outs.append(out_i.strip())
                    final_out = "\n\n".join(outs)
            st.success("ç”ŸæˆAIã§ã®æ•´å½¢ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        else:
            st.info("ç”ŸæˆAIãŒOFFã®ãŸã‚ã€ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯æ•´å½¢ã§å‡ºåŠ›ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        st.error(f"æ•´å½¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    # ===== ä¸‰æ®µè¡¨ç¤º =====
    st.subheader("ğŸ“ åŸæ–‡ï¼ˆå¤‰æ›´å‰ãƒ»è‹±èªï¼ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—é™¤å»ï¼‰")
    st.text_area("åŸæ–‡", value=cleaned_for_llm, height=260)

    st.subheader("ğŸ‡¯ğŸ‡µ è‹±èªâ†’æ—¥æœ¬èªï¼ˆç›´è¨³ãƒ»æ•´å½¢ãªã—ï¼‰")
    if use_llm and api_key_input:
        cached_literal = st.session_state.get("ja_literal_for_article")
        if cached_literal:
            ja_literal = cached_literal
        else:
            with st.spinner("è‹±èªâ†’æ—¥æœ¬èª ç›´è¨³ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ï¼‰..."):
                ja_literal = llm_translate_only(
                    text=cleaned_for_llm,
                    api_key=api_key_input,
                    source_lang=detected_lang,
                    target_lang="ja",
                )
        st.text_area("ç›´è¨³", value=ja_literal, height=260)
    else:
        st.text_area("ç›´è¨³", value="(APIã‚­ãƒ¼æœªå…¥åŠ›ã¾ãŸã¯ç”ŸæˆAIãŒOFFã®ãŸã‚ç›´è¨³ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“)", height=260)

    st.subheader("ğŸ“„ æ•´å½¢çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    if out_kind == "ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³è§£èª¬" and output_lang == "ja" and final_out:
        for _p in ["èƒŒæ™¯", "æ”¹è¨‚ãƒã‚¤ãƒ³ãƒˆ", "æ¨å¥¨åº¦ãƒ»ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹", "è‡¨åºŠã¸ã®å½±éŸ¿", "èª²é¡Œ", "ä»Šå¾Œ"]:
            final_out = re.sub(rf"(#+\s*{_p}\s*\n)(\s*\1)+", r"\1", final_out)
    st.text_area("æ•´å½¢çµæœ", value=final_out, height=380)

    st.download_button("TXTãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=final_out.encode("utf-8"), file_name="output.txt")
    docx_bytes = make_docx(title=f"{out_kind}ï¼ˆ{purpose}ï¼‰", content=final_out)
    st.download_button("DOCXãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=docx_bytes, file_name="output.docx")


if __name__ == "__main__":
    main()
